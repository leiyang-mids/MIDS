{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIDS UC Berkeley, Machine Learning at Scale  \n",
    "DATSCIW261 ASSIGNMENT #5  \n",
    "Version 2016-02-12 (FINAL)  \n",
    "[Natarajan Krishnaswami](mailto:natarajan@krishnaswami.org)  \n",
    "2016 Feb 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTIONS for SUBMISSIONS\n",
    "\n",
    "\n",
    "**SPECIAL INSTURCTIONS**: This weeks homework is a group exercise. Your team assignments for completing this HW are located at:\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1ncFQl5Tovn-16slD8mYjP_nzMTPSfiGeLLzW8v_sMjg/edit?usp=sharing\n",
    "\n",
    "See column Team assignment for Homeworks in tab \"Teams for HW Assignments\"\n",
    "\n",
    "Please submit your homeworks (one per team) going forward via this form (and not thru the ISVC):\n",
    "\n",
    "https://docs.google.com/forms/d/1ZOr9RnIe_A06AcZDB6K1mJN4vrLeSmS2PD6Xm3eOiis/viewform?usp=send_form\n",
    "\n",
    "Please follow the instructions for submissions carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 ASSIGNMENTS\n",
    "---\n",
    "## HW 5.0\n",
    "1. What is a data warehouse?\n",
    "2. What is a Star schema?\n",
    "3. When is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "1. A data warehouse is an enterprise's repository of all relevant information, be it structured, semi-structured, or unstructured, needed to monitor and predict business performance and needs.\n",
    "2. A star schema is one where rows in \"fact\" tables connect together IDs from (flat) \"dimension\" tables, potentially along with some descriptive columns.  It is a star since the fact table's columns fan out to each dimension table.\n",
    "3. If the fact entries do not vary too much in the dimensions they need (e.g., varying by location in a hierarchy), a star schema can be a good fit, and permit straightforward, easy to optimize, queries, and natural visualization of the entity relationships. Snowflake schemas can be a good fit if more flexibility/variability in needed for the dimensions, at the cost of more complex processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.1\n",
    "1. In the database world What is 3NF?\n",
    "1. Does machine learning use data in 3NF?\n",
    "  1. If so why? \n",
    "1. In what form does ML consume data?\n",
    "1. Why would one use log files that are denormalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "1. In Codd's hierarchy of normal forms, third normal form is a reduction of non-key column redundancy with and across rows, but not within superkeys. This avoidance of functional dependencies is (almost) sufficient to guarantee referential integrity during modification \n",
    "2. ML algorithms do not generally use normalized data\n",
    "3. ML algorithms generally use highly denormalized data transformed into a suitable feature space.\n",
    "4. If log files are not normalized, the various pieces of a record would need to be located and processed in order (joined) to process each record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.2\n",
    "Using MRJob, implement a hashside join (memory-backed map-side) for left, \n",
    "right and inner joins. Run your code on the  data used in HW 4.4: (Recall HW 4.4: Find the most frequent visitor of each page using mrjob and the output of 4.2  (i.e., transfromed log file).  \n",
    "In this output please include the webpage URL, webpageID and Visitor ID.)\n",
    "\n",
    "1. Justify which table you chose as the Left table in this hashside join.\n",
    "1. Please report the number of rows resulting from:\n",
    "  1. Left joining Table Left with Table Right\n",
    "  1. Right joining Table Left with Table Right\n",
    "  1. Inner joining Table Left with Table Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw52.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw52.py\n",
    "#!/opt/anaconda/bin/python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class HW52Job(MRJob):\n",
    "    def configure_options(self):\n",
    "        super(HW52Job,self).configure_options()\n",
    "        self.add_passthrough_option(\"--join_type\",type='string',help='[left|right|inner]', default='left')\n",
    "\n",
    "    urlmap={}\n",
    "    seen=set()\n",
    "    def load_urlmap(self):\n",
    "        with open('hw4.2-urls.txt', 'r') as urls:\n",
    "            for row in urls:\n",
    "                fields=row.strip().split(',')\n",
    "                self.urlmap[int(fields[1])]=fields[3].strip('\"')\n",
    "    @staticmethod\n",
    "    def split_visit(line):\n",
    "        fields=line.strip().split(',')\n",
    "        if len(fields) > 4:\n",
    "            return int(fields[1]), int(fields[4])\n",
    "    \n",
    "    def left_join(self, _, line):\n",
    "        urlid, userid=self.split_visit(line)\n",
    "        if urlid in self.urlmap:\n",
    "            self.seen.add(urlid)\n",
    "            yield urlid, (userid, self.urlmap[urlid])\n",
    "    def left_join_final(self):\n",
    "        for urlid in set(self.urlmap)-self.seen:\n",
    "            yield urlid, (self.urlmap[urlid], None)\n",
    "    \n",
    "    def right_join(self, _, line):\n",
    "        urlid, userid=self.split_visit(line)\n",
    "        yield urlid, (userid, self.urlmap.get(urlid, None))\n",
    "\n",
    "    def inner_join(self, _, line):\n",
    "        urlid, userid=self.split_visit(line)\n",
    "        url=self.urlmap.get(urlid, None)\n",
    "        if url:\n",
    "            yield urlid, (userid, url)\n",
    "        \n",
    "\n",
    "    def id_reducer(self, key, values):\n",
    "        for value in values:\n",
    "            yield key, value\n",
    "    \n",
    "    def steps(self):\n",
    "        if self.options.join_type.lower()=='left':\n",
    "            mapper=self.left_join\n",
    "            mapper_final=self.left_join_final\n",
    "        elif self.options.join_type.lower()=='right':\n",
    "            mapper=self.right_join\n",
    "            mapper_final=None\n",
    "        elif self.options.join_type.lower()=='inner':\n",
    "            mapper=self.inner_join\n",
    "            mapper_final=None\n",
    "        else:\n",
    "            raise ValueError('Unknown join type '+ self.options.join_type)\n",
    "        return [MRStep(\n",
    "                mapper_init=self.load_urlmap,\n",
    "                mapper=mapper,\n",
    "                mapper_final=mapper_final,\n",
    "                reducer=self.id_reducer\n",
    "            )]\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    HW52Job().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using configs in /home/nkrishna/.mrjob.conf\n",
      "creating tmp directory /tmp/hw52.nkrishna.20160215.003154.042726\n",
      "writing to /tmp/hw52.nkrishna.20160215.003154.042726/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /tmp/hw52.nkrishna.20160215.003154.042726/step-0-mapper-sorted\n",
      "> sort /tmp/hw52.nkrishna.20160215.003154.042726/step-0-mapper_part-00000\n",
      "writing to /tmp/hw52.nkrishna.20160215.003154.042726/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /tmp/hw52.nkrishna.20160215.003154.042726/step-0-reducer_part-00000 -> hw5.2-left-output/part-00000\n",
      "removing tmp directory /tmp/hw52.nkrishna.20160215.003154.042726\n",
      "using configs in /home/nkrishna/.mrjob.conf\n",
      "creating tmp directory /tmp/hw52.nkrishna.20160215.003200.262725\n",
      "writing to /tmp/hw52.nkrishna.20160215.003200.262725/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /tmp/hw52.nkrishna.20160215.003200.262725/step-0-mapper-sorted\n",
      "> sort /tmp/hw52.nkrishna.20160215.003200.262725/step-0-mapper_part-00000\n",
      "writing to /tmp/hw52.nkrishna.20160215.003200.262725/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /tmp/hw52.nkrishna.20160215.003200.262725/step-0-reducer_part-00000 -> hw5.2-right-output/part-00000\n",
      "removing tmp directory /tmp/hw52.nkrishna.20160215.003200.262725\n",
      "using configs in /home/nkrishna/.mrjob.conf\n",
      "creating tmp directory /tmp/hw52.nkrishna.20160215.003206.714690\n",
      "writing to /tmp/hw52.nkrishna.20160215.003206.714690/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /tmp/hw52.nkrishna.20160215.003206.714690/step-0-mapper-sorted\n",
      "> sort /tmp/hw52.nkrishna.20160215.003206.714690/step-0-mapper_part-00000\n",
      "writing to /tmp/hw52.nkrishna.20160215.003206.714690/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /tmp/hw52.nkrishna.20160215.003206.714690/step-0-reducer_part-00000 -> hw5.2-inner-output/part-00000\n",
      "removing tmp directory /tmp/hw52.nkrishna.20160215.003206.714690\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export HADOOP_HOME=/opt/hadoop-2.7.1\n",
    "export PATH=$HADOOP_HOME/bin:$PATH\n",
    "export HADOOP_ROOT_LOGGER=INFO,console\n",
    "\n",
    "for jointype in left right inner; do\n",
    "    rm -rf hw5.2-${jointype}\n",
    "    ./hw52.py --join_type=${jointype} \\\n",
    "      -r inline --no-output \\\n",
    "      --file ../hw4/hw4.2-urls.txt \\\n",
    "      --output=hw5.2-${jointype}-output \\\n",
    "      ../hw4/hw4.2-visits.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "1. I chose the URLs list for the left table since it is much, much smaller than the visits list.  Thus it made sense for it to be the one to load into ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. A: 98663\n",
      "   B: 98654\n",
      "   C: 98654\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"2. A:\" $(< hw5.2-left-output/part-00000 wc -l)\n",
    "echo \"   B:\" $(< hw5.2-right-output/part-00000 wc -l)\n",
    "echo \"   C:\" $(< hw5.2-inner-output/part-00000 wc -l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## HW 5.3 For the remainder of this assignment you will work with two datasets:\n",
    "\n",
    "### 1: unit/systems test data set: SYSTEMS TEST DATASET\n",
    "Three terms, A,B,C and their corresponding strip-docs of co-occurring terms\n",
    "```\n",
    "DocA {X:20, Y:30, Z:5}\n",
    "DocB {X:100, Y:20}\n",
    "DocC {M:5, N:20, Z:5}\n",
    "```\n",
    "\n",
    "### 2: A large subset of the Google n-grams dataset\n",
    "\n",
    "https://aws.amazon.com/datasets/google-books-ngrams/\n",
    "\n",
    "which we have placed in a bucket/folder on Dropbox on s3:\n",
    "\n",
    "   https://www.dropbox.com/sh/tmqpc4o0xswhkvz/AACUifrl6wrMrlK6a3X3lZ9Ea?dl=0 \n",
    "\n",
    "   s3://filtered-5grams/\n",
    "\n",
    "For each HW 5.3 -5.5 Please unit test and system test your code with with SYSTEMS TEST DATASET and show the results.  \n",
    "Please compute the expected answer by hand and show your hand calculations. Then show the results you get with you system.  \n",
    "Final show your results on the Google n-grams dataset\n",
    "\n",
    "\n",
    "In particular, this bucket contains (~200) files (10Meg each) in the format:\n",
    "```\n",
    "\t(ngram) \\t (count) \\t (pages_count) \\t (books_count)\n",
    "```\n",
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "1. Longest 5-gram (number of characters)\n",
    "2. Top 10 most frequent words (please use the count information), i.e., unigrams\n",
    "3. Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency (Hint: save to PART-000* and take the `head -n 1000`)\n",
    "4. Distribution of 5-gram sizes (using counts info.) sorted in decreasing order of relative frequency.\n",
    "5. OPTIONAL Question: Plot the log-log plot of the frequency distributuion of unigrams. Does it follow power law distribution?\n",
    "\n",
    "For more background see:  \n",
    "https://en.wikipedia.org/wiki/Log%E2%80%93log_plot  \n",
    "https://en.wikipedia.org/wiki/Power_law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('hw5.3-test.txt','w') as f:\n",
    "    print >>f, 'DocA\\t{X:20, Y:30, Z:5}'\n",
    "    print >>f, 'DocB\\t{X:100, Y:20}'\n",
    "    print >>f, 'DocC\\t{M:5, N:20, Z:5}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw5.3-1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw5.3-1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from collections import namedtuple\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class HW53Job(MRJob):\n",
    "    JOBCONF = {\n",
    "        'mapred.output.key.comparator.class':\n",
    "          'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "        'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "    }\n",
    "    Row=namedtuple('Row',['ngram', 'count', 'pages_count', 'books_count'])\n",
    "    @staticmethod\n",
    "    def split_line(line):\n",
    "        fields=line.strip().split('\\t')\n",
    "        return HW53Job.Row(fields[0],*[int(field) for field in fields[1:]])\n",
    "\n",
    "    # Find the longest 5-gram\n",
    "    ## Mapper: keep track of/update the longest 5-gram.\n",
    "    #          finally yield the longest one seen.\n",
    "    def longest_map_init(self):\n",
    "        self.longest=''\n",
    "    def longest_map(self, _, line):\n",
    "        row=HW53Job.split_line(line);\n",
    "        if len(row.ngram) > len(self.longest):\n",
    "            self.longest=row.ngram\n",
    "    def longest_map_final(self):\n",
    "        yield len(self.longest), self.longest\n",
    "        \n",
    "    ## Reducer: keep track of/update the longest word list.\n",
    "    #          finally yield each of the longest words with their length.\n",
    "    def longest_red_init(self):\n",
    "        self.longest=[]\n",
    "    def longest_red(self, key, values):\n",
    "        if not self.longest or key > len(self.longest[0]):\n",
    "            for val in values:\n",
    "                self.longest.append(val)\n",
    "    def longest_red_final(self):\n",
    "        for val in self.longest:\n",
    "            yield len(val), val\n",
    "            \n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                mapper_init=self.longest_map_init,\n",
    "                mapper=self.longest_map,\n",
    "                mapper_final=self.longest_map_final,\n",
    "                reducer_init=self.longest_red_init,\n",
    "                reducer=self.longest_red,\n",
    "                reducer_final=self.longest_red_final,\n",
    "            )]\n",
    "if __name__=='__main__':\n",
    "    HW53Job().run()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted hdfs://master:9000/hw5.3-1-output\n",
      "159\t\"ROPLEZIMPREDASTRODONBRASLPKLSON YHROACLMPARCHEYXMMIOUDAVESAURUS PIOFPILOCOWERSURUASOGETSESNEGCP TYRAVOPSIFENGOQUAPIALLOBOSKENUO OWINFUYAIOKENECKSASXHYILPOYNUAT\"\n",
      "159\t\"AIOPJUMRXUYVASLYHYPSIBEMAPODIKR UFRYDIUUOLBIGASUAURUSREXLISNAYE RNOONDQSRUNSUBUNOUGRABBERYAIRTC UTAHRAPTOREDILEIPMILBDUMMYUVERI SYEVRAHVELOCYALLOSAURUSLINROTSR\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd hw5\n",
      "+ prog=hw5.3-1\n",
      "+ hdfs=hdfs://master:9000\n",
      "+ input=hdfs://master:9000/filtered-5grams\n",
      "+ output=hdfs://master:9000/hw5.3-1-output\n",
      "+ HADOOP_ROOT_LOGGER=WARN,console\n",
      "+ hdfs dfs -rm -r -f hdfs://master:9000/hw5.3-1-output\n",
      "16/02/16 23:24:39 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\n",
      "+ ./hw5.3-1.py -q -r hadoop --no-bootstrap-mrjob --output hdfs://master:9000/hw5.3-1-output hdfs://master:9000/filtered-5grams\n",
      "\n",
      "real\t0m57.575s\n",
      "user\t0m25.311s\n",
      "sys\t0m1.572s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/bin/ssh root@50.22.252.4 bash -xs <<'EOF'\n",
    "cd hw5\n",
    "prog=hw5.3-1\n",
    "hdfs=hdfs://master:9000\n",
    "input=$hdfs/filtered-5grams\n",
    "output=$hdfs/$prog-output\n",
    "HADOOP_ROOT_LOGGER=WARN,console\n",
    "hdfs dfs -rm -r -f $output\n",
    "time ./$prog.py -q -r hadoop --no-bootstrap-mrjob \\\n",
    "  --output $output \\\n",
    "  $input\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw5.3-2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw5.3-2.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from collections import namedtuple\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys\n",
    "\n",
    "class HW53Job(MRJob):\n",
    "    Row=namedtuple('Row',['ngram', 'count', 'pages_count', 'books_count'])\n",
    "    @staticmethod\n",
    "    def split_line(line):\n",
    "        fields=line.strip().split('\\t')\n",
    "        return HW53Job.Row(fields[0],*[int(field) for field in fields[1:]])\n",
    "\n",
    "    \"\"\"Find the top ten unigrams\"\"\"\n",
    "    def get_wordcounts(self, _, line):\n",
    "        \"\"\"Mapper: split the 5-grams, and yield the count with each.\"\"\"\n",
    "        row=HW53Job.split_line(line)\n",
    "        for word in row.ngram.split():\n",
    "            print >>sys.stderr, \"word:\",word\n",
    "            yield word, int(row.count)\n",
    "    def sum_wordcounts(self, key, values):\n",
    "        \"\"\"Combiner: sum the counts as in usual word count\"\"\"\n",
    "        yield key, sum(values)\n",
    "    def sum_swap_wordcounts(self, key, values):\n",
    "        \"\"\"Reducer: sum the counts as in usual word count and swap key/val for sorting\"\"\"\n",
    "        yield sum(values), key\n",
    "\n",
    "    ## dummy map/red steps to cause another sort\n",
    "    def map_id(self, key, val):\n",
    "        yield key, val\n",
    "    def red_id(self, key, vals):\n",
    "        for x in vals:\n",
    "            yield key, x \n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper=self.get_wordcounts,\n",
    "                combiner=self.sum_wordcounts,\n",
    "                reducer=self.sum_swap_wordcounts,\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper=self.map_id,\n",
    "                reducer=self.red_id,\n",
    "                jobconf={\n",
    "                    'mapred.output.key.comparator.class':\n",
    "                       'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "if __name__=='__main__':\n",
    "    HW53Job().run()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted foo\n",
      "5375699242\t\"the\"\n",
      "3691308874\t\"of\"\n",
      "2221164346\t\"to\"\n",
      "1387638591\t\"in\"\n",
      "1342195425\t\"a\"\n",
      "1135779433\t\"and\"\n",
      "798553959\t\"that\"\n",
      "756296656\t\"is\"\n",
      "688053106\t\"be\"\n",
      "481373389\t\"as\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd hw5\n",
      "+ cat out\n",
      "+ cat err\n",
      "16/02/17 08:24:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\n",
      "no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "creating tmp directory /tmp/hw5.root.20160217.142415.557030\n",
      "writing wrapper script to /tmp/hw5.root.20160217.142415.557030/setup-wrapper.sh\n",
      "Using Hadoop version 2.7.2\n",
      "Copying local files into hdfs:///user/root/tmp/mrjob/hw5.root.20160217.142415.557030/files/\n",
      "HADOOP: packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob1443581881176190507.jar tmpDir=null\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Total input paths to process : 190\r\n",
      "HADOOP: number of splits:190\r\n",
      "HADOOP: Submitting tokens for job: job_1455677115242_0032\r\n",
      "HADOOP: Submitted application application_1455677115242_0032\r\n",
      "HADOOP: The url to track the job: http://master:8088/proxy/application_1455677115242_0032/\r\n",
      "HADOOP: Running job: job_1455677115242_0032\r\n",
      "HADOOP: Job job_1455677115242_0032 running in uber mode : false\r\n",
      "HADOOP:  map 0% reduce 0%\r\n",
      "HADOOP:  map 1% reduce 0%\r\n",
      "HADOOP:  map 2% reduce 0%\r\n",
      "HADOOP:  map 3% reduce 0%\r\n",
      "HADOOP:  map 4% reduce 0%\r\n",
      "HADOOP:  map 5% reduce 0%\r\n",
      "HADOOP:  map 6% reduce 0%\r\n",
      "HADOOP:  map 7% reduce 0%\r\n",
      "HADOOP:  map 8% reduce 0%\r\n",
      "HADOOP:  map 9% reduce 0%\r\n",
      "HADOOP:  map 10% reduce 0%\r\n",
      "HADOOP:  map 11% reduce 0%\r\n",
      "HADOOP:  map 12% reduce 0%\r\n",
      "HADOOP:  map 13% reduce 0%\r\n",
      "HADOOP:  map 14% reduce 0%\r\n",
      "HADOOP:  map 15% reduce 0%\r\n",
      "HADOOP:  map 16% reduce 0%\r\n",
      "HADOOP:  map 17% reduce 0%\r\n",
      "HADOOP:  map 18% reduce 0%\r\n",
      "HADOOP:  map 19% reduce 0%\r\n",
      "HADOOP:  map 20% reduce 0%\r\n",
      "HADOOP:  map 22% reduce 0%\r\n",
      "HADOOP:  map 24% reduce 0%\r\n",
      "HADOOP:  map 25% reduce 0%\r\n",
      "HADOOP:  map 25% reduce 6%\r\n",
      "HADOOP:  map 26% reduce 6%\r\n",
      "HADOOP:  map 27% reduce 6%\r\n",
      "HADOOP:  map 28% reduce 6%\r\n",
      "HADOOP:  map 29% reduce 6%\r\n",
      "HADOOP:  map 30% reduce 6%\r\n",
      "HADOOP:  map 31% reduce 6%\r\n",
      "HADOOP:  map 31% reduce 7%\r\n",
      "HADOOP:  map 32% reduce 7%\r\n",
      "HADOOP:  map 33% reduce 7%\r\n",
      "HADOOP:  map 34% reduce 7%\r\n",
      "HADOOP:  map 35% reduce 7%\r\n",
      "HADOOP:  map 35% reduce 8%\r\n",
      "HADOOP:  map 36% reduce 8%\r\n",
      "HADOOP:  map 36% reduce 9%\r\n",
      "HADOOP:  map 37% reduce 9%\r\n",
      "HADOOP:  map 38% reduce 9%\r\n",
      "HADOOP:  map 39% reduce 9%\r\n",
      "HADOOP:  map 40% reduce 9%\r\n",
      "HADOOP:  map 41% reduce 9%\r\n",
      "HADOOP:  map 42% reduce 9%\r\n",
      "HADOOP:  map 43% reduce 10%\r\n",
      "HADOOP:  map 44% reduce 10%\r\n",
      "HADOOP:  map 45% reduce 12%\r\n",
      "HADOOP:  map 46% reduce 12%\r\n",
      "HADOOP:  map 46% reduce 13%\r\n",
      "HADOOP:  map 47% reduce 13%\r\n",
      "HADOOP:  map 48% reduce 14%\r\n",
      "HADOOP:  map 49% reduce 14%\r\n",
      "HADOOP:  map 49% reduce 15%\r\n",
      "HADOOP:  map 50% reduce 15%\r\n",
      "HADOOP:  map 51% reduce 15%\r\n",
      "HADOOP:  map 52% reduce 15%\r\n",
      "HADOOP:  map 53% reduce 15%\r\n",
      "HADOOP:  map 54% reduce 15%\r\n",
      "HADOOP:  map 55% reduce 15%\r\n",
      "HADOOP:  map 56% reduce 15%\r\n",
      "HADOOP:  map 57% reduce 15%\r\n",
      "HADOOP:  map 58% reduce 15%\r\n",
      "HADOOP:  map 59% reduce 15%\r\n",
      "HADOOP:  map 60% reduce 15%\r\n",
      "HADOOP:  map 61% reduce 15%\r\n",
      "HADOOP:  map 62% reduce 15%\r\n",
      "HADOOP:  map 63% reduce 15%\r\n",
      "HADOOP:  map 64% reduce 15%\r\n",
      "HADOOP:  map 64% reduce 16%\r\n",
      "HADOOP:  map 65% reduce 16%\r\n",
      "HADOOP:  map 66% reduce 16%\r\n",
      "HADOOP:  map 66% reduce 17%\r\n",
      "HADOOP:  map 67% reduce 18%\r\n",
      "HADOOP:  map 68% reduce 18%\r\n",
      "HADOOP:  map 68% reduce 19%\r\n",
      "HADOOP:  map 69% reduce 19%\r\n",
      "HADOOP:  map 70% reduce 19%\r\n",
      "HADOOP:  map 70% reduce 21%\r\n",
      "HADOOP:  map 71% reduce 21%\r\n",
      "HADOOP:  map 72% reduce 22%\r\n",
      "HADOOP:  map 73% reduce 22%\r\n",
      "HADOOP:  map 74% reduce 22%\r\n",
      "HADOOP:  map 75% reduce 22%\r\n",
      "HADOOP:  map 76% reduce 22%\r\n",
      "HADOOP:  map 77% reduce 22%\r\n",
      "HADOOP:  map 78% reduce 22%\r\n",
      "HADOOP:  map 79% reduce 22%\r\n",
      "HADOOP:  map 80% reduce 22%\r\n",
      "HADOOP:  map 81% reduce 22%\r\n",
      "HADOOP:  map 82% reduce 22%\r\n",
      "HADOOP:  map 83% reduce 22%\r\n",
      "HADOOP:  map 84% reduce 22%\r\n",
      "HADOOP:  map 85% reduce 22%\r\n",
      "HADOOP:  map 86% reduce 22%\r\n",
      "HADOOP:  map 87% reduce 22%\r\n",
      "HADOOP:  map 88% reduce 22%\r\n",
      "HADOOP:  map 89% reduce 22%\r\n",
      "HADOOP:  map 90% reduce 22%\r\n",
      "HADOOP:  map 90% reduce 25%\r\n",
      "HADOOP:  map 91% reduce 25%\r\n",
      "HADOOP:  map 91% reduce 26%\r\n",
      "HADOOP:  map 92% reduce 26%\r\n",
      "HADOOP:  map 93% reduce 27%\r\n",
      "HADOOP:  map 94% reduce 28%\r\n",
      "HADOOP:  map 95% reduce 28%\r\n",
      "HADOOP:  map 95% reduce 29%\r\n",
      "HADOOP:  map 96% reduce 29%\r\n",
      "HADOOP:  map 96% reduce 30%\r\n",
      "HADOOP:  map 97% reduce 30%\r\n",
      "HADOOP:  map 97% reduce 31%\r\n",
      "HADOOP:  map 98% reduce 31%\r\n",
      "HADOOP:  map 99% reduce 31%\r\n",
      "HADOOP:  map 99% reduce 32%\r\n",
      "HADOOP:  map 99% reduce 33%\r\n",
      "HADOOP:  map 100% reduce 33%\r\n",
      "HADOOP:  map 100% reduce 34%\r\n",
      "HADOOP:  map 100% reduce 67%\r\n",
      "HADOOP:  map 100% reduce 69%\r\n",
      "HADOOP:  map 100% reduce 70%\r\n",
      "HADOOP:  map 100% reduce 72%\r\n",
      "HADOOP:  map 100% reduce 73%\r\n",
      "HADOOP:  map 100% reduce 75%\r\n",
      "HADOOP:  map 100% reduce 76%\r\n",
      "HADOOP:  map 100% reduce 78%\r\n",
      "HADOOP:  map 100% reduce 80%\r\n",
      "HADOOP:  map 100% reduce 82%\r\n",
      "HADOOP:  map 100% reduce 85%\r\n",
      "HADOOP:  map 100% reduce 87%\r\n",
      "HADOOP:  map 100% reduce 89%\r\n",
      "HADOOP:  map 100% reduce 91%\r\n",
      "HADOOP:  map 100% reduce 93%\r\n",
      "HADOOP:  map 100% reduce 95%\r\n",
      "HADOOP:  map 100% reduce 98%\r\n",
      "HADOOP:  map 100% reduce 100%\r\n",
      "HADOOP: Job job_1455677115242_0032 completed successfully\r\n",
      "HADOOP: Counters: 52\r\n",
      "HADOOP: \tFile System Counters\r\n",
      "HADOOP: \t\tFILE: Number of bytes read=50683493\r\n",
      "HADOOP: \t\tFILE: Number of bytes written=206122757\r\n",
      "HADOOP: \t\tFILE: Number of read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of large read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of write operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of bytes read=2156095226\r\n",
      "HADOOP: \t\tHDFS: Number of bytes written=5251252\r\n",
      "HADOOP: \t\tHDFS: Number of read operations=573\r\n",
      "HADOOP: \t\tHDFS: Number of large read operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of write operations=2\r\n",
      "HADOOP: \tJob Counters \r\n",
      "HADOOP: \t\tKilled map tasks=4\r\n",
      "HADOOP: \t\tLaunched map tasks=194\r\n",
      "HADOOP: \t\tLaunched reduce tasks=1\r\n",
      "HADOOP: \t\tOther local map tasks=2\r\n",
      "HADOOP: \t\tData-local map tasks=190\r\n",
      "HADOOP: \t\tRack-local map tasks=2\r\n",
      "HADOOP: \t\tTotal time spent by all maps in occupied slots (ms)=22263989\r\n",
      "HADOOP: \t\tTotal time spent by all reduces in occupied slots (ms)=408000\r\n",
      "HADOOP: \t\tTotal time spent by all map tasks (ms)=22263989\r\n",
      "HADOOP: \t\tTotal time spent by all reduce tasks (ms)=408000\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all map tasks=22263989\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all reduce tasks=408000\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all map tasks=22798324736\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all reduce tasks=417792000\r\n",
      "HADOOP: \tMap-Reduce Framework\r\n",
      "HADOOP: \t\tMap input records=58682266\r\n",
      "HADOOP: \t\tMap output records=293411330\r\n",
      "HADOOP: \t\tMap output bytes=3136729760\r\n",
      "HADOOP: \t\tMap output materialized bytes=132001630\r\n",
      "HADOOP: \t\tInput split bytes=26110\r\n",
      "HADOOP: \t\tCombine input records=298596684\r\n",
      "HADOOP: \t\tCombine output records=8216908\r\n",
      "HADOOP: \t\tReduce input groups=343019\r\n",
      "HADOOP: \t\tReduce shuffle bytes=132001630\r\n",
      "HADOOP: \t\tReduce input records=3031554\r\n",
      "HADOOP: \t\tReduce output records=343019\r\n",
      "HADOOP: \t\tSpilled Records=10953597\r\n",
      "HADOOP: \t\tShuffled Maps =190\r\n",
      "HADOOP: \t\tFailed Shuffles=0\r\n",
      "HADOOP: \t\tMerged Map outputs=190\r\n",
      "HADOOP: \t\tGC time elapsed (ms)=82586\r\n",
      "HADOOP: \t\tCPU time spent (ms)=21252850\r\n",
      "HADOOP: \t\tPhysical memory (bytes) snapshot=51913187328\r\n",
      "HADOOP: \t\tVirtual memory (bytes) snapshot=406539476992\r\n",
      "HADOOP: \t\tTotal committed heap usage (bytes)=37774426112\r\n",
      "HADOOP: \tShuffle Errors\r\n",
      "HADOOP: \t\tBAD_ID=0\r\n",
      "HADOOP: \t\tCONNECTION=0\r\n",
      "HADOOP: \t\tIO_ERROR=0\r\n",
      "HADOOP: \t\tWRONG_LENGTH=0\r\n",
      "HADOOP: \t\tWRONG_MAP=0\r\n",
      "HADOOP: \t\tWRONG_REDUCE=0\r\n",
      "HADOOP: \tFile Input Format Counters \r\n",
      "HADOOP: \t\tBytes Read=2156069116\r\n",
      "HADOOP: \tFile Output Format Counters \r\n",
      "HADOOP: \t\tBytes Written=5251252\r\n",
      "HADOOP: Output directory: hdfs:///user/root/tmp/mrjob/hw5.root.20160217.142415.557030/step-output/1\r\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.2:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "HADOOP: packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob6811890661771153365.jar tmpDir=null\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Total input paths to process : 1\r\n",
      "HADOOP: number of splits:2\r\n",
      "HADOOP: mapred.text.key.comparator.options is deprecated. Instead, use mapreduce.partition.keycomparator.options\r\n",
      "HADOOP: mapred.output.key.comparator.class is deprecated. Instead, use mapreduce.job.output.key.comparator.class\r\n",
      "HADOOP: Submitting tokens for job: job_1455677115242_0033\r\n",
      "HADOOP: Submitted application application_1455677115242_0033\r\n",
      "HADOOP: The url to track the job: http://master:8088/proxy/application_1455677115242_0033/\r\n",
      "HADOOP: Running job: job_1455677115242_0033\r\n",
      "HADOOP: Job job_1455677115242_0033 running in uber mode : false\r\n",
      "HADOOP:  map 0% reduce 0%\r\n",
      "HADOOP:  map 42% reduce 0%\r\n",
      "HADOOP:  map 62% reduce 0%\r\n",
      "HADOOP:  map 100% reduce 0%\r\n",
      "HADOOP:  map 100% reduce 78%\r\n",
      "HADOOP:  map 100% reduce 84%\r\n",
      "HADOOP:  map 100% reduce 91%\r\n",
      "HADOOP:  map 100% reduce 96%\r\n",
      "HADOOP:  map 100% reduce 100%\r\n",
      "HADOOP: Job job_1455677115242_0033 completed successfully\r\n",
      "HADOOP: Counters: 49\r\n",
      "HADOOP: \tFile System Counters\r\n",
      "HADOOP: \t\tFILE: Number of bytes read=5937296\r\n",
      "HADOOP: \t\tFILE: Number of bytes written=12242556\r\n",
      "HADOOP: \t\tFILE: Number of read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of large read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of write operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of bytes read=5255642\r\n",
      "HADOOP: \t\tHDFS: Number of bytes written=5251252\r\n",
      "HADOOP: \t\tHDFS: Number of read operations=9\r\n",
      "HADOOP: \t\tHDFS: Number of large read operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of write operations=2\r\n",
      "HADOOP: \tJob Counters \r\n",
      "HADOOP: \t\tLaunched map tasks=2\r\n",
      "HADOOP: \t\tLaunched reduce tasks=1\r\n",
      "HADOOP: \t\tData-local map tasks=2\r\n",
      "HADOOP: \t\tTotal time spent by all maps in occupied slots (ms)=25505\r\n",
      "HADOOP: \t\tTotal time spent by all reduces in occupied slots (ms)=19097\r\n",
      "HADOOP: \t\tTotal time spent by all map tasks (ms)=25505\r\n",
      "HADOOP: \t\tTotal time spent by all reduce tasks (ms)=19097\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all map tasks=25505\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all reduce tasks=19097\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all map tasks=26117120\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all reduce tasks=19555328\r\n",
      "HADOOP: \tMap-Reduce Framework\r\n",
      "HADOOP: \t\tMap input records=343019\r\n",
      "HADOOP: \t\tMap output records=343019\r\n",
      "HADOOP: \t\tMap output bytes=5251252\r\n",
      "HADOOP: \t\tMap output materialized bytes=5937302\r\n",
      "HADOOP: \t\tInput split bytes=294\r\n",
      "HADOOP: \t\tCombine input records=0\r\n",
      "HADOOP: \t\tCombine output records=0\r\n",
      "HADOOP: \t\tReduce input groups=41362\r\n",
      "HADOOP: \t\tReduce shuffle bytes=5937302\r\n",
      "HADOOP: \t\tReduce input records=343019\r\n",
      "HADOOP: \t\tReduce output records=343019\r\n",
      "HADOOP: \t\tSpilled Records=686038\r\n",
      "HADOOP: \t\tShuffled Maps =2\r\n",
      "HADOOP: \t\tFailed Shuffles=0\r\n",
      "HADOOP: \t\tMerged Map outputs=2\r\n",
      "HADOOP: \t\tGC time elapsed (ms)=221\r\n",
      "HADOOP: \t\tCPU time spent (ms)=38540\r\n",
      "HADOOP: \t\tPhysical memory (bytes) snapshot=706281472\r\n",
      "HADOOP: \t\tVirtual memory (bytes) snapshot=6388023296\r\n",
      "HADOOP: \t\tTotal committed heap usage (bytes)=542113792\r\n",
      "HADOOP: \tShuffle Errors\r\n",
      "HADOOP: \t\tBAD_ID=0\r\n",
      "HADOOP: \t\tCONNECTION=0\r\n",
      "HADOOP: \t\tIO_ERROR=0\r\n",
      "HADOOP: \t\tWRONG_LENGTH=0\r\n",
      "HADOOP: \t\tWRONG_MAP=0\r\n",
      "HADOOP: \t\tWRONG_REDUCE=0\r\n",
      "HADOOP: \tFile Input Format Counters \r\n",
      "HADOOP: \t\tBytes Read=5255348\r\n",
      "HADOOP: \tFile Output Format Counters \r\n",
      "HADOOP: \t\tBytes Written=5251252\r\n",
      "HADOOP: Output directory: hdfs:///hw5.3-2-output\n",
      "Counters from step 2:\n",
      "  (no counters found)\n",
      "removing tmp directory /tmp/hw5.root.20160217.142415.557030\n",
      "deleting hdfs:///user/root/tmp/mrjob/hw5.root.20160217.142415.557030 from HDFS\n",
      "\n",
      "real\t9m38.781s\n",
      "user\t0m33.362s\n",
      "sys\t0m2.039s\n",
      "+ hdfs dfs -cat foo/part-00000\n",
      "+ head\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/bin/ssh root@50.22.252.4 bash -xs <<'EOF'\n",
    "cd hw5\n",
    "prog=hw5.3-2\n",
    "hdfs=hdfs://master:9000\n",
    "input=${hdfs}/filtered-5grams\n",
    "output=${hdfs}/${prog}-output\n",
    "HADOOP_ROOT_LOGGER=INFO,console\n",
    "hdfs dfs -rm -r -f ${output}\n",
    "time ./${prog}.py -r hadoop --strict-protocols --no-bootstrap-mrjob \\\n",
    "  --no-output \\\n",
    "  --output ${output} \\\n",
    "   ${input}\n",
    "hdfs dfs -cat ${output}/part-00000 | head -10\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw5.3-3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw5.3-3.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from collections import namedtuple\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys\n",
    "\n",
    "class HW53Job(MRJob):\n",
    "    Row=namedtuple('Row',['ngram', 'count', 'pages_count', 'books_count'])\n",
    "    @staticmethod\n",
    "    def split_line(line):\n",
    "        fields=line.strip().split('\\t')\n",
    "        return HW53Job.Row(fields[0],*[int(field) for field in fields[1:]])\n",
    "\n",
    "    \"\"\"Produce the word densities and sort them\"\"\"\n",
    "    def get_counts(self, _, line):\n",
    "        \"\"\"Mapper: split the 5-grams, and yield the count with each.\"\"\"\n",
    "        row=HW53Job.split_line(line)\n",
    "        for word in row.ngram.split():\n",
    "            yield word, (row.count, row.pages_count)\n",
    "    def sum_counts(self, key, values):\n",
    "        \"\"\"Combiner: sum the counts as in usual word count\"\"\"\n",
    "        count, page_count = 0,0\n",
    "        for val in values:\n",
    "            count+=val[0]\n",
    "            page_count+=val[1]\n",
    "        yield key, (count, page_count)\n",
    "    def calc_freqs(self, key, values):\n",
    "        \"\"\"Reducer: sum the counts as in usual word count and swap key/val for sorting\"\"\"\n",
    "        for _,(count, page_count) in self.sum_counts(key, values):\n",
    "            yield 1.0*count/page_count, key\n",
    "\n",
    "    ## dummy map/red steps to cause another sort\n",
    "    def map_id(self, key, val):\n",
    "        yield key, val\n",
    "    def red_id(self, key, vals):\n",
    "        for x in vals:\n",
    "            yield key, x \n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper=self.get_counts,\n",
    "                combiner=self.sum_counts,\n",
    "                reducer=self.calc_freqs,\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper=self.map_id,\n",
    "                reducer=self.red_id,\n",
    "                jobconf={\n",
    "                    'mapred.output.key.comparator.class':\n",
    "                       'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'mapred.text.key.comparator.options': '-k1,1nr',\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "if __name__=='__main__':\n",
    "    HW53Job().run()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.557291666666666\t\"xxxx\"\n",
      "10.161726044782885\t\"NA\"\n",
      "8.074159907300116\t\"blah\"\n",
      "7.533333333333333\t\"nnn\"\n",
      "6.561143644505684\t\"nd\"\n",
      "5.40736428467472\t\"ND\"\n",
      "4.921875\t\"oooooooooooooooo\"\n",
      "4.7272727272727275\t\"PIC\"\n",
      "4.511627906976744\t\"llll\"\n",
      "4.349498327759197\t\"LUTHER\"\n",
      "4.207237859573151\t\"oooooo\"\n",
      "4.0908402725208175\t\"NN\"\n",
      "3.9492846924177396\t\"ooooo\"\n",
      "3.9313725490196076\t\"OOOOOO\"\n",
      "3.7877030162412995\t\"IIII\"\n",
      "3.7624521072796937\t\"lillelu\"\n",
      "3.6570701447431206\t\"OOOOO\"\n",
      "3.6065625\t\"Sc\"\n",
      "3.576923076923077\t\"Pfeffermann\"\n",
      "3.576923076923077\t\"Madarassy\"\n",
      "3.56\t\"Meteoritical\"\n",
      "3.536491677336748\t\"Undecided\"\n",
      "3.505639097744361\t\"Lib\"\n",
      "3.5\t\"xxxxxxxx\"\n",
      "3.4791318864774623\t\"ri\"\n",
      "3.375068493150685\t\"Vir\"\n",
      "3.2390171258376768\t\"DREAM\"\n",
      "3.229038854805726\t\"beep\"\n",
      "3.188679245283019\t\"Latha\"\n",
      "3.188317505823329\t\"MARTIN\"\n",
      "3.1699346405228757\t\"Lis\"\n",
      "3.1147458480120784\t\"Ac\"\n",
      "3.037142857142857\t\"OUTPUT\"\n",
      "3.022222222222222\t\"HENNESSY\"\n",
      "3.0\t\"ALLIS\"\n",
      "2.9191176470588234\t\"IYENGAR\"\n",
      "2.869891270467005\t\"ft\"\n",
      "2.8432451923076925\t\"Adapted\"\n",
      "2.825\t\"counterfeiteth\"\n",
      "2.81981981981982\t\"nonmorular\"\n",
      "2.81981981981982\t\"nonsquamous\"\n",
      "2.8085106382978724\t\"RHYME\"\n",
      "2.74468085106383\t\"YOUTHS\"\n",
      "2.7264957264957266\t\"Poing\"\n",
      "2.7\t\"Kuhl\"\n",
      "2.6748466257668713\t\"Sirignano\"\n",
      "2.673469387755102\t\"METRES\"\n",
      "2.673469387755102\t\"YARDS\"\n",
      "2.66414686825054\t\"Illl\"\n",
      "2.660377358490566\t\"Neophytos\"\n",
      "2.660377358490566\t\"Edelby\"\n",
      "2.640311804008909\t\"CHOH\"\n",
      "2.627005347593583\t\"Vocht\"\n",
      "2.5973377703826954\t\"Inactive\"\n",
      "2.595744680851064\t\"plappern\"\n",
      "2.595744680851064\t\"schwatzen\"\n",
      "2.58974358974359\t\"Horida\"\n",
      "2.575\t\"undrinkable\"\n",
      "2.561606725829052\t\"Phys\"\n",
      "2.5521472392638036\t\"Radiat\"\n",
      "2.5166666666666666\t\"Nambo\"\n",
      "2.5133995784402288\t\"Sag\"\n",
      "2.490549791191286\t\"Oncol\"\n",
      "2.476923076923077\t\"Wadiar\"\n",
      "2.4754098360655736\t\"Villanelle\"\n",
      "2.467065868263473\t\"ingrossed\"\n",
      "2.456140350877193\t\"USF\"\n",
      "2.4508196721311477\t\"HUMBER'S\"\n",
      "2.4508196721311477\t\"cillum\"\n",
      "2.418472063854048\t\"pryntinge\"\n",
      "2.418472063854048\t\"lycense\"\n",
      "2.406764168190128\t\"FLEISCHER\"\n",
      "2.4\t\"midell\"\n",
      "2.3991416309012874\t\"Chimeric\"\n",
      "2.394578313253012\t\"Compilations\"\n",
      "2.3846153846153846\t\"rauens\"\n",
      "2.3734177215189876\t\"Brosman\"\n",
      "2.369565217391304\t\"Bursch\"\n",
      "2.357142857142857\t\"Scheffauer\"\n",
      "2.3553750966744005\t\"CHO\"\n",
      "2.3421727972626174\t\"Bl\"\n",
      "2.3333333333333335\t\"Vacchagotta\"\n",
      "2.3316326530612246\t\"RAVI\"\n",
      "2.3114754098360657\t\"Carnwarth\"\n",
      "2.3112582781456954\t\"Logotherapy\"\n",
      "2.3\t\"aliquyam\"\n",
      "2.298611111111111\t\"Bev\"\n",
      "2.2954545454545454\t\"Realschulen\"\n",
      "2.276190476190476\t\"irure\"\n",
      "2.276190476190476\t\"reprehenderit\"\n",
      "2.2441176470588236\t\"Intraocul\"\n",
      "2.234375\t\"Jerico\"\n",
      "2.2339449541284404\t\"JAF\"\n",
      "2.2339449541284404\t\"Roodbergen\"\n",
      "2.2325581395348837\t\"Sanatana\"\n",
      "2.232142857142857\t\"Fouilles\"\n",
      "2.2262351921409995\t\"tO\"\n",
      "2.2222222222222223\t\"douff\"\n",
      "2.207920792079208\t\"Cynddylan\"\n",
      "2.2051282051282053\t\"DOLLS\"\n",
      "2.193548387096774\t\"venireman\"\n",
      "2.1932515337423313\t\"Snorkeling\"\n",
      "2.181858567909212\t\"Pathol\"\n",
      "2.1814321874744835\t\"Adolesc\"\n",
      "2.1706827309236947\t\"ff\"\n",
      "2.1597938144329896\t\"mumblin\"\n",
      "2.1564625850340136\t\"PINT\"\n",
      "2.153960029607698\t\"Aq\"\n",
      "2.1475409836065573\t\"deserunt\"\n",
      "2.1475409836065573\t\"mollit\"\n",
      "2.140625\t\"Triturus\"\n",
      "2.14\t\"defalt\"\n",
      "2.1372549019607843\t\"Kevo\"\n",
      "2.136842105263158\t\"trigram\"\n",
      "2.135135135135135\t\"gefahrlicher\"\n",
      "2.1325301204819276\t\"Multiconference\"\n",
      "2.1221826809015423\t\"JPEN\"\n",
      "2.1221826809015423\t\"Parenter\"\n",
      "2.1144619602467443\t\"COM\"\n",
      "2.0991166077738517\t\"ESTATE\"\n",
      "2.0943775100401605\t\"MOV\"\n",
      "2.091549295774648\t\"MARJORIE\"\n",
      "2.087719298245614\t\"Talich\"\n",
      "2.083565459610028\t\"cun\"\n",
      "2.082666666666667\t\"tempor\"\n",
      "2.082666666666667\t\"incididunt\"\n",
      "2.08125\t\"herrin\"\n",
      "2.0806451612903225\t\"eiusmod\"\n",
      "2.075187969924812\t\"LEKYTHOI\"\n",
      "2.063960639606396\t\"Pogue\"\n",
      "2.0588235294117645\t\"Meseguer\"\n",
      "2.0588235294117645\t\"Goguen\"\n",
      "2.0491803278688523\t\"Blissful\"\n",
      "2.0472560975609757\t\"tcp\"\n",
      "2.0466101694915255\t\"Mekhilta\"\n",
      "2.0412451361867703\t\"laoreet\"\n",
      "2.04\t\"Phelan's\"\n",
      "2.0363475177304964\t\"Ub\"\n",
      "2.0357142857142856\t\"Pos\"\n",
      "2.0357142857142856\t\"Neg\"\n",
      "2.030075187969925\t\"pericranial\"\n",
      "2.028013965906757\t\"Surg\"\n",
      "2.0268456375838926\t\"nonperfection\"\n",
      "2.026143790849673\t\"MAZEL\"\n",
      "2.025189283634246\t\"CL\"\n",
      "2.0217606330365974\t\"IDIOMS\"\n",
      "2.016872160934458\t\"Neusner\"\n",
      "2.010204081632653\t\"Hampartumian\"\n",
      "2.009625668449198\t\"Lorem\"\n",
      "2.008873596522999\t\"Intern\"\n",
      "2.0051730998806208\t\"SP\"\n",
      "2.0\t\"GROWlNG\"\n",
      "2.0\t\"Chamrajendra\"\n",
      "2.0\t\"miming\"\n",
      "1.9909638554216869\t\"ullamco\"\n",
      "1.9852941176470589\t\"Aposentadoria\"\n",
      "1.9852941176470589\t\"Pensoes\"\n",
      "1.978021978021978\t\"PELL\"\n",
      "1.9765625\t\"Waigal\"\n",
      "1.9704704704704705\t\"amet\"\n",
      "1.969450101832994\t\"euismod\"\n",
      "1.969450101832994\t\"tincidunt\"\n",
      "1.969450101832994\t\"nibh\"\n",
      "1.969450101832994\t\"nonummy\"\n",
      "1.9685336689741977\t\"LESTER\"\n",
      "1.9660869565217391\t\"Expense\"\n",
      "1.965034965034965\t\"Pis\"\n",
      "1.9644268774703557\t\"Berenstain\"\n",
      "1.962962962962963\t\"Ventriloquist\"\n",
      "1.9610004936646372\t\"Artif\"\n",
      "1.9591836734693877\t\"Eidhnech\"\n",
      "1.9591836734693877\t\"Cluain\"\n",
      "1.9583333333333333\t\"Branover\"\n",
      "1.9583333333333333\t\"Yeshajahu\"\n",
      "1.957142857142857\t\"Beforderung\"\n",
      "1.9545454545454546\t\"Phytochemicals\"\n",
      "1.9505813953488371\t\"microbiologica\"\n",
      "1.9505813953488371\t\"pathologica\"\n",
      "1.9461538461538461\t\"pariatur\"\n",
      "1.9461538461538461\t\"fugiat\"\n",
      "1.9397590361445782\t\"HEUVEN\"\n",
      "1.9387755102040816\t\"Charuhas\"\n",
      "1.9366197183098592\t\"Aggadic\"\n",
      "1.9363636363636363\t\"Breakfasts\"\n",
      "1.9298245614035088\t\"Cropanzano\"\n",
      "1.9285714285714286\t\"arthropodan\"\n",
      "1.9268292682926829\t\"Civilian's\"\n",
      "1.92580724673404\t\"Disagree\"\n",
      "1.925\t\"pickety\"\n",
      "1.9157894736842105\t\"LEMESHOW\"\n",
      "1.9157894736842105\t\"HOSMER\"\n",
      "1.912736265677442\t\"Gem\"\n",
      "1.9078947368421053\t\"Indemnification\"\n",
      "1.9059829059829059\t\"Reprocessing\"\n",
      "1.90234375\t\"posie\"\n",
      "1.8945544554455445\t\"dolore\"\n",
      "1.893939393939394\t\"HOLOCAUST\"\n",
      "1.8933333333333333\t\"Oakton\"\n",
      "1.8907917383820998\t\"Cl\"\n",
      "1.8904428904428905\t\"Redonnet\"\n",
      "1.888\t\"VOLTAGE\"\n",
      "1.888\t\"NODE\"\n",
      "1.8877679697351828\t\"consequat\"\n",
      "1.8870967741935485\t\"Thleary\"\n",
      "1.8859223300970873\t\"Tuberc\"\n",
      "1.885782475281282\t\"ti\"\n",
      "1.881720430107527\t\"starcher\"\n",
      "1.88135593220339\t\"wisi\"\n",
      "1.8801213960546281\t\"aliquip\"\n",
      "1.8796895213454075\t\"VUNAKIS\"\n",
      "1.8793103448275863\t\"UMN\"\n",
      "1.8793103448275863\t\"LMN\"\n",
      "1.879120879120879\t\"IOOO\"\n",
      "1.8789473684210527\t\"pistol's\"\n",
      "1.878787878787879\t\"nostrud\"\n",
      "1.8780487804878048\t\"wedres\"\n",
      "1.8780487804878048\t\"wintres\"\n",
      "1.8780487804878048\t\"overshake\"\n",
      "1.8775510204081634\t\"histochemischen\"\n",
      "1.8775510204081634\t\"Sichtbarmachung\"\n",
      "1.8775510204081634\t\"Fluoreszenzmethoden\"\n",
      "1.8764044943820224\t\"OMe\"\n",
      "1.875\t\"Unease\"\n",
      "1.875\t\"McEwan's\"\n",
      "1.872340425531915\t\"BURLINGAME\"\n",
      "1.8708708708708708\t\"CALENDAR\"\n",
      "1.8683035714285714\t\"lobortis\"\n",
      "1.8652857042203903\t\"Biol\"\n",
      "1.8613861386138615\t\"Mandelbrote\"\n",
      "1.859922178988327\t\"LILLEY\"\n",
      "1.8596491228070176\t\"overseership\"\n",
      "1.8571428571428572\t\"Wagrushka\"\n",
      "1.85678391959799\t\"ullamcorper\"\n",
      "1.85678391959799\t\"exerci\"\n",
      "1.85678391959799\t\"suscipit\"\n",
      "1.8562091503267975\t\"Fonda's\"\n",
      "1.853846153846154\t\"Moggallana\"\n",
      "1.8535469107551488\t\"veniam\"\n",
      "1.8514851485148516\t\"Berubari\"\n",
      "1.8512396694214877\t\"aliquam\"\n",
      "1.8469750889679715\t\"diam\"\n",
      "1.8444444444444446\t\"Archaeol\"\n",
      "1.84375\t\"isteach\"\n",
      "1.84375\t\"phost\"\n",
      "1.8414634146341464\t\"curiousest\"\n",
      "1.8412887828162292\t\"commodo\"\n",
      "1.8369098712446352\t\"Ackermann's\"\n",
      "1.836734693877551\t\"BUSHY\"\n",
      "1.8339041095890412\t\"Optom\"\n",
      "1.8314606741573034\t\"Inflorescence\"\n",
      "1.8297872340425532\t\"Portlock's\"\n",
      "1.8296543107038734\t\"lournal\"\n",
      "1.828125\t\"Thelephoraceae\"\n",
      "1.8269230769230769\t\"gostak\"\n",
      "1.8269230769230769\t\"distimmed\"\n",
      "1.8268150896722326\t\"Med\"\n",
      "1.826086956521739\t\"Crocombe\"\n",
      "1.8251748251748252\t\"Corson's\"\n",
      "1.8245614035087718\t\"becam\"\n",
      "1.8229166666666667\t\"Primov\"\n",
      "1.8214285714285714\t\"Obeisance\"\n",
      "1.8181818181818181\t\"Immobil\"\n",
      "1.8181818181818181\t\"Substit\"\n",
      "1.8179611650485437\t\"scandinavica\"\n",
      "1.8166666666666667\t\"haerede\"\n",
      "1.8166563082660037\t\"iiii\"\n",
      "1.8148148148148149\t\"tation\"\n",
      "1.8109028960817717\t\"Topchiev\"\n",
      "1.8012820512820513\t\"supposit\"\n",
      "1.8\t\"propios\"\n",
      "1.8\t\"Vibrating\"\n",
      "1.7966101694915255\t\"laboris\"\n",
      "1.7964071856287425\t\"TONY\"\n",
      "1.7946428571428572\t\"Darrow's\"\n",
      "1.794392523364486\t\"ACCOUNTANCY\"\n",
      "1.793103448275862\t\"Mikrofossilien\"\n",
      "1.793103448275862\t\"Silurs\"\n",
      "1.793103448275862\t\"baltischen\"\n",
      "1.793103448275862\t\"mault\"\n",
      "1.7923076923076924\t\"PONY\"\n",
      "1.7916666666666667\t\"Immunoisolation\"\n",
      "1.7892813641900123\t\"cadastre\"\n",
      "1.7882352941176471\t\"Scanty\"\n",
      "1.7872340425531914\t\"Maarten\"\n",
      "1.78\t\"Midship\"\n",
      "1.7752808988764044\t\"TRE\"\n",
      "1.775\t\"Eval\"\n",
      "1.775\t\"Carcinog\"\n",
      "1.7748303516347934\t\"Endod\"\n",
      "1.7745098039215685\t\"TEXTURES\"\n",
      "1.7720694645441388\t\"dolor\"\n",
      "1.7719298245614035\t\"Pickpocket\"\n",
      "1.7695652173913043\t\"Lightwave\"\n",
      "1.7692307692307692\t\"HERCULES\"\n",
      "1.7692307692307692\t\"leive\"\n",
      "1.7647058823529411\t\"Hollandais\"\n",
      "1.7622504537205081\t\"thalweg\"\n",
      "1.7619047619047619\t\"Lavu\"\n",
      "1.76\t\"Fearest\"\n",
      "1.7570093457943925\t\"Nonpassive\"\n",
      "1.7553191489361701\t\"Tanzi\"\n",
      "1.7549019607843137\t\"Ferratas\"\n",
      "1.7547169811320755\t\"Intl\"\n",
      "1.7524613220815752\t\"Tra\"\n",
      "1.7521008403361344\t\"Cryogenic\"\n",
      "1.751269035532995\t\"molestie\"\n",
      "1.7501040366208906\t\"Strongly\"\n",
      "1.75\t\"Marcia's\"\n",
      "1.75\t\"Auricle\"\n",
      "1.7467248908296944\t\"BATSFORD\"\n",
      "1.7452229299363058\t\"chou\"\n",
      "1.742873541228238\t\"Expiration\"\n",
      "1.7407302173604204\t\"Radiol\"\n",
      "1.74\t\"catechetics\"\n",
      "1.7384615384615385\t\"warrantee\"\n",
      "1.7370689655172413\t\"EMBASSY\"\n",
      "1.7354596622889307\t\"BR\"\n",
      "1.7349081364829397\t\"Digumarti\"\n",
      "1.7339246119733924\t\"punkin\"\n",
      "1.7337733773377337\t\"RVs\"\n",
      "1.732484076433121\t\"Pellegrino\"\n",
      "1.73\t\"Misadventure\"\n",
      "1.7291666666666667\t\"inflexional\"\n",
      "1.728395061728395\t\"Gratuitos\"\n",
      "1.728395061728395\t\"Texto\"\n",
      "1.7272727272727273\t\"RUBIN\"\n",
      "1.7258883248730965\t\"prelabour\"\n",
      "1.7241379310344827\t\"Jur\"\n",
      "1.7183098591549295\t\"lungless\"\n",
      "1.7154471544715446\t\"Recalcitrant\"\n",
      "1.712676056338028\t\"Mosq\"\n",
      "1.7122302158273381\t\"Nubar\"\n",
      "1.7117971334068358\t\"INTERNAL\"\n",
      "1.7117117117117118\t\"Gallons\"\n",
      "1.711111111111111\t\"surviver\"\n",
      "1.7092198581560283\t\"Oto\"\n",
      "1.7076882007474639\t\"CENRO\"\n",
      "1.707142857142857\t\"dignissim\"\n",
      "1.7065868263473054\t\"volke\"\n",
      "1.7065868263473054\t\"miscalle\"\n",
      "1.704\t\"Desalination\"\n",
      "1.7035398230088497\t\"Kareah\"\n",
      "1.7031924072476272\t\"SUFFRAGE\"\n",
      "1.703125\t\"Implanted\"\n",
      "1.7030303030303031\t\"iusto\"\n",
      "1.7026143790849673\t\"Aeroengine\"\n",
      "1.702020202020202\t\"ARCHETYPES\"\n",
      "1.7001321003963012\t\"vulputate\"\n",
      "1.6978417266187051\t\"Medineh\"\n",
      "1.6970338983050848\t\"exercitation\"\n",
      "1.696969696969697\t\"jinns\"\n",
      "1.6964285714285714\t\"Buu\"\n",
      "1.6956521739130435\t\"GOSCH\"\n",
      "1.6949924127465856\t\"Opportunistic\"\n",
      "1.6933019976498238\t\"Spectrom\"\n",
      "1.6923076923076923\t\"verrucose\"\n",
      "1.6923076923076923\t\"initdefault\"\n",
      "1.690909090909091\t\"Straf\"\n",
      "1.6901408450704225\t\"Salomos\"\n",
      "1.6890756302521008\t\"Tahle\"\n",
      "1.6890756302521008\t\"Stahle\"\n",
      "1.6868686868686869\t\"prenumeraty\"\n",
      "1.6833333333333333\t\"typologique\"\n",
      "1.6829268292682926\t\"Unicellular\"\n",
      "1.6818181818181819\t\"dientes\"\n",
      "1.6818181818181819\t\"parientes\"\n",
      "1.6766169154228856\t\"Retrieves\"\n",
      "1.6763085399449036\t\"Biographer\"\n",
      "1.676056338028169\t\"Leaming\"\n",
      "1.6744186046511629\t\"Larras\"\n",
      "1.674074074074074\t\"Deuterium\"\n",
      "1.672627235213205\t\"Waitotara\"\n",
      "1.671641791044776\t\"TORRANCE\"\n",
      "1.6691365979381443\t\"Nutr\"\n",
      "1.6688741721854305\t\"JONES'S\"\n",
      "1.66875\t\"Greenwillow\"\n",
      "1.6666666666666667\t\"Klingel\"\n",
      "1.6666666666666667\t\"Deluxe\"\n",
      "1.6666666666666667\t\"lmages\"\n",
      "1.6623376623376624\t\"Axson\"\n",
      "1.6615720524017468\t\"FPGAs\"\n",
      "1.6612903225806452\t\"Shatin\"\n",
      "1.6611721611721613\t\"Ormazd\"\n",
      "1.6610169491525424\t\"IACHR\"\n",
      "1.6608695652173913\t\"Resolusies\"\n",
      "1.6603773584905661\t\"MeO\"\n",
      "1.6597222222222223\t\"noninferior\"\n",
      "1.6586345381526104\t\"Psychosoc\"\n",
      "1.656326932545544\t\"Auditor's\"\n",
      "1.65625\t\"REITER\"\n",
      "1.655\t\"Borisov\"\n",
      "1.6544117647058822\t\"voluptate\"\n",
      "1.654320987654321\t\"Wyes\"\n",
      "1.6538461538461537\t\"Sukhavati\"\n",
      "1.6534090909090908\t\"MEDAL\"\n",
      "1.653061224489796\t\"Percycross\"\n",
      "1.6527777777777777\t\"Mischling\"\n",
      "1.6515151515151516\t\"LYING\"\n",
      "1.6507936507936507\t\"Venation\"\n",
      "1.6501457725947521\t\"praesent\"\n",
      "1.6501457725947521\t\"blandit\"\n",
      "1.6481481481481481\t\"Trucks\"\n",
      "1.647887323943662\t\"occupacion\"\n",
      "1.6470588235294117\t\"transactors\"\n",
      "1.6470588235294117\t\"Fert\"\n",
      "1.6458333333333333\t\"Onc\"\n",
      "1.6442953020134228\t\"unnat\"\n",
      "1.6431492842535786\t\"Cents\"\n",
      "1.6428571428571428\t\"capellet\"\n",
      "1.6428571428571428\t\"lanceam\"\n",
      "1.6425891181988743\t\"Bodywork\"\n",
      "1.6415094339622642\t\"Briefcase\"\n",
      "1.6407185628742516\t\"Nurs\"\n",
      "1.639344262295082\t\"Literarische\"\n",
      "1.6385542168674698\t\"Hortic\"\n",
      "1.6376811594202898\t\"Shaying\"\n",
      "1.6363636363636365\t\"Morhidity\"\n",
      "1.6355140186915889\t\"Microelectromechanical\"\n",
      "1.6354938271604937\t\"Retroviruses\"\n",
      "1.6349041901321149\t\"Acad\"\n",
      "1.631704410011919\t\"Fluidized\"\n",
      "1.6294416243654823\t\"Giovane\"\n",
      "1.6281859070464768\t\"MATTOS\"\n",
      "1.6279294983536703\t\"cn\"\n",
      "1.6274509803921569\t\"anticariogenic\"\n",
      "1.6271186440677967\t\"nmol\"\n",
      "1.6271186440677967\t\"kwh\"\n",
      "1.6262626262626263\t\"cowkeeper\"\n",
      "1.6246096189881325\t\"MISCELLANEOUS\"\n",
      "1.6229508196721312\t\"hayfork\"\n",
      "1.6226415094339623\t\"reviewest\"\n",
      "1.6219512195121952\t\"createst\"\n",
      "1.6212653778558874\t\"velit\"\n",
      "1.6206896551724137\t\"endurethfor\"\n",
      "1.6203703703703705\t\"Virologists\"\n",
      "1.620123203285421\t\"STAMP\"\n",
      "1.619718309859155\t\"promisedst\"\n",
      "1.618805849889089\t\"Natl\"\n",
      "1.6179520801048992\t\"YES\"\n",
      "1.6177303782702883\t\"vellum\"\n",
      "1.6157635467980296\t\"Patently\"\n",
      "1.6143344709897611\t\"birk\"\n",
      "1.6140350877192982\t\"fquares\"\n",
      "1.6132075471698113\t\"SIB\"\n",
      "1.6129032258064515\t\"bec\"\n",
      "1.6122448979591837\t\"microcode\"\n",
      "1.6122448979591837\t\"Littledale's\"\n",
      "1.6115702479338843\t\"Finlande\"\n",
      "1.6101694915254237\t\"Birket\"\n",
      "1.609907120743034\t\"hauke\"\n",
      "1.609628217349857\t\"Aa\"\n",
      "1.609375\t\"bizniss\"\n",
      "1.6074074074074074\t\"Rabutin\"\n",
      "1.606936416184971\t\"Lubbub\"\n",
      "1.6046511627906976\t\"gootther\"\n",
      "1.6013071895424837\t\"Taffy's\"\n",
      "1.6011016913876595\t\"Proc\"\n",
      "1.6006933501418217\t\"ipsum\"\n",
      "1.6\t\"Instituta\"\n",
      "1.5996938384998087\t\"keratomileusis\"\n",
      "1.598802395209581\t\"Jee\"\n",
      "1.5975609756097562\t\"Pilcher\"\n",
      "1.5974781765276431\t\"Mitchenson\"\n",
      "1.5974025974025974\t\"Armorer\"\n",
      "1.5968992248062015\t\"Hwe\"\n",
      "1.5957446808510638\t\"fossile\"\n",
      "1.5952380952380953\t\"Didelphys\"\n",
      "1.5930232558139534\t\"cyanophytes\"\n",
      "1.5925925925925926\t\"Guvener\"\n",
      "1.59247889485802\t\"Implant\"\n",
      "1.5924242424242425\t\"meritos\"\n",
      "1.5921787709497206\t\"Baussiere\"\n",
      "1.5919003115264798\t\"doy\"\n",
      "1.5914634146341464\t\"DESTROYED\"\n",
      "1.5909090909090908\t\"Autohiographical\"\n",
      "1.5899390243902438\t\"Bequeath\"\n",
      "1.5893333333333333\t\"CARL\"\n",
      "1.588623732952658\t\"Sci\"\n",
      "1.587378640776699\t\"Tue\"\n",
      "1.5866666666666667\t\"Zerahites\"\n",
      "1.5853658536585367\t\"Mitchelson\"\n",
      "1.5846153846153845\t\"Angoysses\"\n",
      "1.5846153846153845\t\"douloureuses\"\n",
      "1.5846153846153845\t\"procedent\"\n",
      "1.5844155844155845\t\"costilla\"\n",
      "1.5820895522388059\t\"Namburbi\"\n",
      "1.5820895522388059\t\"Scarpa\"\n",
      "1.58203125\t\"Cruikshank's\"\n",
      "1.5818181818181818\t\"Aichi\"\n",
      "1.5818181818181818\t\"Actto\"\n",
      "1.5809768637532133\t\"wunt\"\n",
      "1.5802707930367506\t\"Gyrate\"\n",
      "1.5802469135802468\t\"Cotran\"\n",
      "1.5801526717557253\t\"Ufficiale\"\n",
      "1.5795454545454546\t\"mearrah\"\n",
      "1.5791139240506329\t\"luptatum\"\n",
      "1.5791139240506329\t\"zzril\"\n",
      "1.5789473684210527\t\"SelectionMode\"\n",
      "1.5781725888324873\t\"Polym\"\n",
      "1.5777777777777777\t\"BALEK\"\n",
      "1.5777777777777777\t\"Episcopale\"\n",
      "1.5775075987841944\t\"Taile\"\n",
      "1.5769230769230769\t\"engorda\"\n",
      "1.576470588235294\t\"Observatorium\"\n",
      "1.576470588235294\t\"Meteorologisch\"\n",
      "1.576470588235294\t\"Magnetisch\"\n",
      "1.576086956521739\t\"Metaplastic\"\n",
      "1.5757804252752223\t\"Agree\"\n",
      "1.5757575757575757\t\"Terracing\"\n",
      "1.5717488789237668\t\"SOMEBODY\"\n",
      "1.5714285714285714\t\"Rogerian\"\n",
      "1.5714285714285714\t\"visaed\"\n",
      "1.5689655172413792\t\"distolingual\"\n",
      "1.568445475638051\t\"Instructs\"\n",
      "1.5681818181818181\t\"Echinoidea\"\n",
      "1.5681063122923589\t\"HELEN\"\n",
      "1.5680473372781065\t\"Nisir\"\n",
      "1.5675675675675675\t\"Gord\"\n",
      "1.5668789808917198\t\"AAMFT\"\n",
      "1.5666666666666667\t\"Commutative\"\n",
      "1.5662650602409638\t\"Helminthic\"\n",
      "1.5660814839350778\t\"char\"\n",
      "1.565217391304348\t\"ofEnology\"\n",
      "1.565217391304348\t\"Superelastic\"\n",
      "1.5641646489104115\t\"Autographa\"\n",
      "1.5619136960600375\t\"Specify\"\n",
      "1.5612244897959184\t\"Calliactis\"\n",
      "1.56\t\"Heliozoa\"\n",
      "1.5593220338983051\t\"dicast\"\n",
      "1.5588235294117647\t\"Biblesoft\"\n",
      "1.558455114822547\t\"wapentake\"\n",
      "1.5573770491803278\t\"Endodontics\"\n",
      "1.5572916666666667\t\"Paleontol\"\n",
      "1.5555555555555556\t\"LONSDALE\"\n",
      "1.5546875\t\"phred\"\n",
      "1.5545454545454545\t\"GHD\"\n",
      "1.553763440860215\t\"laissie\"\n",
      "1.553191489361702\t\"WAGON\"\n",
      "1.5524861878453038\t\"Scatophaga\"\n",
      "1.5511811023622046\t\"shocK\"\n",
      "1.5510204081632653\t\"FMI\"\n",
      "1.5510204081632653\t\"Codicils\"\n",
      "1.55\t\"Krishnamurti\"\n",
      "1.55\t\"Myxoid\"\n",
      "1.5493827160493827\t\"halachah\"\n",
      "1.5490196078431373\t\"DAI\"\n",
      "1.5489534098582038\t\"GILBERT\"\n",
      "1.5472972972972974\t\"BiCMOS\"\n",
      "1.5465116279069768\t\"Coenzyme\"\n",
      "1.5460526315789473\t\"Samanas\"\n",
      "1.5447619047619048\t\"Akaroa\"\n",
      "1.5436893203883495\t\"PLATH\"\n",
      "1.5436893203883495\t\"HOMAGE\"\n",
      "1.5423728813559323\t\"JerseyRobert\"\n",
      "1.5419847328244274\t\"Thur\"\n",
      "1.5416666666666667\t\"chemosurgery\"\n",
      "1.5407725321888412\t\"hendrerit\"\n",
      "1.5406859448554135\t\"Chieh\"\n",
      "1.5405405405405406\t\"previllous\"\n",
      "1.5404310186037944\t\"Unlawful\"\n",
      "1.5394190871369295\t\"Mischlinge\"\n",
      "1.5392670157068062\t\"Siboga\"\n",
      "1.538812785388128\t\"Spillius\"\n",
      "1.5384615384615385\t\"bidis\"\n",
      "1.5373953219751662\t\"MOLDAVE\"\n",
      "1.537313432835821\t\"matchsticks\"\n",
      "1.536470588235294\t\"Stenographisches\"\n",
      "1.5363636363636364\t\"Feyl\"\n",
      "1.5363636363636364\t\"Chavkin\"\n",
      "1.5357142857142858\t\"Psychoanalyzing\"\n",
      "1.53475935828877\t\"procreatis\"\n",
      "1.5347222222222223\t\"Audited\"\n",
      "1.5340236686390532\t\"WOLD\"\n",
      "1.5330012453300124\t\"REGARDLESS\"\n",
      "1.5304232804232805\t\"SHOCK\"\n",
      "1.5294117647058822\t\"Nieves\"\n",
      "1.5294117647058822\t\"Recode\"\n",
      "1.5291734197730957\t\"Hyg\"\n",
      "1.5284552845528456\t\"Oholibamah\"\n",
      "1.528301886792453\t\"urodelean\"\n",
      "1.5276595744680852\t\"unsorted\"\n",
      "1.5274725274725274\t\"Maja\"\n",
      "1.5272727272727273\t\"Bezoar\"\n",
      "1.5272257230570367\t\"Trop\"\n",
      "1.527027027027027\t\"Videha\"\n",
      "1.5268817204301075\t\"brances\"\n",
      "1.5260208166533227\t\"Drilling\"\n",
      "1.5255198487712665\t\"Rangitikei\"\n",
      "1.5227272727272727\t\"Katzeff\"\n",
      "1.5225643748340856\t\"Min\"\n",
      "1.5223880597014925\t\"Ibs\"\n",
      "1.521594684385382\t\"Mycological\"\n",
      "1.5215759849906192\t\"Isot\"\n",
      "1.521505376344086\t\"Monkmeyer\"\n",
      "1.521172638436482\t\"Memher\"\n",
      "1.5211267605633803\t\"NeuroBloc\"\n",
      "1.5209834675710046\t\"Geoscience\"\n",
      "1.5207100591715976\t\"Repelita\"\n",
      "1.52\t\"Appealed\"\n",
      "1.5191815856777493\t\"canakin\"\n",
      "1.5189831898318984\t\"Bone\"\n",
      "1.5180722891566265\t\"Intermediaire\"\n",
      "1.5179487179487179\t\"Friedhoff\"\n",
      "1.5178571428571428\t\"Parme's\"\n",
      "1.5173237753882916\t\"Urogynecol\"\n",
      "1.5172413793103448\t\"intergrown\"\n",
      "1.5169491525423728\t\"Toroidal\"\n",
      "1.5161290322580645\t\"progressiva\"\n",
      "1.5161290322580645\t\"harse\"\n",
      "1.5158730158730158\t\"roily\"\n",
      "1.5156794425087108\t\"equivocated\"\n",
      "1.5151515151515151\t\"salticid\"\n",
      "1.5147058823529411\t\"trinomial\"\n",
      "1.5144927536231885\t\"Ultrasonics\"\n",
      "1.5142857142857142\t\"Codicibus\"\n",
      "1.5141776937618148\t\"Minelike\"\n",
      "1.5141752577319587\t\"Cetacean\"\n",
      "1.514018691588785\t\"Averments\"\n",
      "1.5138888888888888\t\"Aportaciones\"\n",
      "1.5127919911012235\t\"Flaws\"\n",
      "1.5121951219512195\t\"Durzan\"\n",
      "1.5121951219512195\t\"Moats\"\n",
      "1.5121951219512195\t\"Bonga\"\n",
      "1.5120481927710843\t\"Adjournments\"\n",
      "1.5119617224880382\t\"Amarillo\"\n",
      "1.5119047619047619\t\"Besonderheiten\"\n",
      "1.51171875\t\"mustached\"\n",
      "1.5116279069767442\t\"ffreemen\"\n",
      "1.5114155251141552\t\"Ebeling\"\n",
      "1.5106382978723405\t\"Gado\"\n",
      "1.5104166666666667\t\"Panhellenion\"\n",
      "1.5090991810737033\t\"Benthological\"\n",
      "1.5087719298245614\t\"Nonfinancial\"\n",
      "1.5084745762711864\t\"Multiclass\"\n",
      "1.5078534031413613\t\"Kheta\"\n",
      "1.5076923076923077\t\"Ostdeutschland\"\n",
      "1.5076923076923077\t\"Anpassungsprozesse\"\n",
      "1.5076923076923077\t\"unternehmerische\"\n",
      "1.5076923076923077\t\"ingresos\"\n",
      "1.5059920106524634\t\"Mending\"\n",
      "1.5058823529411764\t\"Enabled\"\n",
      "1.5034122842232036\t\"Volcanology\"\n",
      "1.5031847133757963\t\"ampholytes\"\n",
      "1.5030345471521942\t\"Rosen\"\n",
      "1.501466275659824\t\"Harnack's\"\n",
      "1.5011961722488039\t\"TEIXEIRA\"\n",
      "1.5\t\"ANNING\"\n",
      "1.5\t\"SWEEPSTAKES\"\n",
      "1.5\t\"Koniunktur\"\n",
      "1.5\t\"Ingbar's\"\n",
      "1.5\t\"Cen\"\n",
      "1.5\t\"Okeanografii\"\n",
      "1.5\t\"Khozyaistva\"\n",
      "1.5\t\"Rybnogo\"\n",
      "1.5\t\"Handlu\"\n",
      "1.5\t\"Arkham\"\n",
      "1.5\t\"Aupres\"\n",
      "1.5\t\"interganglionic\"\n",
      "1.5\t\"WorId's\"\n",
      "1.5\t\"lmprovement\"\n",
      "1.5\t\"tetanized\"\n",
      "1.5\t\"nigrum\"\n",
      "1.499222395023328\t\"Tackle\"\n",
      "1.498949894989499\t\"Bit\"\n",
      "1.4978723404255319\t\"DAVIDS\"\n",
      "1.4965299040620534\t\"Chem\"\n",
      "1.496\t\"Hola\"\n",
      "1.4959349593495934\t\"Herpetic\"\n",
      "1.4954954954954955\t\"sitae\"\n",
      "1.4952380952380953\t\"AUTHORSHIP\"\n",
      "1.4949367088607595\t\"servicios\"\n",
      "1.49486301369863\t\"Phe\"\n",
      "1.4945054945054945\t\"GAMBIA\"\n",
      "1.4944567627494456\t\"Geothermal\"\n",
      "1.4943683675414627\t\"Oral\"\n",
      "1.494296577946768\t\"SITTING\"\n",
      "1.4939271255060729\t\"USDS\"\n",
      "1.4936708860759493\t\"Antiga\"\n",
      "1.4933333333333334\t\"holomorphy\"\n",
      "1.492537313432836\t\"nightes\"\n",
      "1.4925187032418952\t\"Sakha\"\n",
      "1.4915254237288136\t\"JPB\"\n",
      "1.4912240184757506\t\"MATTER\"\n",
      "1.4911417322834646\t\"odio\"\n",
      "1.490566037735849\t\"Korkut\"\n",
      "1.490566037735849\t\"Tarratines\"\n",
      "1.490566037735849\t\"Dede\"\n",
      "1.490066225165563\t\"Regionalisms\"\n",
      "1.4900542495479205\t\"IRC\"\n",
      "1.4893617021276595\t\"obligatoire\"\n",
      "1.4893617021276595\t\"ngo\"\n",
      "1.488888888888889\t\"PIPELINE\"\n",
      "1.4885057471264367\t\"Slumber's\"\n",
      "1.4882005319915614\t\"Hearing\"\n",
      "1.4881516587677726\t\"int\"\n",
      "1.4880952380952381\t\"Soloukhin\"\n",
      "1.4875283446712018\t\"SABATO\"\n",
      "1.4872389791183294\t\"Lonergan\"\n",
      "1.4862385321100917\t\"bequeathe\"\n",
      "1.4851485148514851\t\"masculis\"\n",
      "1.484375\t\"Cranio\"\n",
      "1.4814814814814814\t\"electroencephalic\"\n",
      "1.481012658227848\t\"RESUMES\"\n",
      "1.4808743169398908\t\"herede\"\n",
      "1.480357142857143\t\"Vide\"\n",
      "1.48\t\"Avantgarde\"\n",
      "1.4790419161676647\t\"CATTERMOLE\"\n",
      "1.4786324786324787\t\"Manshu\"\n",
      "1.4786324786324787\t\"kaisha\"\n",
      "1.4786324786324787\t\"tetsudo\"\n",
      "1.4786324786324787\t\"kabushiki\"\n",
      "1.4785714285714286\t\"loumal\"\n",
      "1.4782608695652173\t\"flavicollis\"\n",
      "1.4782608695652173\t\"Kalotermes\"\n",
      "1.4782608695652173\t\"Choudhry\"\n",
      "1.4782608695652173\t\"Moorad\"\n",
      "1.4782608695652173\t\"Termite\"\n",
      "1.4774980930587338\t\"Tu\"\n",
      "1.4761904761904763\t\"Moraba\"\n",
      "1.476027397260274\t\"emendata\"\n",
      "1.4759825327510918\t\"Coverdell\"\n",
      "1.475177304964539\t\"GLAZE\"\n",
      "1.475\t\"Cusps\"\n",
      "1.4745529573590097\t\"Azincourt\"\n",
      "1.4741935483870967\t\"Turneaure's\"\n",
      "1.473529411764706\t\"SPE\"\n",
      "1.472972972972973\t\"Embalmed\"\n",
      "1.472972972972973\t\"Urheberrecht\"\n",
      "1.4728571428571429\t\"PENR\"\n",
      "1.4728571428571429\t\"PAGANO\"\n",
      "1.4727272727272727\t\"harmoniser\"\n",
      "1.4727272727272727\t\"YOZAN\"\n",
      "1.4723926380368098\t\"Viticultural\"\n",
      "1.4723404255319148\t\"Mendeleev\"\n",
      "1.4712041884816753\t\"Gig\"\n",
      "1.4695259593679457\t\"Vasc\"\n",
      "1.4695259593679457\t\"Endovasc\"\n",
      "1.4690265486725664\t\"herpetology\"\n",
      "1.4688686408504177\t\"KIVIE\"\n",
      "1.4680851063829787\t\"ROUTINE\"\n",
      "1.4678899082568808\t\"Innocently\"\n",
      "1.4678228165482659\t\"Respir\"\n",
      "1.467032967032967\t\"TODD\"\n",
      "1.466992665036675\t\"Outdoors\"\n",
      "1.4666666666666666\t\"parc\"\n",
      "1.4666666666666666\t\"geta\"\n",
      "1.4659090909090908\t\"CRUSH\"\n",
      "1.4655172413793103\t\"Anni\"\n",
      "1.4651162790697674\t\"metaphosphoric\"\n",
      "1.4649122807017543\t\"Yeb\"\n",
      "1.4646464646464648\t\"epiphysiolysis\"\n",
      "1.4646017699115044\t\"TSCA\"\n",
      "1.4644194756554307\t\"Willebois\"\n",
      "1.463855421686747\t\"Politieke\"\n",
      "1.463768115942029\t\"Cadran\"\n",
      "1.4636363636363636\t\"Thacher\"\n",
      "1.4636363636363636\t\"obiit\"\n",
      "1.4631357207342763\t\"SIDNEY\"\n",
      "1.4630872483221478\t\"Endophthalmitis\"\n",
      "1.4628297362110312\t\"Fanfare\"\n",
      "1.4625\t\"diversicolor\"\n",
      "1.4623655913978495\t\"Chicorel\"\n",
      "1.4615384615384615\t\"Paddock's\"\n",
      "1.4615384615384615\t\"Cygni\"\n",
      "1.4615384615384615\t\"Explode\"\n",
      "1.4612546125461254\t\"GROSSMAN\"\n",
      "1.4607843137254901\t\"Alimentos\"\n",
      "1.4606741573033708\t\"Yonson\"\n",
      "1.4602076124567474\t\"BARTHOLOMEW\"\n",
      "1.4588235294117646\t\"Jumps\"\n",
      "1.4583333333333333\t\"Ultracentrifugation\"\n",
      "1.4583333333333333\t\"literaturas\"\n",
      "1.4580152671755726\t\"Ihram\"\n",
      "1.4578005115089514\t\"Gethsemani\"\n",
      "1.4577259475218658\t\"Alinari\"\n",
      "1.457543281121187\t\"betroth\"\n",
      "1.4566929133858268\t\"Vaasa\"\n",
      "1.4565217391304348\t\"homocytotropic\"\n",
      "1.4563881043362685\t\"Enteral\"\n",
      "1.4563106796116505\t\"Succulents\"\n",
      "1.456140350877193\t\"bolshevism\"\n",
      "1.456\t\"Tathagatas\"\n",
      "1.455621301775148\t\"Tiong\"\n",
      "1.4546952224052718\t\"Historiador\"\n",
      "1.4545454545454546\t\"Dharmaraksa\"\n",
      "1.4532019704433496\t\"Magn\"\n",
      "1.4526315789473685\t\"Verhal\"\n",
      "1.4523809523809523\t\"Demoniacks\"\n",
      "1.4517709957674314\t\"GRAMMAR\"\n",
      "1.4503937007874015\t\"Petrochemical\"\n",
      "1.45016077170418\t\"officia\"\n",
      "1.45\t\"stercoraria\"\n",
      "1.45\t\"TRIBUNALS\"\n",
      "1.4496644295302012\t\"oldkyndighed\"\n",
      "1.4482758620689655\t\"Rappard\"\n",
      "1.448051948051948\t\"buffler\"\n",
      "1.4475138121546962\t\"Mesnil\"\n",
      "1.4470588235294117\t\"Axworthy\"\n",
      "1.4464285714285714\t\"Frankiel\"\n",
      "1.4464285714285714\t\"Greenfeld\"\n",
      "1.4462809917355373\t\"Brieg\"\n",
      "1.4462540716612378\t\"candesartan\"\n",
      "1.4461966604823748\t\"Moncton\"\n",
      "1.4461538461538461\t\"Sarig\"\n",
      "1.4461538461538461\t\"Roni\"\n",
      "1.4461538461538461\t\"warranta\"\n",
      "1.4454545454545455\t\"Koyane\"\n",
      "1.4453125\t\"Americanised\"\n",
      "1.4452054794520548\t\"noncontiguous\"\n",
      "1.4444444444444444\t\"Dodonov\"\n",
      "1.4444444444444444\t\"Shostak\"\n",
      "1.4444444444444444\t\"Gomberg\"\n",
      "1.4440959912735205\t\"Seismological\"\n",
      "1.4438502673796791\t\"Geologica\"\n",
      "1.443298969072165\t\"Groveton\"\n",
      "1.443254817987152\t\"Sphingolipid\"\n",
      "1.4430538172715894\t\"HMSO\"\n",
      "1.4430379746835442\t\"Aveiro\"\n",
      "1.4428571428571428\t\"Observes\"\n",
      "1.44279176201373\t\"SD\"\n",
      "1.4426229508196722\t\"MALES\"\n",
      "1.4423076923076923\t\"ACCELERATED\"\n",
      "1.4416243654822336\t\"ametropia\"\n",
      "1.4411764705882353\t\"Cavities\"\n",
      "1.4409722222222223\t\"Assayer\"\n",
      "1.4408945686900958\t\"HHI\"\n",
      "1.4406779661016949\t\"Sanga\"\n",
      "1.4403669724770642\t\"JUMPS\"\n",
      "1.4401041666666667\t\"Timaru\"\n",
      "1.4397163120567376\t\"Suppliant\"\n",
      "1.4390243902439024\t\"nutbrown\"\n",
      "1.4384615384615385\t\"bechance\"\n",
      "1.4383561643835616\t\"Hondureno\"\n",
      "1.4375\t\"Mansell\"\n",
      "1.4375\t\"CAUALLERO\"\n",
      "1.4375\t\"ZIFAR\"\n",
      "1.4374778604321643\t\"Th\"\n",
      "1.4372093023255814\t\"Sinusoidal\"\n",
      "1.4369747899159664\t\"vueil\"\n",
      "1.4366197183098592\t\"nonmelanocytic\"\n",
      "1.4363636363636363\t\"responsiones\"\n",
      "1.4363636363636363\t\"Augustino\"\n",
      "1.4362969752520622\t\"POSTAGE\"\n",
      "1.436105476673428\t\"benzol\"\n",
      "1.435897435897436\t\"hait\"\n",
      "1.4357798165137614\t\"Envelopes\"\n",
      "1.4356435643564356\t\"CANR\"\n",
      "1.435483870967742\t\"Nonpeptide\"\n",
      "1.435483870967742\t\"Gorlach\"\n",
      "1.4352119094637703\t\"unsigned\"\n",
      "1.4349442379182156\t\"Republished\"\n",
      "1.4342322032428683\t\"thankfully\"\n",
      "1.4342105263157894\t\"DIALECTIC\"\n",
      "1.4339622641509433\t\"Falconara\"\n",
      "1.4339622641509433\t\"Camarines\"\n",
      "1.4339622641509433\t\"Parapsychological\"\n",
      "1.4339622641509433\t\"Lundensia\"\n",
      "1.4339622641509433\t\"Archaeologica\"\n",
      "1.4337349397590362\t\"Morskogo\"\n",
      "1.4336283185840708\t\"MCCARTHY\"\n",
      "1.4328621908127208\t\"subduplicate\"\n",
      "1.4328358208955223\t\"balanoides\"\n",
      "1.4328358208955223\t\"Balanus\"\n",
      "1.4328358208955223\t\"Culham\"\n",
      "1.4323232323232322\t\"OSA\"\n",
      "1.4320388349514563\t\"dogstar\"\n",
      "1.4319526627218935\t\"cavernes\"\n",
      "1.4319444444444445\t\"eft\"\n",
      "1.4318181818181819\t\"HRAFlex\"\n",
      "1.4317825405122844\t\"Outlay\"\n",
      "1.430939226519337\t\"Brustein\"\n",
      "1.4309178743961353\t\"Wycliffite\"\n",
      "1.430622009569378\t\"Tiss\"\n",
      "1.4305555555555556\t\"pluye\"\n",
      "1.4305555555555556\t\"froidure\"\n",
      "1.4301470588235294\t\"Monogr\"\n",
      "1.4294975688816856\t\"Folder\"\n",
      "1.4289710208714588\t\"yes\"\n",
      "1.4285714285714286\t\"canso\"\n",
      "1.4285714285714286\t\"constantem\"\n",
      "1.4285714285714286\t\"sithen\"\n",
      "1.4285714285714286\t\"Disapprove\"\n",
      "1.4285714285714286\t\"Conical\"\n",
      "1.4285714285714286\t\"Pratyekabuddhas\"\n",
      "1.4282700421940928\t\"Virchows\"\n",
      "1.4275618374558303\t\"Pushpa\"\n",
      "1.4273504273504274\t\"farden\"\n",
      "1.4270531400966184\t\"Anal\"\n",
      "1.425531914893617\t\"Irrigators\"\n",
      "1.425531914893617\t\"cypionate\"\n",
      "1.4253731343283582\t\"JLG\"\n",
      "1.4253731343283582\t\"Forense\"\n",
      "1.425\t\"liberatio\"\n",
      "1.4245283018867925\t\"juridictions\"\n",
      "1.4239244491080798\t\"OUTLAY\"\n",
      "1.423841059602649\t\"slumber's\"\n",
      "1.423728813559322\t\"tribewn\"\n",
      "1.4230769230769231\t\"aith\"\n",
      "1.4230769230769231\t\"Cullian\"\n",
      "1.4230769230769231\t\"Kelleram\"\n",
      "1.4225806451612903\t\"pseudarthrosis\"\n",
      "1.422343324250681\t\"ICs\"\n",
      "1.4222972972972974\t\"achylia\"\n",
      "1.4222222222222223\t\"Pursuivants\"\n",
      "1.4220183486238531\t\"ALR\"\n",
      "1.4220183486238531\t\"Electrocatalysis\"\n",
      "1.4216867469879517\t\"Basicranium\"\n",
      "1.4216867469879517\t\"pilage\"\n",
      "1.4215686274509804\t\"Powerscourt\"\n",
      "1.421383647798742\t\"Dioxygen\"\n",
      "1.4210526315789473\t\"Christlich\"\n",
      "1.420807453416149\t\"Supracondylar\"\n",
      "1.420183486238532\t\"nontransitory\"\n",
      "1.4201497735980495\t\"LA\"\n",
      "1.42\t\"Colleer\"\n",
      "1.42\t\"Acholeplasma\"\n",
      "1.4195402298850575\t\"fascismo\"\n",
      "1.419431279620853\t\"caske\"\n",
      "1.4193548387096775\t\"Khok\"\n",
      "1.4193194291986828\t\"minim\"\n",
      "1.4191919191919191\t\"Burgher\"\n",
      "1.4190193164933136\t\"carryovers\"\n",
      "1.4189189189189189\t\"Peintures\"\n",
      "1.4188235294117648\t\"VICTORIA\"\n",
      "1.4188034188034189\t\"iDisk\"\n",
      "1.4183006535947713\t\"melanocytoma\"\n",
      "1.418200408997955\t\"Prematurity\"\n",
      "1.4181818181818182\t\"HARVEY'S\"\n",
      "1.4178921568627452\t\"NARA\"\n",
      "1.4173228346456692\t\"grossier\"\n",
      "1.4166666666666667\t\"postsubiculum\"\n",
      "1.4166666666666667\t\"Prets\"\n",
      "1.4166666666666667\t\"Escompte\"\n",
      "1.4166666666666667\t\"Klundert\"\n",
      "1.4161490683229814\t\"counterpositive\"\n",
      "1.4157303370786516\t\"gzhi\"\n",
      "1.415680473372781\t\"Serv\"\n",
      "1.4156626506024097\t\"Dermatomal\"\n",
      "1.4153846153846155\t\"rereward\"\n",
      "1.4152046783625731\t\"jostice\"\n",
      "1.4152046783625731\t\"plet\"\n",
      "1.4148936170212767\t\"locomotory\"\n",
      "1.4146341463414633\t\"ANCHORA\"\n",
      "1.4145077720207253\t\"CCPCC\"\n",
      "1.4138461538461538\t\"HUNTER\"\n",
      "1.4137931034482758\t\"Quasars\"\n",
      "1.4137931034482758\t\"Commonality\"\n",
      "1.4137205603160756\t\"Soc\"\n",
      "1.4131274131274132\t\"Econ\"\n",
      "1.4130434782608696\t\"grotches\"\n",
      "1.4130434782608696\t\"pallial\"\n",
      "1.4130434782608696\t\"voods\"\n",
      "1.4125\t\"Contempory\"\n",
      "1.4125\t\"Combattimento\"\n",
      "1.4118993135011442\t\"Occurs\"\n",
      "1.411764705882353\t\"Oogenesis\"\n",
      "1.4115755627009647\t\"gastrica\"\n",
      "1.4114852762851962\t\"Yes\"\n",
      "1.4113475177304964\t\"presentada\"\n",
      "1.4112903225806452\t\"WPK\"\n",
      "1.4111111111111112\t\"sectionized\"\n",
      "1.4109589041095891\t\"Deliberazioni\"\n",
      "1.4107275133881407\t\"Per\"\n",
      "1.4103269172013444\t\"Geelong\"\n",
      "1.4098360655737705\t\"BERE\"\n",
      "1.4098360655737705\t\"BAGHOT\"\n",
      "1.4098360655737705\t\"Neuvieme\"\n",
      "1.4098360655737705\t\"lnc\"\n",
      "1.4095744680851063\t\"plantagineum\"\n",
      "1.4094076655052266\t\"nonadverse\"\n",
      "1.4091176470588236\t\"Bourke\"\n",
      "1.4090909090909092\t\"Informazioni\"\n",
      "1.4090909090909092\t\"lookahead\"\n",
      "1.4090909090909092\t\"mul\"\n",
      "1.4088888888888889\t\"McGrade\"\n",
      "1.408856183836819\t\"interrogatory\"\n",
      "1.4086956521739131\t\"vocalics\"\n",
      "1.408450704225352\t\"Ance\"\n",
      "1.4083769633507854\t\"Biotelemetry\"\n",
      "1.4083094555873925\t\"Evol\"\n",
      "1.4081632653061225\t\"CFC's\"\n",
      "1.4081632653061225\t\"Lilawati\"\n",
      "1.4070524787388508\t\"Lecture\"\n",
      "1.4069767441860466\t\"unassembled\"\n",
      "1.4069592263206492\t\"Agreed\"\n",
      "1.4067796610169492\t\"Norraikow\"\n",
      "1.40625\t\"Kiukiang\"\n",
      "1.4062362758014932\t\"Assoc\"\n",
      "1.4059405940594059\t\"Beltwide\"\n",
      "1.4059405940594059\t\"MATILDE\"\n",
      "1.4057142857142857\t\"neurula\"\n",
      "1.4055555555555554\t\"organi\"\n",
      "1.4054054054054055\t\"JUMPED\"\n",
      "1.4054054054054055\t\"Schillebeeckx\"\n",
      "1.4051724137931034\t\"Inj\"\n",
      "1.4050632911392404\t\"Clennams\"\n",
      "1.4049586776859504\t\"Trenartha\"\n",
      "1.4048442906574394\t\"coparcener\"\n",
      "1.4038117165515478\t\"Cent\"\n",
      "1.4036697247706422\t\"Opt\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd hw5\n",
      "+ prog=hw5.3-3\n",
      "+ hdfs=hdfs://master:9000\n",
      "+ input=hdfs://master:9000/filtered-5grams\n",
      "+ output=hdfs://master:9000/hw5.3-3-output\n",
      "+ head -1000\n",
      "+ hdfs dfs -cat 'hdfs://master:9000/hw5.3-3-output/*'\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/bin/ssh root@50.22.252.4 bash -xs <<'EOF'\n",
    "cd hw5\n",
    "prog=hw5.3-3\n",
    "hdfs=hdfs://master:9000\n",
    "input=$hdfs/filtered-5grams\n",
    "output=$hdfs/$prog-output\n",
    "HADOOP_ROOT_LOGGER=WARN,console\n",
    "hdfs dfs -rm -r -f $output\n",
    "time ./$prog.py -q -r hadoop --no-bootstrap-mrjob \\\n",
    "  --no-output --output $output \\\n",
    "  $input\n",
    "hdfs dfs -cat ${output}/* | head -1000\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.4  (over 2Gig of Data)\n",
    "In this part of the assignment we will focus on developing methods\n",
    "for detecting synonyms, using the Google 5-grams dataset. To accomplish\n",
    "this you must script two main tasks using MRJob:\n",
    "\n",
    "1. Build stripes for the most frequent 10,000 words using cooccurence informationa based on\n",
    "the words ranked from 1001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "1. Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "**Design notes for (1)**:  \n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "```\n",
    "<word,count>\n",
    "```\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: `(word1,word2)`, and `(word2,word1)`, to preserve\n",
    "symmetry in our output for (2).\n",
    "\n",
    "**Design notes for (2)**:  \n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "* Jaccard\n",
    "* Cosine similarity\n",
    "* Spearman correlation\n",
    "* Euclidean distance\n",
    "* Taxicab (Manhattan) distance\n",
    "* Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "* Pearson correlation\n",
    "* Kendall correlation\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw5.4-1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw5.4-1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys\n",
    "\n",
    "class HW54Job(MRJob):\n",
    "    Row=namedtuple('Row',['ngram', 'count', 'pages_count', 'books_count'])\n",
    "    @staticmethod\n",
    "    def split_line(line):\n",
    "        fields=line.strip().split('\\t')\n",
    "        return HW54Job.Row(fields[0],*[int(field) for field in fields[1:]])\n",
    "\n",
    "    \"\"\"Produce the word densities and sort them\"\"\"\n",
    "    def coocurrence_init(self):\n",
    "        # I produced the vocabulary in a prior step, so I don't actually need the\n",
    "        # total counts for ranking/fitlering in the reducer.\n",
    "        with open('hw5.4-terms-1k-10k.txt') as vocab_file:\n",
    "            self.vocab=set(term.strip('\\n\"') for term in vocab_file)\n",
    "    def coocurrence(self, _, line):\n",
    "        \"\"\"Mapper: split the 5-grams, and yield the coocurrence stripes for each.\"\"\"\n",
    "        row=HW54Job.split_line(line)\n",
    "        # here I filter both co-occuring terms to be in rank 1k to rank 10k.\n",
    "        # This corresponds to option \"B\" in the sync session\n",
    "        terms=[term for term in row.ngram.split() if term in self.vocab]\n",
    "        # Since terms dont CO-occur with themselves, I use slices to omit the\n",
    "        # term under consideration from the inner loop(s)\n",
    "        for idx,term in enumerate(terms):\n",
    "            counts=defaultdict(int)\n",
    "            for co in terms[:idx]:\n",
    "                counts[co]+=row.count\n",
    "            for co in terms[idx+1:]:\n",
    "                counts[co]+=row.count\n",
    "            if counts:\n",
    "                yield term, [row.count,counts]\n",
    "    def sum_counts(self, key, values):\n",
    "        \"\"\"Combiner: sum the counts as in usual word count\"\"\"\n",
    "        counts=Counter()\n",
    "        total=0\n",
    "        for value in values:\n",
    "            total+=value[0]\n",
    "            counts.update(value[1])\n",
    "        yield key, [total, counts]\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.coocurrence_init,\n",
    "                mapper=self.coocurrence,\n",
    "                combiner=self.sum_counts,\n",
    "                reducer=self.sum_counts,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "if __name__=='__main__':\n",
    "    HW54Job().run()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> master: Rsyncing folder: /media/sf_berkeley/w261/hw/hw5/hw5/ => /root/hw5\n",
      "==> master: Rsyncing folder: /media/sf_berkeley/w261/hw/hw5/prov/ => /vagrant\n",
      "Deleted hdfs://master:9000/hw5.4-1-output\n",
      "\"ADV\"\t[159, {\"Router\": 159, \"Seq\": 159}]\n",
      "\"Adjutant\"\t[137, {\"Received\": 137}]\n",
      "\"Agronomic\"\t[94, {\"Chania\": 94}]\n",
      "\"Ar\"\t[1944, {\"aq\": 47, \"Tau\": 408, \"Cap\": 448, \"abs\": 47, \"Ar\": 2270}]\n",
      "\"Arxiu\"\t[174, {\"Ciutat\": 174}]\n",
      "\"Beverlacense\"\t[55, {\"Dunelmense\": 55, \"Sanctuarium\": 110}]\n",
      "\"Biosensors\"\t[190, {\"Sensors\": 190}]\n",
      "\"Bowen\"\t[280, {\"J\": 280}]\n",
      "\"Chichimec\"\t[499, {\"Ripples\": 499}]\n",
      "\"Clinics\"\t[18195, {\"Respiratory\": 67, \"Immunology\": 546, \"Nursing\": 156, \"Maxillofacial\": 226, \"Multidisciplinary\": 88, \"Otolaryngologic\": 162, \"Allergy\": 546, \"Anesthesiology\": 244, \"Radiologic\": 1607, \"Gynecology\": 447, \"Radiological\": 273, \"Orthopedic\": 302, \"Pediatric\": 12112, \"Medicine\": 1788, \"Surgery\": 226, \"Metabolic\": 86, \"Obstetrics\": 447, \"Mortality\": 91}]\n",
      "\"Colliding\"\t[99, {\"Instrumentation\": 99, \"Beam\": 99}]\n",
      "\"Constitutio\"\t[53, {\"Criminalis\": 53}]\n",
      "\"Copenhague\"\t[1381, {\"Cercle\": 1381}]\n",
      "\"Croat\"\t[930, {\"Slovene\": 930}]\n",
      "\"Derate\"\t[124, {\"Dissipation\": 124, \"Total\": 124}]\n",
      "\"Dewanee\"\t[86, {\"Adawlut\": 86, \"Sudder\": 86}]\n",
      "\"Diccionarios\"\t[67, {\"Vocabularios\": 67}]\n",
      "\"Easie\"\t[2895, {\"Readie\": 2895}]\n",
      "\"Electrodiagnostic\"\t[688, {\"Medicine\": 688}]\n",
      "\"FEB\"\t[7771, {\"MAR\": 6008, \"MAY\": 6063, \"JUN\": 5929, \"JAN\": 1763, \"APR\": 5929, \"OCT\": 1708}]\n",
      "\"Finanze\"\t[3112, {\"dello\": 3112, \"Amministrazione\": 1768}]\n",
      "\"Fundamentales\"\t[136, {\"Agricultura\": 136, \"Tropical\": 136}]\n",
      "\"Hannum\"\t[290, {\"Hannum\": 290}]\n",
      "\"Hematology\"\t[1332, {\"Medicine\": 112, \"Internal\": 160, \"Pediatric\": 571, \"Oski's\": 489}]\n",
      "\"Hortalez\"\t[106, {\"Roderigue\": 106}]\n",
      "\"Integr\"\t[1994, {\"Regul\": 1994, \"J\": 1994, \"Am\": 1994, \"Physiol\": 1994}]\n",
      "\"Jun\"\t[2893, {\"Ocl\": 212, \"Aug\": 2422, \"Sep\": 395, \"Apr\": 1492, \"Jul\": 1276, \"Nov\": 139, \"Total\": 78, \"Oct\": 1632}]\n",
      "\"Kissa\"\t[99, {\"Kursi\": 99}]\n",
      "\"McDouall's\"\t[226, {\"Journal\": 226}]\n",
      "\"Microbiology\"\t[13395, {\"Immunology\": 10562, \"Chromatography\": 78, \"Journal\": 606, \"Infections\": 412, \"Microbiology\": 116, \"Automation\": 352, \"Cell\": 222, \"Clinical\": 446, \"Health\": 245, \"Medicine\": 472, \"Toxicology\": 208, \"Experimental\": 243}]\n",
      "\"Molar\"\t[225, {\"Molar\": 450}]\n",
      "\"Mushtari\"\t[83, {\"Parwin\": 83}]\n",
      "\"Nadotti\"\t[70, {\"Giuliana\": 70}]\n",
      "\"Nephrology\"\t[261, {\"Medicine\": 65, \"Urology\": 65, \"Nursing\": 51, \"Dialysis\": 145}]\n",
      "\"Number\"\t[103244, {\"Psychology\": 65, \"USA\": 53, \"Percent\": 51833, \"Acres\": 212, \"Internal\": 50, \"Percentage\": 16991, \"IEEE\": 100, \"Phone\": 159, \"Pounds\": 74, \"df\": 418, \"Items\": 68, \"Vehicles\": 63, \"Refractory\": 102, \"Amount\": 2949, \"Printing\": 63, \"Publications\": 60, \"Variance\": 243, \"Shops\": 71, \"Male\": 198, \"Whole\": 501, \"Mean\": 824, \"Colleges\": 106, \"Code\": 75, \"sq\": 98, \"Testing\": 156, \"Number\": 126690, \"Rank\": 1011, \"Marital\": 80, \"Tons\": 58, \"Computer\": 100, \"Registration\": 424, \"Total\": 8129}]\n",
      "\"Oficial\"\t[207, {\"Federacidn\": 85, \"Boletin\": 122, \"Ministerio\": 122}]\n",
      "\"PIARE\"\t[411, {\"LALL\": 525, \"KUREEL\": 411, \"URF\": 297, \"TALIB\": 297}]\n",
      "\"Pambansa\"\t[1454, {\"Batasang\": 1454}]\n",
      "\"Parishads\"\t[760, {\"Samithis\": 760}]\n",
      "\"Passengers\"\t[1488, {\"Luggage\": 1488}]\n",
      "\"Petraglia\"\t[106, {\"MD\": 106}]\n",
      "\"Pichler\"\t[225, {\"Gasparikova\": 225}]\n",
      "\"Pidgin\"\t[2567, {\"Journal\": 2567}]\n",
      "\"Pigmented\"\t[760, {\"Pigmented\": 256, \"villonodular\": 760, \"synovitis\": 461}]\n",
      "\"Prados\"\t[167, {\"Escosura\": 167}]\n",
      "\"Quantities\"\t[248, {\"Materials\": 91, \"Abnormal\": 157}]\n",
      "\"Ravishing\"\t[284, {\"Lol\": 284}]\n",
      "\"Referred\"\t[76, {\"Notes\": 76}]\n",
      "\"Registration\"\t[2466, {\"Register\": 568, \"Forensic\": 147, \"Deeds\": 116, \"Number\": 424, \"Architects\": 267, \"Unification\": 146, \"Cavite\": 124, \"Registration\": 148, \"CAVITE\": 451, \"Dummies\": 150}]\n",
      "\"SAI\"\t[928, {\"NARHARI\": 928, \"PRASAD\": 928, \"SUKHDEO\": 928, \"SHRI\": 928}]\n",
      "\"SIGMOD\"\t[1311, {\"ACM\": 1311}]\n",
      "\"STATUTES\"\t[1384, {\"AFFECTING\": 1384}]\n",
      "\"Sarasin\"\t[406, {\"Rive\": 406}]\n",
      "\"Sponsors\"\t[40, {\"WOMEN'S\": 40}]\n",
      "\"Statistisches\"\t[75, {\"Jahrbuchfur\": 75}]\n",
      "\"Tentang\"\t[91, {\"Dasar\": 91, \"Negara\": 91}]\n",
      "\"Unnamable\"\t[135, {\"Molloy\": 135}]\n",
      "\"Upload\"\t[95, {\"Notes\": 95}]\n",
      "\"Vakil\"\t[143, {\"Brahmananda\": 143}]\n",
      "\"Vaticani\"\t[196, {\"Oecumenici\": 196, \"Sacrosancti\": 196, \"Synodalia\": 196}]\n",
      "\"Vehicular\"\t[405, {\"IEEE\": 405, \"Semiannual\": 78}]\n",
      "\"Veterinary\"\t[21580, {\"Journal\": 8362, \"Residues\": 368, \"Homoeopathic\": 80, \"Services\": 621, \"Clinical\": 420, \"Human\": 315, \"Medicine\": 11276, \"Toxicology\": 93, \"Notes\": 231, \"Experimental\": 65}]\n",
      "\"anos\"\t[877, {\"Asi\": 463, \"menos\": 334, \"pasen\": 463, \"umbral\": 80}]\n",
      "\"cana\"\t[329, {\"azucar\": 329}]\n",
      "\"dissecans\"\t[635, {\"Osteochondritis\": 635}]\n",
      "\"geeigneten\"\t[102, {\"Bekanntmachung\": 102, \"Verhandlungen\": 102}]\n",
      "\"heredibus\"\t[1482, {\"presentes\": 394, \"successoribus\": 679, \"assignatis\": 409}]\n",
      "\"piccola\"\t[81, {\"aree\": 81}]\n",
      "\"revenu\"\t[113, {\"impot\": 113}]\n",
      "\"secretaria\"\t[123, {\"Memoria\": 123}]\n",
      "\"senderos\"\t[691, {\"bifurcan\": 691}]\n",
      "\"septimanas\"\t[158, {\"septimanis\": 158}]\n",
      "\"shutoff\"\t[250, {\"OFF\": 250}]\n",
      "\"soberana\"\t[124, {\"decretos\": 124}]\n",
      "\"stratiform\"\t[85, {\"stratabound\": 85}]\n",
      "\"tratare\"\t[323, {\"reina\": 323}]\n",
      "\"Anat\"\t[678, {\"Klin\": 317, \"Anat\": 294, \"Abt\": 120, \"Physiol\": 504}]\n",
      "\"Audits\"\t[686, {\"Accounts\": 321, \"Health\": 365}]\n",
      "\"Brachionus\"\t[71, {\"calyciflorus\": 71, \"rotifer\": 71}]\n",
      "\"Cap\"\t[4585, {\"Tropical\": 59, \"Cap\": 6188, \"Ar\": 448}]\n",
      "\"Chihuahuense\"\t[367, {\"Sociedad\": 367}]\n",
      "\"Christoph\"\t[424, {\"Hardin\": 424}]\n",
      "\"Courtesy\"\t[3494, {\"Reproduced\": 694, \"Hagley\": 478, \"Journal\": 936, \"Register\": 107, \"Illuminating\": 95, \"Health\": 255, \"Services\": 571, \"Starrett\": 223, \"Bettmann\": 135}]\n",
      "\"Datagrams\"\t[84, {\"Received\": 84}]\n",
      "\"Ditto\"\t[138, {\"Ditto\": 138}]\n",
      "\"ENERGY\"\t[10371, {\"MINISTER\": 2594, \"MINISTRY\": 7777}]\n",
      "\"Equalization\"\t[168, {\"Opportunity\": 168}]\n",
      "\"Forening\"\t[321, {\"Geologisk\": 225, \"Dansk\": 225, \"Meddelelser\": 321}]\n",
      "\"Gayre\"\t[234, {\"Gayre\": 234}]\n",
      "\"Genitourinary\"\t[192, {\"Medicine\": 134, \"Prostatic\": 58}]\n",
      "\"Hiking\"\t[244, {\"Hiking\": 244}]\n",
      "\"Hydroids\"\t[144, {\"Gymnoblastic\": 144, \"Tubularian\": 144}]\n",
      "\"Intraocular\"\t[684, {\"J\": 684, \"Am\": 510}]\n",
      "\"J\"\t[119715, {\"Tse\": 125, \"Plastic\": 81, \"Collected\": 1035, \"Trans\": 1792, \"Reproduced\": 254, \"Symp\": 613, \"Mol\": 14809, \"Pfliigers\": 110, \"VAN\": 357, \"Notes\": 1069, \"Elem\": 191, \"GA\": 44, \"Dis\": 2620, \"Embryo\": 130, \"Reconstr\": 391, \"Crii\": 138, \"Raffel\": 111, \"Pharm\": 114, \"Crit\": 374, \"Sport\": 556, \"Occup\": 1435, \"Commun\": 1681, \"Radiation\": 1057, \"Lond\": 51, \"Sports\": 294, \"Biomater\": 404, \"Appl\": 2962, \"Biomed\": 197, \"Pert\": 130, \"Afr\": 262, \"Infect\": 367, \"Pub\": 154, \"Ion\": 364, \"Abuse\": 2378, \"Mich\": 170, \"Pediatr\": 254, \"Gynaecol\": 2094, \"Integr\": 1994, \"Exp\": 622, \"Biotechnol\": 264, \"inertia\": 1269, \"Chir\": 68, \"Radium\": 5509, \"Hufbauer\": 2822, \"Plast\": 356, \"Physiol\": 12095, \"Clin\": 4622, \"Ophthalmol\": 254, \"Scand\": 5411, \"Cell\": 15956, \"Circ\": 3808, \"Kerkvliet\": 109, \"Internal\": 72, \"Health\": 7207, \"Rad\": 158, \"Eur\": 7155, \"Roentgenol\": 5509, \"Fr\": 68, \"Regul\": 1994, \"Bowen\": 280, \"NZ\": 114, \"Pract\": 195, \"Inst\": 205, \"Amer\": 141, \"Symptom\": 114, \"AFFAIRS\": 82, \"Sourcebook\": 65, \"Microbiol\": 1163, \"J\": 3748, \"CG\": 42, \"Emp\": 1404, \"Introduced\": 51, \"Int\": 13024, \"Motil\": 956, \"McDonald\": 43, \"Lung\": 2133, \"KV\": 111, \"Intraocular\": 684, \"Allergy\": 161, \"Ment\": 1257, \"Tria\": 109, \"Indust\": 105, \"Nucl\": 8034, \"Subchapter\": 72, \"MINISTER\": 44, \"IEEE\": 44, \"Anim\": 137, \"Chromatography\": 62, \"Endocrinol\": 154, \"Syst\": 1006, \"Pollut\": 382, \"Ther\": 8400, \"Gastrointest\": 2018, \"Forensic\": 2343, \"MINES\": 278, \"Ortho\": 145, \"Environ\": 5395, \"Behav\": 256, \"Radial\": 243, \"Pelvic\": 1270, \"Disord\": 82, \"Am\": 59681, \"Cormier\": 368, \"Immunol\": 452}]\n",
      "\"Jing\"\t[394, {\"Nong\": 269, \"Su\": 125}]\n",
      "\"Kadish\"\t[103, {\"Ruoff\": 103}]\n",
      "\"Landsmal\"\t[68, {\"Folkliv\": 68, \"Svenska\": 68}]\n",
      "\"Lefkandi\"\t[87, {\"Toumba\": 87}]\n",
      "\"Lokalisation\"\t[420, {\"histologischen\": 420, \"Grosshirnrinde\": 209}]\n",
      "\"ME\"\t[4578, {\"ME\": 15240, \"VA\": 97, \"MD\": 193, \"EDWARDS\": 255, \"YS\": 46, \"Reprinted\": 102}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd hw5\n",
      "+ freqs=hdfs://master:9000/hw5.3-3-output\n",
      "+ hdfs dfs -cat 'hdfs://master:9000/hw5.3-3-output/*'\n",
      "+ cut -f2\n",
      "+ head -10000\n",
      "+ tail -9000\n",
      "cat: Unable to write to output stream.\n",
      "+ prog=hw5.4-1\n",
      "+ hdfs=hdfs://master:9000\n",
      "+ input=hdfs://master:9000/filtered-5grams\n",
      "+ output=hdfs://master:9000/hw5.4-1-output\n",
      "+ HADOOP_ROOT_LOGGER=INFO,console\n",
      "+ hdfs dfs -rm -r -f hdfs://master:9000/hw5.4-1-output\n",
      "16/02/18 00:16:05 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\n",
      "+ ./hw5.4-1.py -r hadoop --strict-protocols --no-bootstrap-mrjob --no-output --output hdfs://master:9000/hw5.4-1-output --file hw5.4-terms-1k-10k.txt --hadoop-arg -Dmapreduce.job.maps=56 --hadoop-arg -Dmapreduce.job.reduces=56 hdfs://master:9000/filtered-5grams\n",
      "no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "Using Hadoop version 2.7.2\n",
      "Copying local files into hdfs:///user/root/tmp/mrjob/hw5.root.20160218.061606.405897/files/\n",
      "HADOOP: packageJobJar: [] [/opt/hadoop-2.7.2/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar] /tmp/streamjob7845335100281926203.jar tmpDir=null\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Connecting to ResourceManager at master/10.108.114.214:8032\r\n",
      "HADOOP: Total input paths to process : 190\r\n",
      "HADOOP: number of splits:190\r\n",
      "HADOOP: Submitting tokens for job: job_1455677115242_0055\r\n",
      "HADOOP: Submitted application application_1455677115242_0055\r\n",
      "HADOOP: The url to track the job: http://master:8088/proxy/application_1455677115242_0055/\r\n",
      "HADOOP: Running job: job_1455677115242_0055\r\n",
      "HADOOP: Job job_1455677115242_0055 running in uber mode : false\r\n",
      "HADOOP:  map 0% reduce 0%\r\n",
      "HADOOP:  map 2% reduce 0%\r\n",
      "HADOOP:  map 5% reduce 0%\r\n",
      "HADOOP:  map 11% reduce 0%\r\n",
      "HADOOP:  map 17% reduce 0%\r\n",
      "HADOOP:  map 18% reduce 0%\r\n",
      "HADOOP:  map 19% reduce 0%\r\n",
      "HADOOP:  map 20% reduce 0%\r\n",
      "HADOOP:  map 22% reduce 0%\r\n",
      "HADOOP:  map 24% reduce 0%\r\n",
      "HADOOP:  map 25% reduce 0%\r\n",
      "HADOOP:  map 29% reduce 0%\r\n",
      "HADOOP:  map 31% reduce 0%\r\n",
      "HADOOP:  map 34% reduce 0%\r\n",
      "HADOOP:  map 36% reduce 0%\r\n",
      "HADOOP:  map 39% reduce 0%\r\n",
      "HADOOP:  map 39% reduce 1%\r\n",
      "HADOOP:  map 40% reduce 1%\r\n",
      "HADOOP:  map 41% reduce 1%\r\n",
      "HADOOP:  map 42% reduce 1%\r\n",
      "HADOOP:  map 43% reduce 1%\r\n",
      "HADOOP:  map 46% reduce 2%\r\n",
      "HADOOP:  map 46% reduce 3%\r\n",
      "HADOOP:  map 48% reduce 4%\r\n",
      "HADOOP:  map 49% reduce 4%\r\n",
      "HADOOP:  map 51% reduce 4%\r\n",
      "HADOOP:  map 52% reduce 5%\r\n",
      "HADOOP:  map 55% reduce 5%\r\n",
      "HADOOP:  map 56% reduce 6%\r\n",
      "HADOOP:  map 57% reduce 6%\r\n",
      "HADOOP:  map 58% reduce 7%\r\n",
      "HADOOP:  map 59% reduce 8%\r\n",
      "HADOOP:  map 60% reduce 8%\r\n",
      "HADOOP:  map 61% reduce 8%\r\n",
      "HADOOP:  map 62% reduce 8%\r\n",
      "HADOOP:  map 65% reduce 9%\r\n",
      "HADOOP:  map 66% reduce 9%\r\n",
      "HADOOP:  map 67% reduce 10%\r\n",
      "HADOOP:  map 69% reduce 10%\r\n",
      "HADOOP:  map 70% reduce 10%\r\n",
      "HADOOP:  map 71% reduce 10%\r\n",
      "HADOOP:  map 72% reduce 10%\r\n",
      "HADOOP:  map 73% reduce 11%\r\n",
      "HADOOP:  map 74% reduce 11%\r\n",
      "HADOOP:  map 74% reduce 12%\r\n",
      "HADOOP:  map 75% reduce 12%\r\n",
      "HADOOP:  map 76% reduce 12%\r\n",
      "HADOOP:  map 78% reduce 12%\r\n",
      "HADOOP:  map 79% reduce 12%\r\n",
      "HADOOP:  map 81% reduce 12%\r\n",
      "HADOOP:  map 82% reduce 12%\r\n",
      "HADOOP:  map 84% reduce 12%\r\n",
      "HADOOP:  map 85% reduce 12%\r\n",
      "HADOOP:  map 86% reduce 13%\r\n",
      "HADOOP:  map 87% reduce 13%\r\n",
      "HADOOP:  map 88% reduce 13%\r\n",
      "HADOOP:  map 88% reduce 14%\r\n",
      "HADOOP:  map 89% reduce 14%\r\n",
      "HADOOP:  map 91% reduce 14%\r\n",
      "HADOOP:  map 93% reduce 14%\r\n",
      "HADOOP:  map 94% reduce 14%\r\n",
      "HADOOP:  map 95% reduce 14%\r\n",
      "HADOOP:  map 97% reduce 14%\r\n",
      "HADOOP:  map 97% reduce 15%\r\n",
      "HADOOP:  map 98% reduce 15%\r\n",
      "HADOOP:  map 99% reduce 15%\r\n",
      "HADOOP:  map 99% reduce 16%\r\n",
      "HADOOP:  map 100% reduce 18%\r\n",
      "HADOOP:  map 100% reduce 19%\r\n",
      "HADOOP:  map 100% reduce 34%\r\n",
      "HADOOP:  map 100% reduce 86%\r\n",
      "HADOOP:  map 100% reduce 93%\r\n",
      "HADOOP:  map 100% reduce 98%\r\n",
      "HADOOP:  map 100% reduce 100%\r\n",
      "HADOOP: Job job_1455677115242_0055 completed successfully\r\n",
      "HADOOP: Counters: 53\r\n",
      "HADOOP: \tFile System Counters\r\n",
      "HADOOP: \t\tFILE: Number of bytes read=681099\r\n",
      "HADOOP: \t\tFILE: Number of bytes written=31550684\r\n",
      "HADOOP: \t\tFILE: Number of read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of large read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of write operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of bytes read=2156095226\r\n",
      "HADOOP: \t\tHDFS: Number of bytes written=226669\r\n",
      "HADOOP: \t\tHDFS: Number of read operations=738\r\n",
      "HADOOP: \t\tHDFS: Number of large read operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of write operations=112\r\n",
      "HADOOP: \tJob Counters \r\n",
      "HADOOP: \t\tKilled map tasks=1\r\n",
      "HADOOP: \t\tKilled reduce tasks=1\r\n",
      "HADOOP: \t\tLaunched map tasks=190\r\n",
      "HADOOP: \t\tLaunched reduce tasks=56\r\n",
      "HADOOP: \t\tOther local map tasks=2\r\n",
      "HADOOP: \t\tData-local map tasks=187\r\n",
      "HADOOP: \t\tRack-local map tasks=1\r\n",
      "HADOOP: \t\tTotal time spent by all maps in occupied slots (ms)=2996125\r\n",
      "HADOOP: \t\tTotal time spent by all reduces in occupied slots (ms)=1889011\r\n",
      "HADOOP: \t\tTotal time spent by all map tasks (ms)=2996125\r\n",
      "HADOOP: \t\tTotal time spent by all reduce tasks (ms)=1889011\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all map tasks=2996125\r\n",
      "HADOOP: \t\tTotal vcore-milliseconds taken by all reduce tasks=1889011\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all map tasks=3068032000\r\n",
      "HADOOP: \t\tTotal megabyte-milliseconds taken by all reduce tasks=1934347264\r\n",
      "HADOOP: \tMap-Reduce Framework\r\n",
      "HADOOP: \t\tMap input records=58682266\r\n",
      "HADOOP: \t\tMap output records=22921\r\n",
      "HADOOP: \t\tMap output bytes=840755\r\n",
      "HADOOP: \t\tMap output materialized bytes=744603\r\n",
      "HADOOP: \t\tInput split bytes=26110\r\n",
      "HADOOP: \t\tCombine input records=22921\r\n",
      "HADOOP: \t\tCombine output records=15415\r\n",
      "HADOOP: \t\tReduce input groups=3557\r\n",
      "HADOOP: \t\tReduce shuffle bytes=744603\r\n",
      "HADOOP: \t\tReduce input records=15415\r\n",
      "HADOOP: \t\tReduce output records=3557\r\n",
      "HADOOP: \t\tSpilled Records=30830\r\n",
      "HADOOP: \t\tShuffled Maps =10640\r\n",
      "HADOOP: \t\tFailed Shuffles=0\r\n",
      "HADOOP: \t\tMerged Map outputs=10640\r\n",
      "HADOOP: \t\tGC time elapsed (ms)=38502\r\n",
      "HADOOP: \t\tCPU time spent (ms)=657200\r\n",
      "HADOOP: \t\tPhysical memory (bytes) snapshot=60454170624\r\n",
      "HADOOP: \t\tVirtual memory (bytes) snapshot=523736563712\r\n",
      "HADOOP: \t\tTotal committed heap usage (bytes)=45622493184\r\n",
      "HADOOP: \tShuffle Errors\r\n",
      "HADOOP: \t\tBAD_ID=0\r\n",
      "HADOOP: \t\tCONNECTION=0\r\n",
      "HADOOP: \t\tIO_ERROR=0\r\n",
      "HADOOP: \t\tWRONG_LENGTH=0\r\n",
      "HADOOP: \t\tWRONG_MAP=0\r\n",
      "HADOOP: \t\tWRONG_REDUCE=0\r\n",
      "HADOOP: \tFile Input Format Counters \r\n",
      "HADOOP: \t\tBytes Read=2156069116\r\n",
      "HADOOP: \tFile Output Format Counters \r\n",
      "HADOOP: \t\tBytes Written=226669\r\n",
      "HADOOP: Output directory: hdfs://master:9000/hw5.4-1-output\r\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "deleting hdfs:///user/root/tmp/mrjob/hw5.root.20160218.061606.405897 from HDFS\n",
      "\n",
      "real\t1m58.853s\n",
      "user\t0m22.961s\n",
      "sys\t0m1.442s\n",
      "+ hdfs dfs -cat 'hdfs://master:9000/hw5.4-1-output/*'\n",
      "+ head -100\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "(cd ../prov; vagrant rsync master)\n",
    "/usr/bin/ssh root@50.22.252.4 bash -xs <<'EOF'\n",
    "cd hw5\n",
    "freqs=hdfs://master:9000/hw5.3-3-output\n",
    "hdfs dfs -cat ${freqs}/\\* | cut -f2 | head -10000 | tail -9000 > hw5.4-terms-1k-10k.txt\n",
    "\n",
    "prog=hw5.4-1\n",
    "hdfs=hdfs://master:9000\n",
    "input=${hdfs}/filtered-5grams\n",
    "output=${hdfs}/${prog}-output\n",
    "HADOOP_ROOT_LOGGER=INFO,console\n",
    "hdfs dfs -rm -r -f ${output}\n",
    "time ./${prog}.py -r hadoop \\\n",
    "  --strict-protocols --no-bootstrap-mrjob \\\n",
    "  --no-output --output ${output} \\\n",
    "  --file  hw5.4-terms-1k-10k.txt \\\n",
    "  --hadoop-arg -Dmapreduce.job.maps=56 \\\n",
    "  --hadoop-arg -Dmapreduce.job.reduces=56 \\\n",
    "  ${input}\n",
    "hdfs dfs -cat ${output}/\\* | head -100\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile hw5.4-2.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.protocol import JSONProtocol\n",
    "import sys\n",
    "\n",
    "class HW54Job(MRJob):\n",
    "    \"\"\"Compare words using coocurrences\"\"\"\n",
    "    def coocurrence_init(self):\n",
    "        self.seen=set()\n",
    "    def coocurrence(self, key, stripe):\n",
    "        \"\"\"Mapper: yield each member of the stripe\"\"\"\n",
    "        for co in stripe[1]:\n",
    "            # if we have seen this word as a key already,\n",
    "            # \n",
    "            if co not in self.seen:\n",
    "                yield co, [key, stripe[1]]\n",
    "        yield ' ', [key, stripe[1]]\n",
    "        self.seen.add(key)\n",
    "            \n",
    "    def sum_counts(self, key, values):\n",
    "        \"\"\"Combiner: sum the counts as in usual word count\"\"\"\n",
    "        counts=Counter()\n",
    "        total=0\n",
    "        for value in values:\n",
    "            total+=value[0]\n",
    "            counts.update(value[1])\n",
    "        yield key, [total, counts]\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.coocurrence_init,\n",
    "                mapper=self.coocurrence,\n",
    "                combiner=self.sum_counts,\n",
    "                reducer=self.sum_counts,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "if __name__=='__main__':\n",
    "    HW54Job().run()\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'a', 'cc', 'z']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['a', 'z', 'cc', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "(cd ../prov; vagrant rsync master)\n",
    "/usr/bin/ssh root@50.22.252.4 bash -xs <<'EOF'\n",
    "cd hw5\n",
    "prog=hw5.4-2\n",
    "hdfs=hdfs://master:9000\n",
    "input=${hdfs}/hw5.4-1-output\n",
    "output=${hdfs}/${prog}-output\n",
    "HADOOP_ROOT_LOGGER=INFO,console\n",
    "hdfs dfs -rm -r -f ${output}\n",
    "time ./${prog}.py -r hadoop \\\n",
    "  --strict-protocols --no-bootstrap-mrjob \\\n",
    "  --no-output --output ${output} \\\n",
    "  --file  hw5.4-terms-1k-10k.txt \\\n",
    "  --hadoop-arg -Dmapreduce.job.maps=56 \\\n",
    "  --hadoop-arg -Dmapreduce.job.reduces=56 \\\n",
    "  ${input}\n",
    "hdfs dfs -cat ${output}/\\* | head -100\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.5\n",
    "In this part of the assignment you will evaluate the success of you synonym detector.\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined\n",
    "by your measure in (2), and use the synonyms function in the accompanying\n",
    "python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with `nltk.download()`.\n",
    "\n",
    "For each `(word1,word2)` pair,\n",
    "* check to see if `word1` is in the list, \n",
    "`synonyms(word2)`, and vice-versa.\n",
    "* If one of the two is a synonym of the other, then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of your detector across your 1,000 best guesses.\n",
    "* Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.5.1 (optional)\n",
    "There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "```\n",
    ">> from nltk.corpus import stopwords\n",
    ">>> stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW 5.6 (optional)\n",
    "There are many good ways to build our synonym detectors, so for optional homework, \n",
    "measure co-occurrence by (left/right/all) consecutive words only, \n",
    "or make stripes according to word co-occurrences with the accompanying \n",
    "2-, 3-, or 4-grams (note here that your output will no longer \n",
    "be interpretable as a network) inside of the 5-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Hw 5.7 (optional)\n",
    "Once again, benchmark your top 10,000 associations (as in 5.5), this time for your\n",
    "results from 5.6. Has your detector improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
