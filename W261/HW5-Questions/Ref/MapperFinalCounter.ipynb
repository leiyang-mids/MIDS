{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This is a wordcount to show the usage of counter in mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write some words to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo foo foo quux labs foo bar quux > WordCount.txt\n",
    "!echo fodd fodo quuxa labs foo bar quux >> WordCount.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MrJob class for Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mr_wc_counter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mr_wc_counter.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRJobStep\n",
    "import re\n",
    " \n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRWordFreqCount(MRJob):\n",
    "    def init_get_words(self):\n",
    "        self.words = {}\n",
    "\n",
    "    def get_words(self, _, line):\n",
    "        self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "        for word in WORD_RE.findall(line):\n",
    "            word = word.lower()\n",
    "            self.words.setdefault(word, 0)\n",
    "            self.words[word] = self.words[word] + 1\n",
    "\n",
    "    def final_get_words(self):\n",
    "        self.increment_counter('group', 'Num_mapper_final_calls', 1)\n",
    "        for word, val in self.words.iteritems():\n",
    "            yield word, val\n",
    "\n",
    "    def sum_words_combiner(self, word, counts):\n",
    "        self.increment_counter('group', 'Num_combiner_calls', 1)\n",
    "        yield word, sum(counts)\n",
    "        \n",
    "    def sum_words(self, word, counts):\n",
    "        self.increment_counter('group', 'Num_reducer_calls', 1)\n",
    "        yield word, sum(counts)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper_init=self.init_get_words,\n",
    "                       mapper=self.get_words,\n",
    "                       mapper_final=self.final_get_words,\n",
    "                       combiner=self.sum_words_combiner,\n",
    "                       reducer=self.sum_words)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is straightforward. Mapper outputs (word, 1) key value pairs, and then conbiner combines the sum locally. At last, Reducer sums them up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code through python driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reminder: You cannot use the programmatic runner functionality in the same file as your job class. That is because the file with the job class is sent to Hadoop to be run. Therefore, the job file cannot attempt to start the Hadoop job, or you would be recursively creating Hadoop jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use make_runner() to run an MRJob\n",
    "1. seperate driver from mapreduce jobs\n",
    "2. now we can run it within pythonnode book \n",
    "3. In python, typically one class is in each file. Each mrjob job is a seperate class, should be in a seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'group': {'Num_combiner_calls': 7, 'Num_mapper_calls': 2, 'Num_reducer_calls': 7, 'Num_mapper_final_calls': 1}}]\n"
     ]
    }
   ],
   "source": [
    "from mr_wc_counter import MRWordFreqCount\n",
    "mr_job = MRWordFreqCount(args=['WordCount.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    print runner.counters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
