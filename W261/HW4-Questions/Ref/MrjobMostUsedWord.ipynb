{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write some words to MostUsedWord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/jshanahan/Dropbox/Lectures-UC-Berkeley-ML-Class-2015/Slides/Lecture-04-ClusteringInMrJob/MrJob/MrJobIntroJobs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo foo foo quux labs foo bar quux > MostUsedWord.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append some more records to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo New line by Jimi >> MostUsedWord.txt\n",
    "!echo New line by Jimi 2222222 >> MostUsedWord.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the code of MrJob class for Most frequent/used Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Mostused.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Mostused.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "#    OUTPUT_PROTOCOL = JSONValueProtocol\n",
    "    SORT_VALUES = True\n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(MRMostUsedWord, self).jobconf()        \n",
    "        custom_jobconf = {  #key value pairs\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2nr',\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "    def steps(self):  #pipeline of Map-Reduce jobs\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,       # STEP 1: word count step\n",
    "                    combiner=self.combiner_count_words,\n",
    "                    reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word) # Step 2: most frequent word\n",
    "        ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code has two mapreduce. The first Mapreduce Mapper outputs (word, 1) key value pairs, and then the combiner combines the sum locally. Lastly, Reducer sums them up. The second mapreduce output the word having max number of count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/leiyang/.mrjob.conf\n",
      "creating tmp directory /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/Mostused.leiyang.20160206.052002.975302\n",
      "writing wrapper script to /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/Mostused.leiyang.20160206.052002.975302/setup-wrapper.sh\n",
      "Traceback (most recent call last):\n",
      "  File \"Mostused.py\", line 53, in <module>\n",
      "    MRMostUsedWord.run()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 461, in run\n",
      "    mr_job.execute()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/job.py\", line 479, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 153, in execute\n",
      "    self.run_job()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/launch.py\", line 216, in run_job\n",
      "    runner.run()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/runner.py\", line 470, in run\n",
      "    self._run()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/hadoop.py\", line 236, in _run\n",
      "    self._upload_local_files_to_hdfs()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/hadoop.py\", line 263, in _upload_local_files_to_hdfs\n",
      "    self._mkdir_on_hdfs(self._upload_mgr.prefix)\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/hadoop.py\", line 272, in _mkdir_on_hdfs\n",
      "    hadoop_version = self.get_hadoop_version()\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/hadoop.py\", line 220, in get_hadoop_version\n",
      "    stdout = self.invoke_hadoop(['version'], return_stdout=True)\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/site-packages/mrjob/fs/hadoop.py\", line 86, in invoke_hadoop\n",
      "    proc = Popen(args, stdout=PIPE, stderr=PIPE)\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/subprocess.py\", line 710, in __init__\n",
      "    errread, errwrite)\n",
      "  File \"/Users/leiyang/anaconda/lib/python2.7/subprocess.py\", line 1335, in _execute_child\n",
      "    raise child_exception\n",
      "OSError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python Mostused.py MostUsedWord.txt -r hadoop \\\n",
    "--hadoop-home '/usr/local/Cellar/hadoop/2*/libexec/etc/hadoop/' \\\n",
    "--hadoop-streaming-jar '/usr/local/Cellar/hadoop/2.*/libexec/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar' \n",
    "--file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code though python driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.sim:ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'new')\n"
     ]
    }
   ],
   "source": [
    "from Mostused import MRMostUsedWord\n",
    "mr_job = MRMostUsedWord(args=['MostUsedWord.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
