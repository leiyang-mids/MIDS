{"paragraphs":[{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461365703775_-1977976648","id":"20160422-185503_1462869072","dateCreated":"Apr 22, 2016 6:55:03 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:207","dateUpdated":"Apr 23, 2016 12:25:38 AM","dateFinished":"Apr 23, 2016 12:08:15 AM","dateStarted":"Apr 23, 2016 12:08:10 AM","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.spark._\nimport org.apache.spark.graphx._\nimport org.apache.spark.rdd.RDD\ngetLinks: (line: String)Array[org.apache.spark.graphx.Edge[String]]\ngetPages: (line: String)(org.apache.spark.graphx.VertexId, (String, String))\ngetLinks2: (line: String)Array[org.apache.spark.graphx.Edge[String]]\ngetPages2: (line: String)(org.apache.spark.graphx.VertexId, (String, String))\ntime: [R](block: => R)R\n('Node_b,2.837824310201201)\n('Node_c,2.4868526601543555)\n('Node_e,0.7503400819355781)\n('Node_f,0.3625952805244703)\n('Node_d,0.3625952805244703)\n('Node_a,0.3040900819355781)\n('crap_k,0.15)\n('Node_j,0.15)\n('Node_h,0.15)\n('Node_g,0.15)\n('Node_i,0.15)\n('Node_k,0.15)\nElapsed time: 0.18835716666666666 minutes\n"},"text":"import org.apache.spark.graphx._\nimport org.apache.spark.graphx.lib._\n\n\ndef getLinks(line: String): Array[Edge[String]] = {\n    val elem = line.split(\"\\t\", 2)\n    for {n <-  elem(1).stripPrefix(\"{\").split(\",\")\n        // get Edge between id\n    }yield Edge(elem(0).toLong, n.split(\":\")(0).trim().stripPrefix(\"'\").stripSuffix(\"'\").toLong, \"\")\n}\n\ndef getPages(line: String): (VertexId, (String, String)) = {\n    val elem = line.split(\"\\t\")\n    (elem(1).toLong, (elem(0), \"\"))\n}\n\ndef getLinks2(line: String): Array[Edge[String]] = {\n    val elem = line.split(\"\\t\", 2)\n    for {n <-  elem(1).stripPrefix(\"{\").split(\",\")\n        // get Edge between id\n    }yield Edge(elem(0).foldLeft(1L)(_ * _.toLong), n.split(\":\")(0).trim().stripPrefix(\"'\").stripSuffix(\"'\").foldLeft(1L)(_ * _.toLong), \"\")\n}\n\ndef getPages2(line: String): (VertexId, (String, String)) = {\n    val elem = line.split(\"\\t\")\n    return (elem(1).foldLeft(1L)(_ * _.toLong), (elem(0), \"\"))\n}\n\ndef time[R](block: => R): R = {  \n    val t0 = System.nanoTime()\n    val result = block    // call-by-name\n    val t1 = System.nanoTime()\n    println(\"Elapsed time: \" + (t1 - t0)/100000000.0/60.0 + \" minutes\")\n    result\n}\n\ntime{\n    // Create an RDD for the edges and vertices\n    val links = sc.textFile(\"/home/hadoop/lei/all-pages-indexed-out.txt\", 80).flatMap(getLinks);\n    val pages = sc.textFile(\"/home/hadoop/lei/indices.txt\", 16).map(getPage);\n\n    //val links = sc.textFile(\"/Users/leiyang/GitHub/mids/w261_project/HW13/PageRank-test.txt\").flatMap(getLinks2);\n    //val pages = sc.textFile(\"/Users/leiyang/GitHub/mids/w261_project/HW13/toy_index.txt\").map(getPages2);\n\n    // Build the initial Graph\n    val graph = Graph(pages, links);\n    // Run pageRank\n    val rank = PageRank.run(graph, numIter=10).vertices\n    // Show results\n    println(rank.join(pages).map(l => (l._2._2._1, l._2._1)).sortBy(l=>l._2, ascending=false).take(200).mkString(\"\\n\"))\n}"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1461377767080_-1520119550","id":"20160422-221607_1223889623","dateCreated":"Apr 22, 2016 10:16:07 PM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:524"}],"name":"HW13","id":"2BKT6QGMJ","angularObjects":{"2BHJHXRRB":[],"2BHF1P9VD":[],"2BJAVCGX3":[],"2BFC3CNC6":[],"2BFWYU9DG":[],"2BEYPVR7R":[],"2BERN8TS4":[],"2BGW3FZUR":[],"2BJDKF9TY":[],"2BHMXV9F9":[],"2BEYX17DY":[],"2BGDVJSVP":[],"2BGD6FH1A":[],"2BGJQ5WQX":[]},"config":{"looknfeel":"default"},"info":{}}