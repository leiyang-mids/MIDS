{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set enviroment variable for PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.3.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, May 28 2015 17:04:42)\n",
      "SparkContext available as sc, HiveContext available as sqlCtx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "spark_home = os.environ['SPARK_HOME'] = '/Users/liang/Downloads/spark-1.3.0-bin-hadoop2.4/'\n",
    "spark_home = os.environ['SPARK_HOME'] = '/Users/jshanahan/Dropbox/Lectures-UC-Berkeley-ML-Class-2015/spark-1.5.0-bin-hadoop2.6/'\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Example in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ALS with numUser=5000, numItem=100, rank=10, iterations=5, numPartitions=2\n",
      "\n",
      "Simple paralleling ---Suppose MaUsertrix R is small enough to be broadcast\n",
      "Iteration 0:\n",
      "\n",
      "RMSE: 0.981523\n",
      "\n",
      "Iteration 1:\n",
      "\n",
      "RMSE: 0.183839\n",
      "\n",
      "Iteration 2:\n",
      "\n",
      "RMSE: 0.046112\n",
      "\n",
      "Iteration 3:\n",
      "\n",
      "RMSE: 0.038168\n",
      "\n",
      "Iteration 4:\n",
      "\n",
      "RMSE: 0.035043\n",
      "\n",
      "Distributed Version---Tow copies of R, one is partitioned by rowIdx, the other is partitioned by colIndx\n",
      "Iteration 0:\n",
      "\n",
      "RMSE: 0.183839\n",
      "\n",
      "Iteration 1:\n",
      "\n",
      "RMSE: 0.046112\n",
      "\n",
      "Iteration 2:\n",
      "\n",
      "RMSE: 0.038168\n",
      "\n",
      "Iteration 3:\n",
      "\n",
      "RMSE: 0.035043\n",
      "\n",
      "Iteration 4:\n",
      "\n",
      "RMSE: 0.033598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import matrix\n",
    "\n",
    "def rmse(R, U, V): # Metric\n",
    "    return np.sqrt(np.sum(np.power(R-U*V, 2))/(U.shape[0]*V.shape[1]))\n",
    "\n",
    "def solver(mat, R, LAMBDA):  # solver to get R*mat(matT*mat + lambda*I)^-1\n",
    "    d1 = mat.shape[0]\n",
    "    d2 = mat.shape[1]\n",
    "\n",
    "    X2 = mat.T * mat\n",
    "    XY = mat.T * R.T\n",
    "\n",
    "    for j in range(d2):\n",
    "        X2[j, j] += LAMBDA * d1\n",
    "\n",
    "    return np.linalg.solve(X2, XY)\n",
    "\n",
    "# Only parallelize the calculation. It does not consider the data transmission cost\n",
    "def simpleParalleling(R,InitialU,InitialVt,rank,iterations,numPartitions,LAMBDA=0.01):\n",
    "    Rb = sc.broadcast(R)\n",
    "    U = InitialU\n",
    "    Vt = InitialVt\n",
    "    Ub = sc.broadcast(U)\n",
    "    Vtb = sc.broadcast(Vt)\n",
    "    numUsers = InitialU.shape[0]\n",
    "    numItems = InitialVt.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        print \"Iteration %d:\" % i\n",
    "        print \"\\nRMSE: %f\\n\" % rmse(R, U, Vt.T)\n",
    "        U3d = sc.parallelize(range(numUsers), numPartitions) \\\n",
    "           .map(lambda x: solver( Vtb.value, Rb.value[x, :],LAMBDA)) \\\n",
    "           .collect() # a list of two 2-D matrix\n",
    "        U = matrix(np.array(U3d)[:, :, 0]) # transfered to 2-D matrix\n",
    "        Ub = sc.broadcast(U)\n",
    "\n",
    "        Vt3d = sc.parallelize(range(numItems), numPartitions) \\\n",
    "           .map(lambda x: solver(Ub.value, Rb.value.T[x,:],LAMBDA)) \\\n",
    "           .collect() # a list of two 2-D matrix\n",
    "        Vt = matrix(np.array(Vt3d)[:, :, 0]) # transfered to 2-D matrix\n",
    "        Vtb = sc.broadcast(Vt)\n",
    "    return U, Vt\n",
    "\n",
    "# Not only caculation is paralleized but also the data is wisely partitioned and shared to improve locality.\n",
    "def closedFormALS(R,InitialU,InitialVt,rank,iterations,numPartitions,LAMBDA=0.01):\n",
    "    R_Userslice = sc.parallelize(R,numPartitions).cache() # R will automaticly be partitioned by row index\n",
    "    R_Itemslice = sc.parallelize(R.T,numPartitions).cache() # R_T will automaticly be partitioned by row index\n",
    "    U = InitialU\n",
    "    Vt = InitialVt\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print \"Iteration %d:\" % i\n",
    "        print \"\\nRMSE: %f\\n\" % rmse(R, U, Vt.T)\n",
    "        \n",
    "        Vtb = sc.broadcast(Vt)\n",
    "        U3d = R_Userslice.map(lambda x:solver(Vtb.value,x,LAMBDA)).collect() # a list of two 2-D matrix\n",
    "        U = matrix(np.array(U3d)[:, :, 0]) # transfered to 2-D matrix\n",
    "        \n",
    "        Ub = sc.broadcast(U)\n",
    "        Vt3d = R_Itemslice.map(lambda x:solver(Ub.value,x,LAMBDA)).collect() # a list of two 2-D matrix\n",
    "        Vt = matrix(np.array(Vt3d)[:, :, 0])  # transfered to 2-D matrix\n",
    "    \n",
    "    return U, Vt \n",
    "        \n",
    "    \n",
    "        \n",
    "def main():\n",
    "    LAMBDA = 0.01   # regularization parameter\n",
    "    np.random.seed(100)\n",
    "    numUsers = 5000\n",
    "    numItems = 100\n",
    "    rank = 10\n",
    "    iterations = 5\n",
    "    numPartitions = 2\n",
    "\n",
    "    trueU = matrix(rand(numUsers, rank)) #True matrix U to generate R\n",
    "    trueV = matrix(rand(rank, numItems)) #True matrix V to generate R\n",
    "    R = matrix(trueU*trueV)   #generate Rating matrix\n",
    "    \n",
    "    InitialU = matrix(rand(numUsers, rank)) #Initialization of U\n",
    "    InitialVt = matrix(rand(numItems,rank))#Initialization of V\n",
    "    \n",
    "    print \"Running ALS with numUser=%d, numItem=%d, rank=%d, iterations=%d, numPartitions=%d\\n\" % \\\n",
    "    (numUsers, numItems, rank, iterations, numPartitions)\n",
    "    \n",
    "    print\"Distributed Version---Tow copies of R, one is partitioned by rowIdx, the other is partitioned by colIndx\"\n",
    "    closedFormALS(R,InitialU,InitialVt,rank,iterations,numPartitions,LAMBDA)\n",
    "    \n",
    "    print \"Simple paralleling ---Suppose MaUsertrix R is small enough to be broadcast\"\n",
    "    simpleParalleling(R,InitialU,InitialVt,rank,iterations,numPartitions,LAMBDA)\n",
    "    \n",
    "    \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
