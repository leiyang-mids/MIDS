{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261, Machine Learning at Scale\n",
    "--------\n",
    "####Assignement:  week \\#7\n",
    "####[Lei Yang](mailto:leiyang@berkeley.edu) | [Michael Kennedy](mailto:mkennedy@ischool.berkeley.edu) | [Natarajan Krishnaswami](mailto:natarajan@krishnaswami.org)\n",
    "####Due: 2016-03-10, 8AM PST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###General Description\n",
    "In this assignment you will explore networks and develop MRJob code for \n",
    "finding shortest path graph distances. To build up to large data \n",
    "you will develop your code on some very simple, toy networks.\n",
    "After this you will take your developed code forward and modify it and \n",
    "apply it to two larger datasets (performing EDA along the way).\n",
    "\n",
    "\n",
    "####Undirected toy network dataset\n",
    "\n",
    "In an undirected network all links are symmetric, \n",
    "i.e., for a pair of nodes 'A' and 'B,' both of the links:\n",
    "\n",
    "A -> B and B -> A\n",
    "\n",
    "will exist. \n",
    "\n",
    "The toy data are available in a sparse (stripes) representation:\n",
    "\n",
    "(node) \\t (dictionary of links)\n",
    "\n",
    "on AWS/Dropbox via the url:\n",
    "\n",
    "s3://ucb-mids-mls-networks/undirected_toy.txt\n",
    "\n",
    "On under the Data Subfolder for HW7 on Dropbox with the same file name\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values \n",
    "(here, all weights are 1, i.e., the network is unweighted).\n",
    "\n",
    "\n",
    "####Directed toy network dataset\n",
    "\n",
    "In a directed network all links are not necessarily symmetric, \n",
    "i.e., for a pair of nodes 'A' and 'B,' it is possible for only one of:\n",
    "\n",
    "A -> B or B -> A\n",
    "\n",
    "to exist. \n",
    "\n",
    "These toy data are available in a sparse (stripes) representation:\n",
    "\n",
    "(node) \\t (dictionary of links)\n",
    "\n",
    "on AWS/Dropbox via the url:\n",
    "\n",
    "s3://ucb-mids-mls-networks/directed_toy.txt\n",
    "\n",
    "On under the Data Subfolder for HW7 on Dropbox with the same file name\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values \n",
    "(here, all weights are 1, i.e., the network is unweighted).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "###HW 7.0: Shortest path graph distances (toy networks)\n",
    "\n",
    "In this part of your assignment you will develop the base of your code for the week.\n",
    "\n",
    "Write MRJob classes to find shortest path graph distances, \n",
    "as described in the lectures. In addition to finding the distances, \n",
    "your code should also output a distance-minimizing path between the source and target.\n",
    "Work locally for this part of the assignment, and use \n",
    "both of the undirected and directed toy networks.\n",
    "\n",
    "To proof you code's function, run the following jobs\n",
    "\n",
    "- shortest path in the undirected network from node 1 to node 4\n",
    "\n",
    "Solution: 1,5,4 \n",
    "\n",
    "- shortest path in the directed network from node 1 to node 5\n",
    "\n",
    "Solution: 1,2,4,5\n",
    "\n",
    "and report your output---make sure it is correct!\n",
    "\n",
    "###One Iteration BFS Mrjob\n",
    "<img src=\"ShortestPathMapReduce.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ShortestPathIter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ShortestPathIter.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "\n",
    "class ShortestPathIter(MRJob):\n",
    "    DEFAULT_PROTOCOL = 'json'\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ShortestPathIter, self).__init__(*args, **kwargs)\n",
    "        \n",
    "                                                 \n",
    "    def configure_options(self):\n",
    "        super(ShortestPathIter, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--source', dest='source', default='1', type='string',\n",
    "            help='source: source node (default 1)')        \n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        nid, dic = line.strip().split('\\t', 1)\n",
    "        cmd = 'node = %s' %dic\n",
    "        exec cmd        \n",
    "        # if the node structure is incomplete (first pass), add them                \n",
    "        if 'dist' not in node:            \n",
    "            node = {'adj':node, 'path':[]}            \n",
    "            node['dist'] = 0 if self.options.source==nid else -1            \n",
    "        # emit node\n",
    "        yield nid, node        \n",
    "        # emit distances to reachable nodes\n",
    "        if node['dist'] >= 0:\n",
    "            for m in node['adj']:                \n",
    "                ##### for regular weighted dataset\n",
    "                #yield m, {'dd':node['adj'][m] + node['dist'], 'pp':node['path']+[nid]}\n",
    "                ##### for wikipedia dataset, no weight\n",
    "                yield m, {'dd':1 + node['dist'], 'pp':node['path']+[nid]}\n",
    "                \n",
    "    def reducer(self, nid, value):\n",
    "        dmin = float('inf')\n",
    "        path = node = None\n",
    "        # loop through all arrivals\n",
    "        for v in value:            \n",
    "            if 'dist' in v:\n",
    "                node = v\n",
    "            elif v['dd'] < dmin:\n",
    "                dmin = v['dd']\n",
    "                path = v['pp']\n",
    "        # handle dangling node\n",
    "        if not node:\n",
    "            node = {'adj':{}, 'dist':dmin, 'path':path}\n",
    "        # update distance and path\n",
    "        if (node['dist'] == -1 and path) or dmin < node['dist']:\n",
    "            node['dist'] = dmin\n",
    "            node['path'] = path\n",
    "        # emit for next iteration\n",
    "        yield nid, node\n",
    "        \n",
    "    def steps(self):\n",
    "        jc = {\n",
    "            'mapreduce.job.maps': '10',\n",
    "            'mapreduce.job.reduces': '10',\n",
    "        }\n",
    "        return [MRStep(mapper=self.mapper\n",
    "                       , combiner=self.reducer\n",
    "                       , reducer=self.reducer\n",
    "                       #, reducer_final=self.reducer_final\n",
    "                       #, jobconf = jc\n",
    "                      )\n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ShortestPathIter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### unit test #####\n",
    "#!python ShortestPathIter.py undirected_toy.txt --source 1 -r 'inline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Driver Program\n",
    "- init_job: take raw import, do first level traverse, output intermediate graph file\n",
    "- iter_job: iteratively traverse the graph and update the shortest distance and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RunBFS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile RunBFS.py\n",
    "#!/usr/bin/python\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "from ShortestPathIter import ShortestPathIter\n",
    "import sys, getopt\n",
    "\n",
    "# parse parameter\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:], \"hg:s:d:m:\")\n",
    "    except getopt.GetoptError:\n",
    "        print 'RunBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "        sys.exit(2)\n",
    "    if len(opts) != 4:\n",
    "        print 'RunBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt == '-h':\n",
    "            print 'RunBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "            sys.exit(2)\n",
    "        elif opt == '-g':\n",
    "            graph = arg\n",
    "        elif opt == '-s':\n",
    "            source = arg\n",
    "        elif opt == '-d':\n",
    "            destination = arg\n",
    "        elif opt == '-m':\n",
    "            mode = arg\n",
    "        \n",
    "\n",
    "# creat BFS job\n",
    "init_job = ShortestPathIter(args=[graph, '--source', source, '-r', mode])\n",
    "iter_job = ShortestPathIter(args=['graph', '--source', source, '-r', mode])\n",
    "\n",
    "# run initialization job\n",
    "with init_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    dist_old = {}\n",
    "    # save our graph file for iteration\n",
    "    with open('graph', 'w') as f:\n",
    "        for line in runner.stream_output():\n",
    "            # value is nid and node object\n",
    "            nid, node = init_job.parse_output_line(line)\n",
    "            # record distance for each node\n",
    "            dist_old[nid] = node['dist']\n",
    "            # write graph file \n",
    "            f.write('%s\\t%s\\n' %(nid, node))\n",
    "\n",
    "# run BFS iteratively\n",
    "i = 1\n",
    "while(1):    \n",
    "    print 'iteration %s' %i\n",
    "    dist = {}\n",
    "    with iter_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output    \n",
    "        with open('graph', 'w') as f:\n",
    "            for line in runner.stream_output():\n",
    "                # value is nid and node object\n",
    "                nid, node = iter_job.parse_output_line(line)\n",
    "                dist[nid] = node['dist']\n",
    "                f.write('%s\\t%s\\n' %(nid, str(node)))\n",
    "            \n",
    "    # check if distance for each node changes\n",
    "    stop = True\n",
    "    for n in dist:\n",
    "        if dist_old[n] != dist[n]:\n",
    "            stop = False\n",
    "            break  \n",
    "    \n",
    "    if stop:\n",
    "        break\n",
    "    \n",
    "    # save dist for next iteration comparison\n",
    "    dist_old = dist\n",
    "    i += 1\n",
    "        \n",
    "print \"Traversing completes!\\n\"\n",
    "\n",
    "# show path between source and destination\n",
    "with open('graph', 'r') as f:\n",
    "    line = f.readline()\n",
    "    while (line):\n",
    "        nid, node = line.split('\\t')\n",
    "        if nid == destination:\n",
    "            cmd = 'node = %s' %node\n",
    "            exec cmd\n",
    "            if node['path']:\n",
    "                print 'shortest distance between %s and %s: %s' %(source, destination, node['dist'])\n",
    "                print 'path: %s' %' -> '.join(node['path']+[destination])\n",
    "            else:\n",
    "                print '%s is a dangling node, cannot traverse from it!' %source\n",
    "            break\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest path in the undirected network from node 1 to node 4:\n",
      "iteration 1\n",
      "iteration 2\n",
      "Traversing completes!\n",
      "\n",
      "shortest distance between 1 and 4: 2\n",
      "path: 1 -> 2 -> 4\n",
      "\n",
      "The shortest path in the directed network from node 1 to node 5:\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "Traversing completes!\n",
      "\n",
      "shortest distance between 1 and 5: 3\n",
      "path: 1 -> 2 -> 4 -> 5\n"
     ]
    }
   ],
   "source": [
    "!echo 'The shortest path in the undirected network from node 1 to node 4:'\n",
    "!python RunBFS.py -s 1 -d 4 -m 'inline' -g undirected_toy.txt\n",
    "\n",
    "!echo '\\nThe shortest path in the directed network from node 1 to node 5:'\n",
    "!python RunBFS.py -s 1 -d 5 -m 'inline' -g directed_toy.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Main dataset 1: NLTK synonyms\n",
    "\n",
    "- In the next part of this assignment you will explore a network derived from\n",
    "the NLTK synonym database used for evaluation in HW 5. \n",
    "- At a high level, this network is undirected, defined so that there exists link between two nodes/words \n",
    "if the pair or words are a synonym. \n",
    "\n",
    "These data may be found at the location:\n",
    "\n",
    "- s3://ucb-mids-mls-networks/synNet/synNet.txt\n",
    "- s3://ucb-mids-mls-networks/synNet/indices.txt\n",
    "\n",
    "On under the Data Subfolder for HW7 on Dropbox with the same file names\n",
    "\n",
    "where synNet.txt contains a sparse representation of the network:\n",
    "\n",
    "(index) \\t (dictionary of links)\n",
    "\n",
    "in indexed form, and indices.txt contains a lookup list\n",
    "\n",
    "(word) \\t (index)\n",
    "\n",
    "of indices and words. This network is small enough for you to explore and run\n",
    "scripts locally, but will also be good for a systems test (for later) on AWS.\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values \n",
    "(here, all weights are 1, i.e., the network is unweighted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.1: Exploratory data analysis (NLTK synonyms)\n",
    "\n",
    "Using MRJob, explore the synonyms network data.\n",
    "Consider plotting the degree distribution (does it follow a power law?),\n",
    "and determine some of the key features, like:\n",
    "\n",
    "- number of nodes, \n",
    "- number links,\n",
    "- or the average degree (i.e., the average number of links per node),\n",
    "- etc...\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS).\n",
    "\n",
    "###MrJob to scan the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ExploreGraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ExploreGraph.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class ExploreGraph(MRJob):\n",
    "    \n",
    "    DEFAULT_PROTOCOL = 'json'\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ExploreGraph, self).__init__(*args, **kwargs)\n",
    "\n",
    "    # assuming we are dealing with directed graph\n",
    "    # this job can handle undirected graph as well, \n",
    "    # but it can be done more efficiently\n",
    "    def mapper(self, _, line):\n",
    "        nid, dic = line.strip().split('\\t', 1)\n",
    "        cmd = 'adj = %s' %dic\n",
    "        exec cmd        \n",
    "        # we need to emit node ID as key, in order to count dangling nodes\n",
    "        # the value emitted here is (out, in) degree for the node\n",
    "        yield nid, (len(adj), 0)\n",
    "        # emit in degree from adjacency list\n",
    "        for n in adj:\n",
    "            yield n, (0, 1)\n",
    "                        \n",
    "    def combiner(self, nid, deg):\n",
    "        din = dout = 0\n",
    "        for d in deg:            \n",
    "            dout += d[0]\n",
    "            din += d[1]            \n",
    "        yield nid, (dout, din)\n",
    "        \n",
    "    def reducer_init(self):\n",
    "        self.node_cnt = 0\n",
    "        self.out_deg = {}\n",
    "        self.in_deg = {}\n",
    "        \n",
    "    def reducer(self, node, deg):\n",
    "        # add node by 1\n",
    "        self.node_cnt += 1\n",
    "        # aggregate in/out degree\n",
    "        _out = _in = 0\n",
    "        for d in deg:            \n",
    "            _out += d[0]\n",
    "            _in += d[1]    \n",
    "        # accumulate degree distribution\n",
    "        if _out not in self.out_deg:\n",
    "            self.out_deg[_out] = 1\n",
    "        else:\n",
    "            self.out_deg[_out] += 1\n",
    "        if _in not in self.in_deg:\n",
    "            self.in_deg[_in] = 1\n",
    "        else:\n",
    "            self.in_deg[_in] += 1\n",
    "        \n",
    "            \n",
    "    def reducer_final(self):\n",
    "        # final aggregation        \n",
    "        tot_degree = sum([d*self.out_deg[d] for d in self.out_deg])\n",
    "        yield 'total nodes: ', self.node_cnt\n",
    "        yield 'total links: ', tot_degree\n",
    "        yield 'average in degree: ', 1.0*tot_degree/sum(self.in_deg.values())\n",
    "        yield 'average out degree: ', 1.0*tot_degree/sum(self.out_deg.values())\n",
    "        yield 'dist of in-degree: ', self.in_deg\n",
    "        yield 'dist of out-degree: ', self.out_deg\n",
    "        \n",
    "    def steps(self):\n",
    "        jc = {\n",
    "            'mapreduce.job.maps': '10',\n",
    "            'mapreduce.job.reduces': '1',\n",
    "        }\n",
    "        return [MRStep(mapper=self.mapper\n",
    "                       , combiner=self.combiner\n",
    "                       , reducer_init=self.reducer_init\n",
    "                       , reducer=self.reducer                       \n",
    "                       , reducer_final=self.reducer_final\n",
    "                       #, jobconf = jc\n",
    "                      )\n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ExploreGraph.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Explore NLTK Synonyms Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using configs in /Users/leiyang/.mrjob.conf\n",
      "creating tmp directory /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096\n",
      "writing to /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/step-0-mapper-sorted\n",
      "> sort /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/step-0-mapper_part-00000\n",
      "writing to /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/step-0-reducer_part-00000 -> /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/output/part-00000\n",
      "Streaming final output from /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096/output\n",
      "removing tmp directory /var/folders/tx/5ldq67q511q8wqwqkvptnxd00000gn/T/ExploreGraph.leiyang.20160301.010635.985096\n",
      "\n",
      "Summary stats of the graph:\n",
      "\"total nodes: \"\t100\n",
      "\"total links: \"\t929\n",
      "\"average in degree: \"\t9.29\n",
      "\"average out degree: \"\t9.29\n",
      "\"dist of in-degree: \"\t{\"3\": 1, \"4\": 2, \"5\": 3, \"6\": 7, \"7\": 13, \"8\": 19, \"9\": 10, \"10\": 15, \"11\": 10, \"12\": 7, \"13\": 5, \"14\": 5, \"16\": 2, \"17\": 1}\n",
      "\"dist of out-degree: \"\t{\"4\": 3, \"5\": 6, \"6\": 7, \"7\": 14, \"8\": 13, \"9\": 12, \"10\": 12, \"11\": 11, \"12\": 8, \"13\": 5, \"14\": 7, \"15\": 1, \"20\": 1}\n"
     ]
    }
   ],
   "source": [
    "!python ExploreGraph.py randNet.txt -r 'inline' > sumstats\n",
    "!echo '\\nSummary stats of the graph:'\n",
    "!cat sumstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Node degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAFRCAYAAADXWVQUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwAAmADhDgAAYAKEOwAAgAn4/9s+5kBpLw4gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107fdc2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "in_deg = {\"3\": 1, \"4\": 2, \"5\": 3, \"6\": 7, \"7\": 13, \"8\": 19, \"9\": 10, \"10\": 15, \"11\": 10, \"12\": 7, \"13\": 5, \"14\": 5, \"16\": 2, \"17\": 1}\n",
    "out_deg = {\"4\": 3, \"5\": 6, \"6\": 7, \"7\": 14, \"8\": 13, \"9\": 12, \"10\": 12, \"11\": 11, \"12\": 8, \"13\": 5, \"14\": 7, \"15\": 1, \"20\": 1}\n",
    "# plot the in/out distribution histogram\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_size_inches([15,5])\n",
    "ax1.bar([int(k) for k in in_deg.keys()], in_deg.values())\n",
    "ax1.set_title('in-degree distribution')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xlabel('in-deg')\n",
    "ax2.bar([int(k) for k in out_deg.keys()], out_deg.values())\n",
    "ax2.set_title('out-degree distribution')\n",
    "ax2.set_xlabel('out-deg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.2: Shortest path graph distances (NLTK synonyms)\n",
    "\n",
    "Write (reuse your code from 7.0) an MRJob class to find shortest path graph distances, \n",
    "and apply it to the NLTK synonyms network dataset. \n",
    "\n",
    "Proof your code's function by running the job:\n",
    "\n",
    "- shortest path starting at \"walk\" (index=7827) and ending at \"make\" (index=536),\n",
    "\n",
    "and showing you code's output. Once again, your output should include the path and the distance.\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "Traversing completes!\n",
      "\n",
      "shortest distance between 58 and 34: 2\n",
      "path: 58 -> 21 -> 34\n"
     ]
    }
   ],
   "source": [
    "##### execute RunBFS.py from HW 7.0 #####\n",
    "!python RunBFS.py -g randNet.txt -d 34 -s 58 -m 'inline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Main dataset 2: English Wikipedia\n",
    "\n",
    "For the remainder of this assignment you will explore the English Wikipedia hyperlink network.\n",
    "The dataset is built from the Sept. 2015 XML snapshot of English Wikipedia.\n",
    "For this directed network, a link between articles: \n",
    "\n",
    "A -> B\n",
    "\n",
    "is defined by the existence of a hyperlink in A pointing to B.\n",
    "This network also exists in the indexed format:\n",
    "\n",
    "- s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt\n",
    "- s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-in.txt\n",
    "- s3://ucb-mids-mls-networks/wikipedia/indices.txt\n",
    "\n",
    "On under the Data Subfolder for HW7 on Dropbox with the same file names\n",
    "\n",
    "but has an index with more detailed data:\n",
    "\n",
    "(article name) \\t (index) \\t (in degree) \\t (out degree)\n",
    "\n",
    "In the dictionary, target nodes are keys, link weights are values .\n",
    "Here, a weight indicates the number of time a page links to another.\n",
    "However, for the sake of this assignment, treat this an unweighted network,\n",
    "and set all weights to 1 upon data input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.3: Exploratory data analysis (Wikipedia)\n",
    "\n",
    "Using MRJob, explore the Wikipedia network data on the AWS cloud. Reuse your code from HW 7.1---does is scale well? \n",
    "Be cautioned that Wikipedia is a directed network, where links are not symmetric. \n",
    "So, even though a node may be linked to, it will not appear as a primary record itself if it has no out-links. \n",
    "This means that you may have to ADJUST your code (depending on its design). \n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hadoop@ip-172-31-1-180 lei_wiki]$ ls -l\r\n",
      "total 2041476\r\n",
      "-rw-rw-r-- 1 hadoop hadoop 2090459616 Oct 22 02:29 all-pages-indexed-out.txt\r\n",
      "-rw-rw-r-- 1 hadoop hadoop       2655 Mar  1 01:57 ExploreGraph.py\r\n",
      "[hadoop@ip-172-31-1-180 lei_wiki]$ python ExploreGraph.py 'all-pages-indexed-out.txt' -r 'hadoop' --cleanup 'NONE' > wiki_sumstats\r\n",
      "using configs in /home/hadoop/.mrjob.conf\r\n",
      "creating tmp directory /tmp/ExploreGraph.hadoop.20160301.015847.095270\r\n",
      "writing wrapper script to /tmp/ExploreGraph.hadoop.20160301.015847.095270/setup-wrapper.sh\r\n",
      "Using Hadoop version 2.7.1\r\n",
      "Copying local files into hdfs:///user/hadoop/tmp/mrjob/ExploreGraph.hadoop.20160301.015847.095270/files/\r\n",
      "HADOOP: packageJobJar: [] [/usr/lib/hadoop/hadoop-streaming-2.7.1-amzn-0.jar] /tmp/streamjob2321478639392700904.jar tmpDir=null\r\n",
      "HADOOP: Connecting to ResourceManager at ip-172-31-1-180.ec2.internal/172.31.1.180:8032\r\n",
      "HADOOP: Connecting to ResourceManager at ip-172-31-1-180.ec2.internal/172.31.1.180:8032\r\n",
      "HADOOP: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1456796497690\r\n",
      "HADOOP: Created MetricsSaver j-273F2CEVES2O8:i-2bfc5aaf:RunJar:10200 period:60 /mnt/var/em/raw/i-2bfc5aaf_20160301_RunJar_10200_raw.bin\r\n",
      "HADOOP: Loaded native gpl library\r\n",
      "HADOOP: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 02f444f0932ea7710dcc4bcdc1aa7ca55adf48c9]\r\n",
      "HADOOP: Total input paths to process : 1\r\n",
      "HADOOP: number of splits:16\r\n",
      "HADOOP: Submitting tokens for job: job_1456796483811_0001\r\n",
      "HADOOP: Submitted application application_1456796483811_0001\r\n",
      "HADOOP: The url to track the job: http://ip-172-31-1-180.ec2.internal:20888/proxy/application_1456796483811_0001/\r\n",
      "HADOOP: Running job: job_1456796483811_0001\r\n",
      "HADOOP: Job job_1456796483811_0001 running in uber mode : false\r\n",
      "HADOOP:  map 0% reduce 0%\r\n",
      "HADOOP:  map 1% reduce 0%\r\n",
      "HADOOP:  map 2% reduce 0%\r\n",
      "HADOOP:  map 3% reduce 0%\r\n",
      "HADOOP:  map 4% reduce 0%\r\n",
      "HADOOP:  map 5% reduce 0%\r\n",
      "HADOOP:  map 6% reduce 0%\r\n",
      "HADOOP:  map 7% reduce 0%\r\n",
      "HADOOP:  map 8% reduce 0%\r\n",
      "HADOOP:  map 9% reduce 0%\r\n",
      "HADOOP:  map 10% reduce 0%\r\n",
      "HADOOP:  map 11% reduce 0%\r\n",
      "HADOOP:  map 12% reduce 0%\r\n",
      "HADOOP:  map 13% reduce 0%\r\n",
      "HADOOP:  map 14% reduce 0%\r\n",
      "HADOOP:  map 15% reduce 0%\r\n",
      "HADOOP:  map 16% reduce 0%\r\n",
      "HADOOP:  map 17% reduce 0%\r\n",
      "HADOOP:  map 18% reduce 0%\r\n",
      "HADOOP:  map 19% reduce 0%\r\n",
      "HADOOP:  map 20% reduce 0%\r\n",
      "HADOOP:  map 21% reduce 0%\r\n",
      "HADOOP:  map 22% reduce 0%\r\n",
      "HADOOP:  map 23% reduce 0%\r\n",
      "HADOOP:  map 24% reduce 0%\r\n",
      "HADOOP:  map 25% reduce 0%\r\n",
      "HADOOP:  map 26% reduce 0%\r\n",
      "HADOOP:  map 27% reduce 0%\r\n",
      "HADOOP:  map 28% reduce 0%\r\n",
      "HADOOP:  map 29% reduce 0%\r\n",
      "HADOOP:  map 30% reduce 0%\r\n",
      "HADOOP:  map 31% reduce 0%\r\n",
      "HADOOP:  map 32% reduce 0%\r\n",
      "HADOOP:  map 34% reduce 0%\r\n",
      "HADOOP:  map 35% reduce 0%\r\n",
      "HADOOP:  map 36% reduce 0%\r\n",
      "HADOOP:  map 37% reduce 0%\r\n",
      "HADOOP:  map 38% reduce 0%\r\n",
      "HADOOP:  map 39% reduce 0%\r\n",
      "HADOOP:  map 40% reduce 0%\r\n",
      "HADOOP:  map 41% reduce 0%\r\n",
      "HADOOP:  map 42% reduce 0%\r\n",
      "HADOOP:  map 43% reduce 0%\r\n",
      "HADOOP:  map 44% reduce 0%\r\n",
      "HADOOP:  map 45% reduce 0%\r\n",
      "HADOOP:  map 46% reduce 0%\r\n",
      "HADOOP:  map 47% reduce 0%\r\n",
      "HADOOP:  map 48% reduce 0%\r\n",
      "HADOOP:  map 49% reduce 0%\r\n",
      "HADOOP:  map 50% reduce 0%\r\n",
      "HADOOP:  map 51% reduce 0%\r\n",
      "HADOOP:  map 52% reduce 0%\r\n",
      "HADOOP:  map 54% reduce 0%\r\n",
      "HADOOP:  map 55% reduce 0%\r\n",
      "HADOOP:  map 56% reduce 0%\r\n",
      "HADOOP:  map 58% reduce 0%\r\n",
      "HADOOP:  map 59% reduce 0%\r\n",
      "HADOOP:  map 61% reduce 0%\r\n",
      "HADOOP:  map 63% reduce 0%\r\n",
      "HADOOP:  map 65% reduce 0%\r\n",
      "HADOOP:  map 67% reduce 0%\r\n",
      "HADOOP:  map 69% reduce 0%\r\n",
      "HADOOP:  map 71% reduce 0%\r\n",
      "HADOOP:  map 72% reduce 0%\r\n",
      "HADOOP:  map 73% reduce 0%\r\n",
      "HADOOP:  map 73% reduce 4%\r\n",
      "HADOOP:  map 75% reduce 4%\r\n",
      "HADOOP:  map 75% reduce 17%\r\n",
      "HADOOP:  map 76% reduce 17%\r\n",
      "HADOOP:  map 77% reduce 17%\r\n",
      "HADOOP:  map 78% reduce 17%\r\n",
      "HADOOP:  map 79% reduce 17%\r\n",
      "HADOOP:  map 80% reduce 17%\r\n",
      "HADOOP:  map 81% reduce 17%\r\n",
      "HADOOP:  map 82% reduce 17%\r\n",
      "HADOOP:  map 83% reduce 17%\r\n",
      "HADOOP:  map 84% reduce 17%\r\n",
      "HADOOP:  map 85% reduce 17%\r\n",
      "HADOOP:  map 86% reduce 17%\r\n",
      "HADOOP:  map 87% reduce 17%\r\n",
      "HADOOP:  map 88% reduce 17%\r\n",
      "HADOOP:  map 89% reduce 17%\r\n",
      "HADOOP:  map 90% reduce 17%\r\n",
      "HADOOP:  map 92% reduce 17%\r\n",
      "HADOOP:  map 94% reduce 17%\r\n",
      "HADOOP:  map 95% reduce 17%\r\n",
      "HADOOP:  map 97% reduce 17%\r\n",
      "HADOOP:  map 98% reduce 17%\r\n",
      "HADOOP:  map 100% reduce 17%\r\n",
      "HADOOP:  map 100% reduce 27%\r\n",
      "HADOOP:  map 100% reduce 33%\r\n",
      "HADOOP:  map 100% reduce 67%\r\n",
      "HADOOP:  map 100% reduce 68%\r\n",
      "HADOOP:  map 100% reduce 69%\r\n",
      "HADOOP:  map 100% reduce 70%\r\n",
      "HADOOP:  map 100% reduce 71%\r\n",
      "HADOOP:  map 100% reduce 72%\r\n",
      "HADOOP:  map 100% reduce 73%\r\n",
      "HADOOP:  map 100% reduce 74%\r\n",
      "HADOOP:  map 100% reduce 75%\r\n",
      "HADOOP:  map 100% reduce 76%\r\n",
      "HADOOP:  map 100% reduce 77%\r\n",
      "HADOOP:  map 100% reduce 78%\r\n",
      "HADOOP:  map 100% reduce 79%\r\n",
      "HADOOP:  map 100% reduce 80%\r\n",
      "HADOOP:  map 100% reduce 81%\r\n",
      "HADOOP:  map 100% reduce 82%\r\n",
      "HADOOP:  map 100% reduce 83%\r\n",
      "HADOOP:  map 100% reduce 84%\r\n",
      "HADOOP:  map 100% reduce 85%\r\n",
      "HADOOP:  map 100% reduce 86%\r\n",
      "HADOOP:  map 100% reduce 87%\r\n",
      "HADOOP:  map 100% reduce 88%\r\n",
      "HADOOP:  map 100% reduce 89%\r\n",
      "HADOOP:  map 100% reduce 90%\r\n",
      "HADOOP:  map 100% reduce 91%\r\n",
      "HADOOP:  map 100% reduce 92%\r\n",
      "HADOOP:  map 100% reduce 93%\r\n",
      "HADOOP:  map 100% reduce 94%\r\n",
      "HADOOP:  map 100% reduce 95%\r\n",
      "HADOOP:  map 100% reduce 96%\r\n",
      "HADOOP:  map 100% reduce 97%\r\n",
      "HADOOP:  map 100% reduce 98%\r\n",
      "HADOOP:  map 100% reduce 99%\r\n",
      "HADOOP:  map 100% reduce 100%\r\n",
      "HADOOP: Job job_1456796483811_0001 completed successfully\r\n",
      "HADOOP: Counters: 51\r\n",
      "HADOOP: \tFile System Counters\r\n",
      "HADOOP: \t\tFILE: Number of bytes read=551813329\r\n",
      "HADOOP: \t\tFILE: Number of bytes written=901418328\r\n",
      "HADOOP: \t\tFILE: Number of read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of large read operations=0\r\n",
      "HADOOP: \t\tFILE: Number of write operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of bytes read=2091445696\r\n",
      "HADOOP: \t\tHDFS: Number of bytes written=76840\r\n",
      "HADOOP: \t\tHDFS: Number of read operations=51\r\n",
      "HADOOP: \t\tHDFS: Number of large read operations=0\r\n",
      "HADOOP: \t\tHDFS: Number of write operations=2\r\n",
      "HADOOP: \tJob Counters\r\n",
      "HADOOP: \t\tKilled map tasks=3\r\n",
      "HADOOP: \t\tLaunched map tasks=19\r\n",
      "HADOOP: \t\tLaunched reduce tasks=1\r\n",
      "HADOOP: \t\tData-local map tasks=14\r\n",
      "HADOOP: \t\tRack-local map tasks=5\r\n",
      "HADOOP: \t\tTotal time spent by all maps in occupied slots (ms)=415795488\r\n",
      "HADOOP: \t\tTotal time spent by all reduces in occupied slots (ms)=85978592\r\n",
      "HADOOP: \t\tTotal time spent by all map tasks (ms)=17324812\r\n",
      "HADOOP: \t\tTotal time spent by all reduce tasks (ms)=2686831\r\n",
      "HADOOP: \t\tTotal vcore-seconds taken by all map tasks=17324812\r\n",
      "HADOOP: \t\tTotal vcore-seconds taken by all reduce tasks=2686831\r\n",
      "HADOOP: \t\tTotal megabyte-seconds taken by all map tasks=13305455616\r\n",
      "HADOOP: \t\tTotal megabyte-seconds taken by all reduce tasks=2751314944\r\n",
      "HADOOP: \tMap-Reduce Framework\r\n",
      "HADOOP: \t\tMap input records=5781290\r\n",
      "HADOOP: \t\tMap output records=147895347\r\n",
      "HADOOP: \t\tMap output bytes=2566288353\r\n",
      "HADOOP: \t\tMap output materialized bytes=347440319\r\n",
      "HADOOP: \t\tInput split bytes=3040\r\n",
      "HADOOP: \t\tCombine input records=210009639\r\n",
      "HADOOP: \t\tCombine output records=88093113\r\n",
      "HADOOP: \t\tReduce input groups=15192277\r\n",
      "HADOOP: \t\tReduce shuffle bytes=347440319\r\n",
      "HADOOP: \t\tReduce input records=25978821\r\n",
      "HADOOP: \t\tReduce output records=6\r\n",
      "HADOOP: \t\tSpilled Records=150207405\r\n",
      "HADOOP: \t\tShuffled Maps =16\r\n",
      "HADOOP: \t\tFailed Shuffles=0\r\n",
      "HADOOP: \t\tMerged Map outputs=16\r\n",
      "HADOOP: \t\tGC time elapsed (ms)=22362\r\n",
      "HADOOP: \t\tCPU time spent (ms)=10309990\r\n",
      "HADOOP: \t\tPhysical memory (bytes) snapshot=6520324096\r\n",
      "HADOOP: \t\tVirtual memory (bytes) snapshot=22371188736\r\n",
      "HADOOP: \t\tTotal committed heap usage (bytes)=5087166464\r\n",
      "HADOOP: \tShuffle Errors\r\n",
      "HADOOP: \t\tBAD_ID=0\r\n",
      "HADOOP: \t\tCONNECTION=0\r\n",
      "HADOOP: \t\tIO_ERROR=0\r\n",
      "HADOOP: \t\tWRONG_LENGTH=0\r\n",
      "HADOOP: \t\tWRONG_MAP=0\r\n",
      "HADOOP: \t\tWRONG_REDUCE=0\r\n",
      "HADOOP: \tFile Input Format Counters\r\n",
      "HADOOP: \t\tBytes Read=2091442656\r\n",
      "HADOOP: \tFile Output Format Counters\r\n",
      "HADOOP: \t\tBytes Written=76840\r\n",
      "HADOOP: Output directory: hdfs:///user/hadoop/tmp/mrjob/ExploreGraph.hadoop.20160301.015847.095270/output\r\n",
      "Counters from step 1:\r\n",
      "  (no counters found)\r\n",
      "Streaming final output from hdfs:///user/hadoop/tmp/mrjob/ExploreGraph.hadoop.20160301.015847.095270/output\r\n",
      "[hadoop@ip-172-31-1-180 lei_wiki]$\r\n"
     ]
    }
   ],
   "source": [
    "#!python ExploreGraph.py 'all-pages-indexed-out.txt' -r 'hadoop' --cleanup 'NONE' > wiki_sumstats\n",
    "!cat wiki_explore_emr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"total nodes: \"\t5781290\n",
      "\"total links: \"\t71057028\n",
      "\"average degree: \"\t24.58172086160701\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEPCAYAAAB2s3LUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrZD0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107b38fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10\n",
    "\n",
    "with open('wiki_sumstats_emr.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    if 'dist' not in line:\n",
    "        print line.strip()\n",
    "    else:\n",
    "        dc, dic = line.split('\\t')\n",
    "        cmd = 'degrees = %s' %dic\n",
    "        exec cmd\n",
    "        \n",
    "plt.plot([log10(int(k)) for k in degrees.keys()], degrees.values(), 'r.')\n",
    "plt.xlabel('log(Node Degree)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.4: Shortest path graph distances (Wikipedia)\n",
    "\n",
    "Using MRJob, find shortest path graph distances in the Wikipedia network on the AWS cloud.\n",
    "Reuse your code from 7.2, but once again be warned of Wikipedia being a directed network.\n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n",
    "\n",
    "When running your code on the Wikipedia network, proof its function by running the job:\n",
    "\n",
    "- shortest path from \"Ireland\" (index=6176135) to \"University of California, Berkeley\" (index=13466359),\n",
    "\n",
    "and show your code's output.\n",
    "\n",
    "Once your code is running, find some other shortest paths and report your results.\n",
    "\n",
    "###Two changes to improve performance for unweighted graph\n",
    "- in iteration mrjob: no need to store weight value, to reduce the amount of data during processing\n",
    "- in driver program: the stopping criterion for unweighted network is simpler: once the destination becomes frontier, it has the shortest path from the source\n",
    "\n",
    "###Mrjob for unweighted BFS iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UnweightedShortestPathIter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile UnweightedShortestPathIter.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "\n",
    "class UnweightedShortestPathIter(MRJob):\n",
    "    DEFAULT_PROTOCOL = 'json'\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(UnweightedShortestPathIter, self).__init__(*args, **kwargs)\n",
    "        \n",
    "                                                 \n",
    "    def configure_options(self):\n",
    "        super(UnweightedShortestPathIter, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--source', dest='source', default='1', type='string',\n",
    "            help='source: source node (default 1)') \n",
    "        self.add_passthrough_option(\n",
    "            '--destination', dest='destination', default='1', type='string',\n",
    "            help='destination: destination node (default 1)') \n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        nid, dic = line.strip().split('\\t', 1)\n",
    "        cmd = 'node = %s' %dic\n",
    "        exec cmd        \n",
    "        # if the node structure is incomplete (first pass), add them                \n",
    "        if 'dist' not in node:            \n",
    "            node = {'adj':node.keys(), 'path':[]}            \n",
    "            node['dist'] = 0 if self.options.source==nid else -1            \n",
    "        # emit node\n",
    "        yield nid, node        \n",
    "        # emit distances to reachable nodes\n",
    "        if node['dist'] >= 0:\n",
    "            for m in node['adj']:                     \n",
    "                yield m, {'dd':(1+node['dist']), 'pp':(node['path']+[nid])}\n",
    "                \n",
    "    def reducer(self, nid, value):\n",
    "        dmin = float('inf')\n",
    "        path = node = None\n",
    "        # loop through all arrivals\n",
    "        for v in value:            \n",
    "            if 'dist' in v:\n",
    "                node = v\n",
    "            elif v['dd'] < dmin:\n",
    "                dmin = v['dd']\n",
    "                path = v['pp']\n",
    "        # handle dangling node, we only care if it's destination\n",
    "        if not node and nid == self.options.destination:\n",
    "            node = {'adj':[], 'dist':dmin, 'path':path}\n",
    "        elif not node and nid != self.options.destination:\n",
    "            return\n",
    "        # update distance and path\n",
    "        if (node['dist'] == -1 and path) or dmin < node['dist']:\n",
    "            node['dist'] = dmin\n",
    "            node['path'] = path\n",
    "        # emit for next iteration\n",
    "        yield nid, node\n",
    "        \n",
    "    def steps(self):\n",
    "        jc = {\n",
    "            'mapreduce.job.maps': '10',\n",
    "            'mapreduce.job.reduces': '10',\n",
    "        }\n",
    "        return [MRStep(mapper=self.mapper\n",
    "                       , combiner=self.reducer\n",
    "                       , reducer=self.reducer                       \n",
    "                       , jobconf = jc\n",
    "                      )\n",
    "               ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    UnweightedShortestPathIter.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Unit test for unweighted BFS iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python UnweightedShortestPathIter.py all-pages-indexed-out.txt \\\n",
    "--source '6176135' --destination '13466359' -r 'hadoop' --cleanup 'NONE' --no-output True\n",
    "\n",
    "# s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt\n",
    "#python UnweightedShortestPathIter.py all*out.txt --source 6176135 --cleanup 'NONE' -r 'inline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Driver program for unweighted BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RunUnweightedBFS.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile RunUnweightedBFS.py\n",
    "#!/usr/bin/python\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "from UnweightedShortestPathIter import UnweightedShortestPathIter\n",
    "import sys, getopt\n",
    "\n",
    "# parse parameter\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:], \"hg:s:d:m:\")\n",
    "    except getopt.GetoptError:\n",
    "        print 'RunUnweightedBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "        sys.exit(2)\n",
    "    if len(opts) != 4:\n",
    "        print 'RunUnweightedBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt == '-h':\n",
    "            print 'RunUnweightedBFS.py -g <graph> -s <source> -d <destination> -m <mode>'\n",
    "            sys.exit(2)\n",
    "        elif opt == '-g':\n",
    "            graph = arg\n",
    "        elif opt == '-s':\n",
    "            source = arg\n",
    "        elif opt == '-d':\n",
    "            destination = arg\n",
    "        elif opt == '-m':\n",
    "            mode = arg\n",
    "        \n",
    "\n",
    "# creat BFS job\n",
    "init_job = UnweightedShortestPathIter(args=[graph, '--source', source, '--destination', destination, '-r', mode])\n",
    "iter_job = UnweightedShortestPathIter(args=['graph', '--source', source, '--destination', destination, '-r', mode])\n",
    "\n",
    "# run initialization job\n",
    "with init_job.make_runner() as runner:\n",
    "    runner.run()    \n",
    "    # save our graph file for iteration\n",
    "    with open('graph', 'w') as f:\n",
    "        for line in runner.stream_output():\n",
    "            # value is nid and node object\n",
    "            nid, node = init_job.parse_output_line(line)            \n",
    "            # write graph file \n",
    "            f.write('%s\\t%s\\n' %(nid, node))\n",
    "\n",
    "# run BFS iteratively\n",
    "\n",
    "i = 1\n",
    "while(1):    \n",
    "    print 'iteration %s' %i    \n",
    "    fileName = 'shortest_path_%s_%s' %(source, destination)\n",
    "    stop = False\n",
    "    with iter_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output    \n",
    "        with open('graph', 'w') as f:\n",
    "            for line in runner.stream_output():\n",
    "                # value is nid and node object\n",
    "                nid, node = iter_job.parse_output_line(line)                \n",
    "                # if the destination is reached, save results and quit\n",
    "                if nid == destination and node['dist'] > 0:\n",
    "                    with open(fileName) as s:\n",
    "                        s.write('%s\\t%s\\n' %(nid, str(node)))\n",
    "                    stop = True\n",
    "                    break\n",
    "                else:\n",
    "                    # otherwise write to file for next iteration\n",
    "                    f.write('%s\\t%s\\n' %(nid, str(node)))\n",
    "    \n",
    "    if stop:\n",
    "        break\n",
    "    # more iteration needed\n",
    "    i += 1    \n",
    "        \n",
    "print \"Traversing completes!\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Unit test of unweighted BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\r\n",
      "Traversing completes!\r\n",
      "\r\n",
      "shortest distance between 1 and 4: 2\r\n",
      "path: 1 -> 2 -> 4\r\n"
     ]
    }
   ],
   "source": [
    "!python RunUnweightedBFS.py -s 1 -d 4 -m 'inline' -g undirected_toy.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting FindWikiShortestPath.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile FindWikiShortestPath.sh\n",
    "#!/usr/bin/python\n",
    "\n",
    "python RunUnweightedBFS.py -s '6176135' -d '13466359' -m 'hadoop' -g 'all-pages-indexed-out.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### temp: show path between source and destination\n",
    "with open('graph', 'r') as f:\n",
    "    line = f.readline()\n",
    "    while (line):\n",
    "        nid, node = line.split('\\t')\n",
    "        if nid == destination:\n",
    "            cmd = 'node = %s' %node\n",
    "            exec cmd\n",
    "            if node['path']:\n",
    "                print 'shortest distance between %s and %s: %s' %(source, destination, node['dist'])\n",
    "                print 'path: %s' %' -> '.join(node['path']+[destination])\n",
    "            else:\n",
    "                print '%s is a dangling node, cannot traverse from it!' %source\n",
    "            break\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMR_script_submit.txt                directed_toy.txt\n",
      "ExploreGraph.py                      graph\n",
      "FindWikiShortestPath.sh              indices.txt\n",
      "HW7-Questions.txt                    randNet.txt\n",
      "MIDS-W261-2016-HWK-Week07-Yang.ipynb randNet_topics.txt\n",
      "PageRank-test.txt                    \u001b[34mref\u001b[m\u001b[m\n",
      "PageRank-test_indexed.txt            sumstats\n",
      "RunBFS.py                            undirected_toy.txt\n",
      "RunUnweightedBFS.py                  wiki_explore.txt\n",
      "ShortestPathIter.py                  wiki_explore_emr.txt\n",
      "ShortestPathIter.pyc                 wiki_sample.txt\n",
      "ShortestPathMapReduce.png            wiki_sumstats\n",
      "UnweightedShortestPathIter.py        wiki_sumstats_emr.txt\n",
      "UnweightedShortestPathIter.pyc\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    !ls\n",
    "    a=1\n",
    "    print a\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.5: Conceptual exercise: Largest single-source network distances\n",
    "\n",
    "Suppose you wanted to find the largest network distance from a single source,\n",
    "i.e., a node that is the furthest (but still reachable) from a single source.\n",
    "\n",
    "How would you implement this task? \n",
    "How is this different from finding the shortest path graph distances?\n",
    "\n",
    "Is this task more difficult to implement than the shortest path distance?\n",
    "\n",
    "As you respond, please comment on program structure, runtimes, iterations, general system requirements, etc...\n",
    "\n",
    "###Answer:\n",
    "- change the distance comparison step, instead of keeping smaller distance, choose larger distance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.6 (optional): Computational exercise: Largest single-source network distances \n",
    "\n",
    "Using MRJob, write a code to find the largest graph distance and distance-maximizing nodes from a single-source.\n",
    "Test your code first on the toy networks and synonyms network to proof its function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###stop yarn, hdfs, and job history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping yarn daemons\n",
      "stopping resourcemanager\n",
      "localhost: stopping nodemanager\n",
      "localhost: nodemanager did not stop gracefully after 5 seconds: killing with kill -9\n",
      "no proxyserver to stop\n",
      "Stopping namenodes on [localhost]\n",
      "localhost: stopping namenode\n",
      "localhost: stopping datanode\n",
      "Stopping secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: stopping secondarynamenode\n",
      "stopping historyserver\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/Cellar/hadoop/2*/sbin/stop-yarn.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/stop-dfs.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/mr-jobhistory-daemon.sh --config /usr/local/Cellar/hadoop/2*/libexec/etc/hadoop/ stop historyserver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###start yarn, hdfs, and job history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting yarn daemons\n",
      "starting resourcemanager, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/yarn-leiyang-resourcemanager-Leis-MacBook-Pro.local.out\n",
      "localhost: starting nodemanager, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/yarn-leiyang-nodemanager-Leis-MacBook-Pro.local.out\n",
      "Starting namenodes on [localhost]\n",
      "localhost: starting namenode, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/hadoop-leiyang-namenode-Leis-MacBook-Pro.local.out\n",
      "localhost: starting datanode, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/hadoop-leiyang-datanode-Leis-MacBook-Pro.local.out\n",
      "Starting secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: starting secondarynamenode, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/hadoop-leiyang-secondarynamenode-Leis-MacBook-Pro.local.out\n",
      "starting historyserver, logging to /usr/local/Cellar/hadoop/2.7.1/libexec/logs/mapred-leiyang-historyserver-Leis-MacBook-Pro.local.out\n",
      "16/02/26 17:44:11 INFO hs.JobHistoryServer: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting JobHistoryServer\n",
      "STARTUP_MSG:   host = leis-macbook-pro.local/192.168.0.12\n",
      "STARTUP_MSG:   args = []\n",
      "STARTUP_MSG:   version = 2.7.1\n",
      "STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/contrib/capacity-scheduler/*.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/contrib/capacity-scheduler/*.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/Cellar/hadoop/2.7.1/libexec/modules/*.jar\n",
      "STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z\n",
      "STARTUP_MSG:   java = 1.7.0_79\n",
      "************************************************************/\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/Cellar/hadoop/2*/sbin/start-yarn.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/start-dfs.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/mr-jobhistory-daemon.sh --config /usr/local/Cellar/hadoop/2*/libexec/etc/hadoop/ start historyserver "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
