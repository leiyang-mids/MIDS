{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261, Machine Learning at Scale\n",
    "--------\n",
    "####Assignement:  week \\#10\n",
    "####[Lei Yang](mailto:leiyang@berkeley.edu) | [Michael Kennedy](mailto:mkennedy@ischool.berkeley.edu) | [Natarajan Krishnaswami](mailto:natarajan@krishnaswami.org)\n",
    "####Due: 2016-03-29, 8AM PST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###HW 10.0: Short answer questions\n",
    "\n",
    "***What is Apache Spark and how is it different to Apache Hadoop? ***\n",
    "\n",
    "**Fill in the blanks:**\n",
    "- Spark API consists of interfaces to develop applications based on it in Java, ...... languages (list languages). \n",
    "- Using Spark, resource management can be done either in a single server instance or using a framework such as Mesos or ????? in a distributed manner.\n",
    "\n",
    "**What is an RDD and show a fun example of creating one and bringing the first element back to the driver program.**\n",
    "\n",
    "**What is lazy evaluation and give an intuitoive example of lazy evaluation and comment on the massive computational savings to be had from lazy evaluation.**\n",
    "\n",
    "\n",
    "###HW 10.1: \n",
    "In Spark write the code to count how often each word appears in a text document (or set of documents). Please use this homework document as a the example document to run an experiment.  Report the following: provide a sorted list of tokens in decreasing order of frequency of occurence.\n",
    "\n",
    "###HW 10.1.1\n",
    "Modify the above word count code to count words that begin with lower case letters (a-z) and report your findings. Again sort the output words in decreasing order of frequency.\n",
    "\n",
    "\n",
    "\n",
    "###HW 10.2: KMeans a la MLLib \n",
    "Using the following  MLlib-centric KMeans code snippet: \n",
    "\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "#### Load and parse the data\n",
    "#### NOTE  kmeans_data.txt is available here https://www.dropbox.com/s/q85t0ytb9apggnh/kmeans_data.txt?dl=0 \n",
    "data = sc.textFile(\"kmeans_data.txt\")\n",
    "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "\n",
    "#### Build the model (cluster the data)\n",
    "clusters = KMeans.train(parsedData, 2, maxIterations=10,\n",
    "        runs=10, initializationMode=\"random\")\n",
    "\n",
    "#### Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n",
    "\n",
    "#### Save and load model\n",
    "clusters.save(sc, \"myModelPath\")\n",
    "sameModel = KMeansModel.load(sc, \"myModelPath\")\n",
    "\n",
    "\n",
    "#### NOTE  kmeans_data.txt is available here https://www.dropbox.com/s/q85t0ytb9apggnh/kmeans_data.txt?dl=0 \n",
    "\n",
    "Run this code snippet and list the clusters that your find and compute the Within Set Sum of Squared Errors for the found clusters. Comment on your findings.\n",
    "\n",
    "\n",
    "\n",
    "###HW 10.3: \n",
    "Download the following KMeans notebook:\n",
    "\n",
    "https://www.dropbox.com/s/3nsthvp8g2rrrdh/EM-Kmeans.ipynb?dl=0\n",
    "\n",
    "Generate 3 clusters with 100 (one hundred) data points per cluster (using the code provided). Plot the data.\n",
    "Then run MLlib's Kmean implementation on this data  and report your results as follows:\n",
    "\n",
    "- plot the resulting clusters after 1 iteration, 10 iterations, after 20 iterations, after 100 iterations.\n",
    "- in each plot please report the Within Set Sum of Squared Errors for the found clusters. Comment on the progress of this measure as the KMEans algorithms runs for more iterations\n",
    "\n",
    "\n",
    "\n",
    "###HW 10.4: \n",
    "Using the KMeans code (homegrown code) provided repeat the experiments in HW10.3. Comment on any differences between the results in HW10.3 and HW10.4. Explain.\n",
    "\n",
    "\n",
    "\n",
    "###HW 10.5:  (OPTIONAL)\n",
    "Using the KMeans code provided modify it to do a weighted KMeans and repeat the experiements in HW10.3. Comment on any differences between the results in HW10.3 and HW10.5. Explain.\n",
    "\n",
    "NOTE: Weight each example as follows using the inverse vector length (Euclidean norm): \n",
    "\n",
    "weight(X)= 1/||X||, \n",
    "\n",
    "where ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n",
    "\n",
    "Here X is vector made up of X1 and X2.\n",
    "\n",
    "\n",
    "\n",
    "###HW 10.6: Linear Regression (OPTIONAL)\n",
    "###HW 10.6.1\n",
    "Using the following linear regression notebook:\n",
    "\n",
    " https://www.dropbox.com/s/atzqkc0p1eajuz6/LinearRegression-Notebook-Challenge.ipynb?dl=0 \n",
    "\n",
    "Generate 2 sets of data with 100 data points using the data generation code provided and plot each in separate plots. Call one the training set and the other the testing set.\n",
    "\n",
    "Using MLLib's LinearRegressionWithSGD train up a linear regression model with the training dataset and evaluate with the testing set. What a good number of iterations for training the linear regression model? Justify with plots and words. \n",
    "\n",
    "###HW 10.6.2\n",
    "In the notebook provide, in the cell labeled \"Gradient descent (regularization)\".\n",
    "\n",
    "Fill in the blanks and get this code to work for LASS0 and RIDGE linear regression.\n",
    "\n",
    "Using the data from 10.6.1 tune the hyper parameters of your LASS0 and RIDGE regression. Report your findings with words and plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###stop yarn, hdfs, and job history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping yarn daemons\n",
      "stopping resourcemanager\n",
      "localhost: stopping nodemanager\n",
      "no proxyserver to stop\n",
      "Stopping namenodes on [localhost]\n",
      "localhost: stopping namenode\n",
      "localhost: stopping datanode\n",
      "Stopping secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: stopping secondarynamenode\n",
      "stopping historyserver\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/Cellar/hadoop/2*/sbin/stop-yarn.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/stop-dfs.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/mr-jobhistory-daemon.sh --config /usr/local/Cellar/hadoop/2*/libexec/etc/hadoop/ stop historyserver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###start yarn, hdfs, and job history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting yarn daemons\n",
      "resourcemanager running as process 77362. Stop it first.\n",
      "localhost: nodemanager running as process 77463. Stop it first.\n",
      "Starting namenodes on [localhost]\n",
      "localhost: namenode running as process 77612. Stop it first.\n",
      "localhost: datanode running as process 77705. Stop it first.\n",
      "Starting secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: secondarynamenode running as process 77824. Stop it first.\n",
      "historyserver running as process 77932. Stop it first.\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/Cellar/hadoop/2*/sbin/start-yarn.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/start-dfs.sh\n",
    "!/usr/local/Cellar/hadoop/2*/sbin/mr-jobhistory-daemon.sh --config /usr/local/Cellar/hadoop/2*/libexec/etc/hadoop/ start historyserver "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
