{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MIDS DATASCI W271 [Lab #1](https://drive.google.com/open?id=0B3l4mqbuf82YNFk2Y0x5S0ZLc1U)\n",
    "---------\n",
    "##Submitted by Lei Yang ([leiyang@berkeley.edu](mailto:leiyang@berkeley.edu)) 2016-01-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Question 5 (6 Points)\n",
    "\n",
    "####1. Find the value of x that minimizes E(Y). Show that your result is really the minimum.\n",
    "We first expand the definition of $Y$:\n",
    "\n",
    "$$Y=a+b(X-x)^2=a+bx^2+bX^2-2bxX$$\n",
    "\n",
    "then $E(Y)$ becomes:\n",
    "\n",
    "$$E(Y)=a+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "to find the $x$ that minimums $E(Y)$, we take derivative with respect to $x$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=2bx-2bE(X)$$\n",
    "\n",
    "set it to $0$ and we will the $x$ that minimums $E(Y)$:\n",
    "\n",
    "$$\\color{red}{x=E(Y)}$$\n",
    "\n",
    "Geometrically, by subtracting $E(X)$ from X we move the whole population of $X$ around zero, which will give the minimum square value of the population.\n",
    "\n",
    "####2. Find the value of E(Y) for the choice of x you found in (1)?\n",
    "Plug in $x=E(X)$ into the formula of $E(Y)$, we have:\n",
    "\n",
    "$$E(Y)=a+bE(X)^2+bE(X^2)-2bE(X)^2=a+b(E(X^2)-E(X)^2)$$\n",
    "\n",
    "and we have \n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=a+bVar(X)}$$\n",
    "\n",
    "####3. Suppose $Y = ax + b(X − x)^2$. Find the values of $x$ that minimizes $E(Y)$. Show that your result is really the minimum.\n",
    "Similar to part \\#1, we first obtain the new $E(Y)$:\n",
    "\n",
    "$$E(Y)=ax+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "take derivative of $E(Y)$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=a+2bx-2bE(X)$$\n",
    "\n",
    "set it to zero, we have the $x$ that minimums $E(Y)$\n",
    "\n",
    "$$x=E(X)-\\frac{a}{2b}$$\n",
    "\n",
    "plug $x$ into $E(Y)$, and the minimum is:\n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=aE(X)+bVar(X)-\\frac{a^2}{2b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Question 5 (6 Points)\n",
    "\n",
    "####1. Find the value of x that minimizes E(Y). Show that your result is really the minimum.\n",
    "We first expand the definition of $Y$:\n",
    "\n",
    "$$Y=a+b(X-x)^2=a+bx^2+bX^2-2bxX$$\n",
    "\n",
    "then $E(Y)$ becomes:\n",
    "\n",
    "$$E(Y)=a+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "to find the $x$ that minimums $E(Y)$, we take derivative with respect to $x$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=2bx-2bE(X)$$\n",
    "\n",
    "set it to $0$ and we will the $x$ that minimums $E(Y)$:\n",
    "\n",
    "$$\\color{red}{x=E(Y)}$$\n",
    "\n",
    "Geometrically, by subtracting $E(X)$ from X we move the whole population of $X$ around zero, which will give the minimum square value of the population.\n",
    "\n",
    "####2. Find the value of E(Y) for the choice of x you found in (1)?\n",
    "Plug in $x=E(X)$ into the formula of $E(Y)$, we have:\n",
    "\n",
    "$$E(Y)=a+bE(X)^2+bE(X^2)-2bE(X)^2=a+b(E(X^2)-E(X)^2)$$\n",
    "\n",
    "and we have\n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=a+bVar(X)}$$\n",
    "\n",
    "####3. Suppose $Y = ax + b(X − x)^2$. Find the values of $x$ that minimizes $E(Y)$. Show that your result is really the minimum.\n",
    "Similar to part \\#1, we first obtain the new $E(Y)$:\n",
    "\n",
    "$$E(Y)=ax+bx^2+bE(X^2)-2bxE(X)$$\n",
    "\n",
    "take derivative of $E(Y)$:\n",
    "\n",
    "$$\\frac{dE(Y)}{dx}=a+2bx-2bE(X)$$\n",
    "\n",
    "set it to zero, we have the $x$ that minimums $E(Y)$\n",
    "\n",
    "$$x=E(X)-\\frac{a}{2b}$$\n",
    "\n",
    "plug $x$ into $E(Y)$, and the minimum is:\n",
    "\n",
    "$$\\color{red}{E(Y)_{min}=aE(X)+bVar(X)-\\frac{a^2}{2b}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Question 9 (10 Points)\n",
    "\n",
    "Let $\\bar{Y}$ denote the average of $n$ independent draws from a population distribution with\n",
    "mean $\\mu$ and variance $\\sigma^2$. Consider two alternative estimators of $\\mu$: $W1=(\\frac{n-1}{n})\\bar{Y}$ and\n",
    "$W2 = k\\bar{Y}$ , where $0 < k < 1$.\n",
    "\n",
    "####1. Compute the biases of both $W_1$ and $W_2$. Which estimator is consistent?\n",
    "\n",
    "The bias $B$ of an estimator $e$ for statistic $s$ is defined as the difference between the expectation of the estimator $E(e)$ and the true value $s$ from the population, thus\n",
    "\n",
    "$$B(W_1)=E(W_1)-\\mu,$$ \n",
    "\n",
    "where $$E(W_1)=E((\\frac{n-1}{n})\\bar{Y})=(\\frac{n-1}{n})E(\\bar{Y})=(\\frac{n-1}{n})\\mu$$, because the sample average $\\bar{Y}$ is the unbiased estimation population $\\mu$,\n",
    "\n",
    "thus $\\color{red}{B(W_1)=(\\frac{n-1}{n})\\mu-\\mu=-\\frac{\\mu}{n}}.$\n",
    "\n",
    "Similarly $B(W_2)=E(W_2)-\\mu$, where\n",
    "\n",
    "$E(W_2)=E(k\\bar{Y})=kE(\\bar{Y})=k\\mu$, then $$\\color{red}{B(W_2)=k\\mu-\\mu}.$$\n",
    "\n",
    "As $n$ increases, $B(W_1)$ will decreases to $0$, so $W_1$ is consistent, while $W_2$ is not.\n",
    "\n",
    "####2. Compute $Var(W_1)$ and $Var(W_2)$. Which estimator has lower variance?\n",
    "\n",
    "In general $Var(X)=E(X^2)-E(X)^2$, so we need $E(W_1^2)$ and $E(W_1^2)$:\n",
    "\n",
    "$$E(W_1^2)=E((\\frac{n-1}{n})^2\\bar{Y}^2)=(\\frac{n-1}{n})^2E(\\bar{Y}^2)$$\n",
    "$$E(W_2^2)=E(k^2\\bar{Y}^2)=k^2E(\\bar{Y}^2)$$\n",
    "\n",
    "where $E(\\bar{Y}^2)=Var(\\bar{Y})+E(\\bar{Y})^2$, \n",
    "\n",
    "then $Var(\\bar{Y})=Var(\\frac{1}{n}\\sum_i{X_i})=\\frac{1}{n^2}Var(\\sum_i{X_i})$.\n",
    "\n",
    "Because $X_i$ are independent draws, $Var(\\sum_i{X_i})=\\sum_i{Var(X_i)}=n\\sigma^2$, then $Var(\\bar{Y})=\\frac{1}{n^2}\\times n\\times \\sigma^2=\\frac{\\sigma^2}{n}$\n",
    "\n",
    "And we can obtain $E(\\bar{Y}^2)=\\frac{\\sigma^2}{n}+\\mu^2$, plug it back to get $E(W_1^2)$ and $E(W_2^2)$:\n",
    "\n",
    "$$E(W_1^2)=(\\frac{n-1}{n})^2\\times (\\frac{\\sigma^2}{n}+\\mu^2)$$\n",
    "$$E(W_2^2)=k^2\\times \\frac{\\sigma^2}{n}+\\mu^2$$\n",
    "\n",
    "Finally we have $Var(W_1)$ and $Var(W_2)$:\n",
    "\n",
    "$$Var(W_1)=E(W_1^2)-E(W_1)^2=(\\frac{n-1}{n})^2\\times (\\frac{\\sigma^2}{n}+\\mu^2) - (\\frac{n-1}{n})^2\\times\\mu^2 = \\color{red}{\\frac{((n-1)\\sigma)^2}{n^3}}$$\n",
    "$$Var(W_2)=E(W_2^2)-E(W_2)^2=k^2\\times \\frac{\\sigma^2}{n}+\\mu^2 - k^2\\mu^2=\\color{red}{\\frac{k^2\\sigma^2}{n}+\\mu^2(1-k)}$$\n",
    "\n",
    "\n",
    "\n",
    "###Question 10 (10 Points)\n",
    "Given a random sample $Y_1, Y_2,...,Y_n$ from some distribution $F(.)$ with mean $\\mu$ and variance $\\sigma^2$, where both $\\mu$ and $\\sigma^2$ are unknown parameters.\n",
    "\n",
    "Let $\\bar{Y} be the average of the sample. Consider the following estimator for $\\sigma^2$:\n",
    "\n",
    "$$\\hat{\\sigma^2}=\\frac{1}{n}\\sum_{i=1}^n{(Y_i-\\bar{Y})^2}$$\n",
    "\n",
    "####1. Show that $E(\\bar{Y}) = E(Y_i) \\quad \\forall i \\in 1,2,...,n$\n",
    "$E(\\bar{Y})=E(\\frac{1}{n}\\sum_{i=1}^n{Y_i})=\\frac{1}{n}\\sum_{i=1}^n{E(Y_i)}$, considering $\\forall i\\quad E(Y_i)=E(Y)$, we have\n",
    "\n",
    "$$E(\\bar{Y})=\\frac{1}{n}\\sum_{i=1}^n{E(Y)}=\\frac{1}{n}\\times n\\times E(Y)=E(Y_i)$$\n",
    "\n",
    "####2. Show that $Var(\\bar{Y}) = \\frac{1}{n}Var(Y_i) \\quad \\forall i \\in 1,2,...,n$\n",
    "$Var(\\bar{Y})=Var(\\frac{1}{n}\\sum_i{Y_i})=\\frac{1}{n^2}Var(\\sum_i{Y_i})$, where\n",
    "\n",
    "$$Var(\\sum_i{Y_i})=\\sum_{i,j}{Cov(X_i,X_j)}=$$\n",
    "\n",
    "\n",
    "####3. Compute the expectation of $\\hat{\\sigma^2}$ in terms of n and $\\sigma^2$. In your derivation, make sure make use of the $i.i.d$ property and identify where you use it.\n",
    "####4. Is this an unbiased estimator for $\\sigma^2$?\n",
    "####5. If not, what function of $\\hat{\\sigma^2}$ produce an unbiased estimator?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
