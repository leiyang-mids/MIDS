{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average similarity: 0.493664888871\n"
     ]
    }
   ],
   "source": [
    "dim = 88\n",
    "npt = 66\n",
    "pts = np.random.randint(low=0, high=2, size=(npt, dim))\n",
    "# pts\n",
    "norm_pts = normalize(pts.astype(np.float))\n",
    "dist = norm_pts.dot(norm_pts.T)\n",
    "print 'average similarity:', np.mean(dist[np.triu_indices(npt,k=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_query_clusters(points, k):\n",
    "    '''\n",
    "    points [n,m] - array for n points with dimention m - encoded query\n",
    "    '''\n",
    "    # normalize input\n",
    "    points = normalize(points.astype(np.float))\n",
    "    # get similarity matrix (cosine distance)\n",
    "    dist = points.dot(points.T)\n",
    "    # initialize variables\n",
    "    n_pt = len(points)\n",
    "    cluster_old, cluster_new = np.ones(n_pt), np.zeros(n_pt)\n",
    "    # special case, no clustering\n",
    "    if k==1 or n_pt==1:        \n",
    "        return np.zeros(n_pt), 1 if n_pt==1 else np.mean(dist[np.triu_indices(n_pt,k=1)])\n",
    "    # randomly choose k starting centroids\n",
    "    centroids = points[np.random.permutation(n_pt)[:k]]\n",
    "    while not np.array_equal(cluster_old, cluster_new):\n",
    "        cluster_old = cluster_new\n",
    "        # get cluster index for each point\n",
    "        cluster_new = np.argmax(points.dot(centroids.T), axis=1)\n",
    "        # get new centroids, and within class mean distance/similarity\n",
    "        centroids, in_dist = [], []\n",
    "        for c in np.unique(cluster_new):\n",
    "            pid = cluster_new==c\n",
    "            # set new centroid as the one who has minimum total distance to rest of the points in the cluster\n",
    "            cid = np.argmax(np.sum(dist[np.ix_(pid, pid)], axis=1))\n",
    "            centroids.append(points[pid][cid])\n",
    "            in_dist.append(1 if sum(pid)==1 else np.mean(dist[np.ix_(pid,pid)][np.triu_indices(sum(pid),k=1)]))\n",
    "        centroids = np.array(centroids)\n",
    "        # traditional way to get new centroid, not working well for cosine distance\n",
    "#         centroids = normalize([np.mean(points[cluster_new==c], axis=0) for c in np.unique(cluster_new)])\n",
    "\n",
    "    return cluster_new, np.mean(in_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_characterizer(queries, similarity_limit = 0.9):\n",
    "    '''\n",
    "    queries - list of string for queries\n",
    "    return - list of integers to indicate cluster for each query\n",
    "    '''\n",
    "    # vectorize queries\n",
    "#     characterizer = CountVectorizer()\n",
    "#     encoded_query = characterizer.fit_transform(queries)\n",
    "    # find the optimal clusters based on minimum within cluster distance\n",
    "    avg_sim, k = 0, 0\n",
    "    while avg_sim < similarity_limit:\n",
    "        k += 1\n",
    "        clusters, avg_sim = get_query_clusters(queries, k)\n",
    "        \n",
    "    return clusters, k, avg_sim\n",
    "    # for each cluster, assemble training points from its queries\n",
    "    # for c in np.unique(clusters):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8, 20, 10, 14,  1,  8, 14, 15, 14,  6, 14, 18, 10, 10, 14,  3,  7,\n",
       "         7, 10, 20, 12, 11,  9, 10, 14, 14,  5, 10, 10, 14,  0, 13, 17, 14,\n",
       "        19, 10, 10, 10,  8,  8, 18, 15,  8, 13, 14,  9,  8, 10,  7, 13, 13,\n",
       "        10, 10, 10,  9, 16,  7, 10, 10, 18, 10,  2, 10,  4, 10,  7], dtype=int64),\n",
       " 21,\n",
       " 0.81634124511092665)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_characterizer(pts,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.]), 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize(pts.astype(np.float))\n",
    "get_query_clusters(pts,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644579618166\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(20)\n",
    "cluster = km.fit_predict(norm_pts)\n",
    "in_dist = []\n",
    "for c in np.unique(cluster):\n",
    "    pid = cluster==c    \n",
    "    in_dist.append(1 if sum(pid)==1 else np.mean(dist[np.ix_(pid,pid)][np.triu_indices(sum(pid),k=1)]))\n",
    "print np.mean(in_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "savedData = 'UT_74_19243.pickle'\n",
    "with open(savedData) as f: \n",
    "    feature, plan = pickle.load(f)\n",
    "plan=np.array(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# np.where(sim_click[0][0]=='68781UT0020016')[0][0]\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "n_query = 8\n",
    "n_plan, n_fea = feature.shape\n",
    "sim_click = np.array([[plan[np.random.permutation(n_plan)], \n",
    "                       plan[np.random.permutation(n_plan)[0:np.random.randint(low=1, high=10)]]] \n",
    "                      for i in range(n_query)])\n",
    "q_cluster = np.random.random_integers(0,2,n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 74 plans from feature data with dimension 19243\n",
      "training started for 3 query clusters\n",
      "\n",
      "getting training data from cluster 0 with 3 queries\n",
      "query has 6 clicks\n",
      "extracting feature for clicked plan 68781UT0020001\n",
      "extracting feature for clicked plan 68781UT0030008\n",
      "extracting feature for clicked plan 68781UT0020009\n",
      "extracting feature for clicked plan 68781UT0010016\n",
      "extracting feature for clicked plan 68781UT0020002\n",
      "extracting feature for clicked plan 68781UT0030015\n",
      "query has 8 clicks\n",
      "extracting feature for clicked plan 68781UT0030009\n",
      "extracting feature for clicked plan 18167UT0010002\n",
      "extracting feature for clicked plan 68781UT0010017\n",
      "extracting feature for clicked plan 68781UT0020001\n",
      "extracting feature for clicked plan 68781UT0140005\n",
      "extracting feature for clicked plan 56764UT0010002\n",
      "extracting feature for clicked plan 68781UT0010008\n",
      "extracting feature for clicked plan 68781UT0140010\n",
      "query has 8 clicks\n",
      "extracting feature for clicked plan 68781UT0020019\n",
      "extracting feature for clicked plan 68781UT0030012\n",
      "extracting feature for clicked plan 68781UT0010008\n",
      "extracting feature for clicked plan 18167UT0010001\n",
      "extracting feature for clicked plan 68781UT0020008\n",
      "extracting feature for clicked plan 68781UT0010005\n",
      "extracting feature for clicked plan 56764UT0010003\n",
      "extracting feature for clicked plan 68781UT0030017\n",
      "\n",
      "start training with 851 pair features with 444 +1\n",
      "training completed, obtain plan ranking\n",
      "\n",
      "getting training data from cluster 1 with 3 queries\n",
      "query has 8 clicks\n",
      "extracting feature for clicked plan 18167UT0010001\n",
      "extracting feature for clicked plan 68781UT0140005\n",
      "extracting feature for clicked plan 68781UT0020015\n",
      "extracting feature for clicked plan 42261UT0050001\n",
      "extracting feature for clicked plan 68781UT0010019\n",
      "extracting feature for clicked plan 68781UT0010008\n",
      "extracting feature for clicked plan 68781UT0010005\n",
      "extracting feature for clicked plan 56764UT0010003\n",
      "query has 3 clicks\n",
      "extracting feature for clicked plan 68781UT0010001\n",
      "extracting feature for clicked plan 18167UT0010001\n",
      "extracting feature for clicked plan 68781UT0020007\n",
      "query has 1 clicks\n",
      "extracting feature for clicked plan 68781UT0020010\n",
      "\n",
      "start training with 405 pair features with 204 +1\n",
      "training completed, obtain plan ranking\n",
      "\n",
      "getting training data from cluster 2 with 2 queries\n",
      "query has 7 clicks\n",
      "extracting feature for clicked plan 68781UT0030003\n",
      "extracting feature for clicked plan 68781UT0030016\n",
      "extracting feature for clicked plan 56764UT0010005\n",
      "extracting feature for clicked plan 56764UT0010004\n",
      "extracting feature for clicked plan 56764UT0010006\n",
      "extracting feature for clicked plan 68781UT0030012\n",
      "extracting feature for clicked plan 68781UT0010018\n",
      "query has 7 clicks\n",
      "extracting feature for clicked plan 68781UT0030010\n",
      "extracting feature for clicked plan 42261UT0050003\n",
      "extracting feature for clicked plan 42261UT0050002\n",
      "extracting feature for clicked plan 68781UT0030009\n",
      "extracting feature for clicked plan 68781UT0030005\n",
      "extracting feature for clicked plan 68781UT0030001\n",
      "extracting feature for clicked plan 56764UT0010004\n",
      "\n",
      "start training with 428 pair features with 202 +1\n",
      "training completed, obtain plan ranking\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from get_rank_for_state_plan import *\n",
    "cluster_rank = get_rank_for_state_plan(q_cluster, sim_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22835128,  0.73983946,  0.30144769,  0.21298428,  0.        ,\n",
       "         0.36515739,  0.0931118 ,  0.83875313,  1.        ,  0.37856997,\n",
       "         0.59644845,  0.52429864,  0.73983946,  0.52429864,  0.09456797,\n",
       "         0.0931118 ,  0.52429864,  0.52429864,  0.51873839,  0.52429864,\n",
       "         0.52429864,  0.66193672,  0.52429864,  0.66990897,  0.52429864,\n",
       "         0.66990897,  0.51019228,  0.50954509,  0.52235708,  0.82526049,\n",
       "         0.7360281 ,  0.59644845,  0.5958176 ,  0.66387829,  0.7360281 ,\n",
       "         0.58485751,  0.66387829,  0.59775916,  0.64977193,  0.66387829,\n",
       "         0.59775916,  0.7360281 ,  0.66387829,  0.58356314,  0.17657996,\n",
       "         0.52235708,  0.59775916,  0.5836528 ,  0.44527786,  0.51019228,\n",
       "         0.66387829,  0.59775916,  0.66990897,  0.51873839,  0.5836528 ,\n",
       "         0.64912474,  0.51814962,  0.59775916,  0.45203049,  0.59775916,\n",
       "         0.59775916,  0.64977193,  0.58300561,  0.5958176 ,  0.44527786,\n",
       "         0.66193672,  0.58485751,  0.59775916,  0.66387829,  0.66387829,\n",
       "         0.59644845,  0.66387829,  0.44398349,  0.51744401],\n",
       "       [ 0.26026667,  0.2923153 ,  0.27109306,  0.05237532,  0.21564883,\n",
       "         0.14175468,  0.64115284,  1.        ,  0.99266719,  0.32781749,\n",
       "         0.75677118,  0.7652309 ,  0.2923153 ,  0.7652309 ,  0.64324785,\n",
       "         0.64115284,  0.7652309 ,  0.7652309 ,  0.32678971,  0.7652309 ,\n",
       "         0.7652309 ,  0.54296403,  0.7652309 ,  0.54044267,  0.7652309 ,\n",
       "         0.54044267,  0.76361503,  0.76268391,  0.76243755,  0.43566201,\n",
       "         0.53729766,  0.75677118,  0.54610904,  0.54575738,  0.53729766,\n",
       "         0.3236447 ,  0.54575738,  0.54890239,  0.54414151,  0.54575738,\n",
       "         0.54890239,  0.53729766,  0.54575738,  0.32178246,  0.        ,\n",
       "         0.76243755,  0.54890239,  0.54728652,  0.54311822,  0.76361503,\n",
       "         0.54575738,  0.54890239,  0.54044267,  0.32678971,  0.54728652,\n",
       "         0.54321039,  0.10834397,  0.54890239,  0.11148899,  0.54890239,\n",
       "         0.54890239,  0.54414151,  0.5463554 ,  0.54610904,  0.54311822,\n",
       "         0.54296403,  0.3236447 ,  0.54890239,  0.54575738,  0.54575738,\n",
       "         0.75677118,  0.54575738,  0.54125598,  0.32492748],\n",
       "       [ 0.91849754,  0.18621412,  1.        ,  0.7317965 ,  0.98584244,\n",
       "         0.66406552,  0.30364701,  0.33867609,  0.01183722,  0.54918084,\n",
       "         0.36777204,  0.36528638,  0.18621412,  0.36528638,  0.30091159,\n",
       "         0.30364701,  0.36528638,  0.36528638,  0.5495795 ,  0.36528638,\n",
       "         0.36528638,  0.00581148,  0.36528638,  0.55165348,  0.36528638,\n",
       "         0.55165348,  0.36312212,  0.36433786,  0.36893359,  0.34008531,\n",
       "         0.00464993,  0.36777204,  0.55281503,  0.00216426,  0.00464993,\n",
       "         0.00257595,  0.00216426,  0.54916781,  0.        ,  0.00216426,\n",
       "         0.54916781,  0.00464993,  0.00216426,  0.00500743,  0.80018181,\n",
       "         0.36893359,  0.54916781,  0.54700355,  0.36569807,  0.36312212,\n",
       "         0.00216426,  0.54916781,  0.55165348,  0.5495795 ,  0.54700355,\n",
       "         0.00121574,  0.18605873,  0.54916781,  0.73306228,  0.54916781,\n",
       "         0.54916781,  0.        ,  0.54821929,  0.55281503,  0.36569807,\n",
       "         0.00581148,  0.00257595,  0.54916781,  0.00216426,  0.00216426,\n",
       "         0.36777204,  0.00216426,  0.36812954,  0.55201098]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_rank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
