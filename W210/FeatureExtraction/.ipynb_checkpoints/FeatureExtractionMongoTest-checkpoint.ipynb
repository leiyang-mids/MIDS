{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pymongo import MongoClient, DESCENDING\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "from scipy.sparse import *\n",
    "from scipy import stats\n",
    "from sklearn import svm\n",
    "from sets import Set\n",
    "import numpy as np\n",
    "import json, sys, os, time, re, datetime, itertools, pickle\n",
    "\n",
    "def logTime():\n",
    "    return str(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from aca_drug_feature import *\n",
    "from aca_plan_feature import *\n",
    "from aca_provider_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 14:18:20.846091: using aws Mongo, total drug: 46206, total plan: 6035, total provider: 8799098\n"
     ]
    }
   ],
   "source": [
    "local = False\n",
    "if local:\n",
    "    client = MongoClient('fc8iasm01', 27017)\n",
    "    plan_col = client.aca.plan\n",
    "    drug_col = client.aca.drug\n",
    "else:\n",
    "    client = MongoClient('ec2-54-153-83-172.us-west-1.compute.amazonaws.com', 27017)\n",
    "    plan_col = client.plans.plans\n",
    "    drug_col = client.formularies.drugs\n",
    "    prov_col = client.providers.providers\n",
    "    faci_col = client.providers.facilities\n",
    "\n",
    "all_plan = drug_col.distinct('plans.plan_id')\n",
    "all_drug = drug_col.distinct('rxnorm_id')\n",
    "\n",
    "print '%s: using %s Mongo, total drug: %d, total plan: %d, total provider: %d' %(\n",
    "    logTime(), 'local' if local else 'aws', len(all_drug), len(all_plan), prov_col.count())\n",
    "# client.formularies.scollection_names()\n",
    "# client.providers.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-09 14:07:38.909204: plan document: 12136\n",
      "2016-07-09 14:07:38.998114: drug document: 1540473\n",
      "2016-07-09 14:07:39.084850: provider document: 8799098\n",
      "2016-07-09 14:07:39.171320: facility document: 4815321\n",
      "2016-07-09 14:07:39.264177: unique plan_id: 6035\n",
      "2016-07-09 14:07:39.264318: unique rxnorm_id: 46206\n",
      "2016-07-09 14:07:39.267385: states in the plan: AK, AL, AR, AZ, CO, DE, FL, GA, HI, IA, IL, IN, KS, KY, LA, MA, ME, MI, MN, MO, MS, MT, NC, ND, NE, NH, NJ, NM, NV, OH, OK, OR, PA, SC, SD, TN, TX, UT, VA, WA, WI, WV, WY\n"
     ]
    }
   ],
   "source": [
    "print '%s: plan document: %d' %(logTime(), plan_col.count())\n",
    "print '%s: drug document: %d' %(logTime(), drug_col.count())\n",
    "print '%s: provider document: %d' %(logTime(), prov_col.count())\n",
    "print '%s: facility document: %d' %(logTime(), faci_col.count())\n",
    "print '%s: unique plan_id: %d' %(logTime(), len(all_plan))\n",
    "print '%s: unique rxnorm_id: %d' %(logTime(), len(all_drug))\n",
    "\n",
    "# multi_plan = [1 for p in plan_col.aggregate([{\"$group\": {\"_id\":\"$plan_id\", \"count\":{\"$sum\":1}}}]) if p['count']>1]\n",
    "# print '%s: plans with multiple documents: %d' %(logTime(), sum(multi_plan))\n",
    "\n",
    "# multi_drug = [1 for p in drug_col.aggregate([{\"$group\": {\"_id\":\"$rxnorm_id\", \"count\":{\"$sum\":1}}}]) if p['count']>1]\n",
    "# print '%s: drugs with multiple documents: %d' %(logTime(), sum(multi_drug))\n",
    "\n",
    "state_id = np.unique([i[5:7] for i in all_plan])\n",
    "print '%s: states in the plan: %s' %(logTime(), ', '.join(state_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:27:55.363123: processing 74 plans for UT\n"
     ]
    }
   ],
   "source": [
    "state = 'UT' # set to None to include all (very slow process for all)\n",
    "ex_id = all_plan if not state else [i for i in all_plan if state in i]\n",
    "n_plan = len(ex_id)\n",
    "print '%s: processing %d plans for %s' %(logTime(), len(ex_id), 'all' if not state else state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:29:51.997403: processing 74 plans for UT\n",
      "2016-07-10 17:29:51.997520: 1/11 get formulary state space for all plans\n",
      "2016-07-10 17:29:52.317457: total formulary states: 77\n",
      "2016-07-10 17:29:52.318247: 2/11 extract formulary states for each plan\n",
      "2016-07-10 17:29:52.835207: complete for 74 plans\n",
      "2016-07-10 17:29:52.835771: 3/11 get formulary summary feature for each plan\n",
      "2016-07-10 17:29:52.941727: complete for 74 plans\n",
      "2016-07-10 17:29:52.942321: 4/11 get all drugs covered by all plans\n",
      "2016-07-10 17:29:53.445309: total rx: 6990\n",
      "2016-07-10 17:29:53.445854: 5/11 check drug coverage for each plan\n",
      "2016-07-10 17:30:23.566267: complete for 74 plans\n",
      "2016-07-10 17:30:23.566872: 6/11 get summary feature for drug\n",
      "2016-07-10 17:30:26.199454: total drug states: 56\n",
      "2016-07-10 17:30:26.200027: 7/11 extract drug sumstat for each plan\n",
      "2016-07-10 17:30:29.222912: complete for 74 plans\n",
      "2016-07-10 17:30:29.223427: 8/11 get provider under the plans\n",
      "2016-07-10 17:30:29.735360: total providers: 10473\n",
      "2016-07-10 17:30:29.736040: 9/11 check provider coverage for each plan\n",
      "2016-07-10 17:31:25.826871: complete for 74 plans\n",
      "2016-07-10 17:31:25.827448: 10/11 get summary feature for provider\n",
      "2016-07-10 17:31:28.038992: total provider summary: 1644\n",
      "2016-07-10 17:31:28.039727: 11/11 extract provider sumstat for each plan\n",
      "2016-07-10 17:31:34.252822: complete for 74 plans\n"
     ]
    }
   ],
   "source": [
    "state = 'UT' # set to None to include all (very slow process for all)\n",
    "ex_id = all_plan if not state else [i for i in all_plan if state in i]\n",
    "n_plan = len(ex_id)\n",
    "print '%s: processing %d plans for %s' %(logTime(), len(ex_id), 'all' if not state else state)\n",
    "\n",
    "print '%s: 1/11 get formulary state space for all plans' %logTime()\n",
    "all_plan_states = getFormularyAllStates1(plan_col, ex_id) + \\\n",
    "                  getFormularyAllStates2(plan_col, ex_id) + \\\n",
    "                  getFormularyAllStates3(plan_col, ex_id) \n",
    "print '%s: total formulary states: %d' %(logTime(), len(all_plan_states))\n",
    "\n",
    "print '%s: 2/11 extract formulary states for each plan' %logTime()\n",
    "plan_feature = lil_matrix((n_plan, len(all_plan_states)))\n",
    "valid_plan1 = []\n",
    "for f in [getFormularyStatesForPlan1,getFormularyStatesForPlan2,getFormularyStatesForPlan3]:\n",
    "    for p in f(plan_col, ex_id):\n",
    "        r_id = ex_id.index(p['_id'])\n",
    "        valid_plan1.append(p['_id'])\n",
    "        for s in p['plan_states']:\n",
    "            plan_feature[r_id, all_plan_states.index(s)] = 1        \n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan1))\n",
    "\n",
    "print '%s: 3/11 get formulary summary feature for each plan' %logTime()\n",
    "plan_sumstat = [[0]*3]*len(valid_plan1)\n",
    "for p in getFormularyAggregate(plan_col, valid_plan1):\n",
    "    r_id = ex_id.index(p['plan'])\n",
    "    plan_sumstat[r_id] = [p['avg_copay'],p['avg_ci_rate'],p['count']]\n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan1))\n",
    "    \n",
    "print '%s: 4/11 get all drugs covered by all plans' %logTime()\n",
    "all_rxnorm = drug_col.find({'plans.plan_id':{'$in':valid_plan1}}).distinct('rxnorm_id')\n",
    "print '%s: total rx: %d' %(logTime(), len(all_rxnorm))\n",
    "\n",
    "print '%s: 5/11 check drug coverage for each plan' %logTime()\n",
    "drug_coverage = lil_matrix((n_plan, len(all_rxnorm)))\n",
    "valid_plan2 = []\n",
    "for p in getDrugListForPlans(drug_col, valid_plan1):\n",
    "    valid_plan2.append(p['plan'])\n",
    "    r_id = ex_id.index(p['plan'])\n",
    "    for r in p['drug']:\n",
    "        drug_coverage[r_id, all_rxnorm.index(r)] = 1\n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan2))\n",
    "\n",
    "print '%s: 6/11 get summary feature for drug' %logTime()\n",
    "all_drug_states = getDrugAggregateAllStates(drug_col, valid_plan2)\n",
    "print '%s: total drug states: %d' %(logTime(), len(all_drug_states))\n",
    "\n",
    "print '%s: 7/11 extract drug sumstat for each plan' %logTime()\n",
    "drug_sumstat = lil_matrix((n_plan, len(all_drug_states)))\n",
    "valid_plan3 = []\n",
    "for p in getDrugAggregateCountForPlans(drug_col, valid_plan2):\n",
    "    valid_plan3.append(p['plan'])\n",
    "    r_id = ex_id.index(p['plan'])\n",
    "    for d in p['drug_state']:\n",
    "        drug_sumstat[r_id, all_drug_states.index(d['key'])] = d['cnt']\n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan3))\n",
    "\n",
    "print '%s: 8/11 get provider under the plans' %logTime()\n",
    "all_npi = prov_col.find({'plans.plan_id':{'$in':valid_plan3}}).distinct('npi')\n",
    "print '%s: total providers: %d' %(logTime(), len(all_npi))\n",
    "\n",
    "print '%s: 9/11 check provider coverage for each plan' %logTime() ##### slow #####\n",
    "provider_coverage = lil_matrix((n_plan, len(all_npi)))\n",
    "valid_plan4 = []\n",
    "for p in getProviderListForPlans(prov_col, valid_plan3):\n",
    "    valid_plan4.append(p['plan'])\n",
    "    r_id = ex_id.index(p['plan'])\n",
    "    for npi in p['npi']:\n",
    "        provider_coverage[r_id, all_npi.index(npi)] = 1\n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan4))\n",
    "\n",
    "print '%s: 10/11 get summary feature for provider' %logTime()\n",
    "all_provider_states = getProviderAllStates(prov_col, valid_plan4)\n",
    "print '%s: total provider summary: %d' %(logTime(), len(all_provider_states))\n",
    "\n",
    "print '%s: 11/11 extract provider sumstat for each plan' %logTime()\n",
    "provider_sumstat = lil_matrix((n_plan, len(all_provider_states)))\n",
    "valid_plan5 = []\n",
    "for p in getProviderStateForPlans(prov_col, valid_plan4):\n",
    "    r_id = ex_id.index(p['_id'])\n",
    "    valid_plan5.append(p['_id'])\n",
    "    for d in p['plan_states']:\n",
    "        provider_sumstat[r_id, all_provider_states.index(d['key'])] = d['count'] #[d['count'], d['location']]\n",
    "print '%s: complete for %d plans' %(logTime(), len(valid_plan5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:33:20.075173: feature dimension: (74, 19243)\n",
      "2016-07-10 17:33:22.425142: feature matrix saved as UT_74_19243.pickle\n"
     ]
    }
   ],
   "source": [
    "# combine features\n",
    "plan_sumstat = lil_matrix(plan_sumstat)\n",
    "feature_mat = [plan_feature, drug_coverage, drug_sumstat, provider_coverage, provider_sumstat, plan_sumstat]\n",
    "n_fea = sum(m.shape[1] for m in feature_mat)\n",
    "total_feature = lil_matrix((len(valid_plan5), n_fea))\n",
    "for i in range(len(valid_plan5)):\n",
    "    r_id = ex_id.index(valid_plan5[i])\n",
    "    total_feature[i] = hstack([m.getrow(r_id) for m in feature_mat])\n",
    "print '%s: feature dimension: %s' %(logTime(), total_feature.shape)    \n",
    "\n",
    "saveName = '%s_%d_%d.pickle' %(state, len(valid_plan5), n_fea)\n",
    "with open(saveName, 'w') as f:\n",
    "    pickle.dump([total_feature, valid_plan5], f)\n",
    "print '%s: feature matrix saved as %s' %(logTime(), saveName)\n",
    "\n",
    "del plan_feature\n",
    "del plan_sumstat\n",
    "del drug_coverage\n",
    "del drug_sumstat\n",
    "del provider_coverage \n",
    "del provider_sumstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load saved feature data (feature matrix and plan IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:34:18.042346: data loaded: (74, 19243)\n"
     ]
    }
   ],
   "source": [
    "# Getting back the objects:\n",
    "savedData = 'UT_74_19243.pickle'\n",
    "with open(savedData) as f: \n",
    "    total_feature, plans = pickle.load(f)\n",
    "print '%s: data loaded: %s' %(logTime(), total_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Query to rank plans based on number of specialities in providers the plan covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'speciality_cnt': 119, u'_id': u'18167UT0010001', u'provider_cnt': 7861}\n",
      "{u'speciality_cnt': 119, u'_id': u'18167UT0010003', u'provider_cnt': 7861}\n",
      "{u'speciality_cnt': 119, u'_id': u'18167UT0010002', u'provider_cnt': 7861}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030014', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030016', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030010', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030002', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030011', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0140005', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030005', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030001', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030009', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030006', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030004', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030008', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030017', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030015', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0140010', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030019', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030003', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030012', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030007', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 114, u'_id': u'68781UT0030018', u'provider_cnt': 8818}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020017', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020004', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020009', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020016', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0130010', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0130005', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020014', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020008', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020015', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020003', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020019', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020012', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020002', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020010', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020001', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020011', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020007', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020018', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020005', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 111, u'_id': u'68781UT0020006', u'provider_cnt': 7364}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010005', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010009', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010011', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010007', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010012', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010002', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010004', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010006', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010016', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010017', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010015', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0120005', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010014', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0120010', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010001', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010003', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010010', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010019', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010018', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 103, u'_id': u'68781UT0010008', u'provider_cnt': 4974}\n",
      "{u'speciality_cnt': 88, u'_id': u'42261UT0050001', u'provider_cnt': 969}\n",
      "{u'speciality_cnt': 88, u'_id': u'42261UT0050004', u'provider_cnt': 969}\n",
      "{u'speciality_cnt': 88, u'_id': u'42261UT0050005', u'provider_cnt': 969}\n",
      "{u'speciality_cnt': 88, u'_id': u'42261UT0050002', u'provider_cnt': 969}\n",
      "{u'speciality_cnt': 88, u'_id': u'42261UT0050003', u'provider_cnt': 969}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010001', u'provider_cnt': 1099}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010003', u'provider_cnt': 1099}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010004', u'provider_cnt': 1099}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010005', u'provider_cnt': 1099}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010002', u'provider_cnt': 1099}\n",
      "{u'speciality_cnt': 68, u'_id': u'56764UT0010006', u'provider_cnt': 1097}\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "provider_rank = []\n",
    "for p in prov_col.aggregate(\n",
    "        [\n",
    "            {'$match':{'plans.plan_id':{'$in':plans}, 'facility_name':{'$exists':False}}},\n",
    "            {'$unwind':'$plans'},\n",
    "            {'$match':{'plans.plan_id':{'$in':plans}}},\n",
    "            {'$unwind':'$speciality'},\n",
    "            {'$unwind':'$languages'},\n",
    "            {'$group':{\n",
    "                    '_id':{\n",
    "                        'pl':'$plans.plan_id',\n",
    "                        'sp':'$speciality',\n",
    "                    },\n",
    "                    'cnt':{'$sum':1},\n",
    "                    'loc':{'$sum':{'$size':'$addresses'}}\n",
    "                }\n",
    "            },\n",
    "            {'$project':{'_id':0, 'plan':'$_id.pl', 'speciality':'$_id.sp', 'count':'$cnt'}},\n",
    "            {'$group':{'_id':'$plan', 'speciality_cnt':{'$sum':1}, 'provider_cnt':{'$sum':'$count'} }},\n",
    "            {'$sort':{'speciality_cnt':-1, 'provider_cnt':-1}}        \n",
    "        ], #allowDiskUse=True\n",
    "    ):\n",
    "    i+=1\n",
    "    provider_rank.append(p['_id'])\n",
    "    print p\n",
    "    \n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:34:55.952765: total training sample: 666\n"
     ]
    }
   ],
   "source": [
    "train_rank = provider_rank[0::2]\n",
    "test_rank = provider_rank[1::2]\n",
    "rank_index = [plans.index(x) for x in train_rank]\n",
    "\n",
    "pair_fea, pair_diff = [], []\n",
    "\n",
    "for rank in [rank_index]:\n",
    "    k = 0\n",
    "    for i,j in itertools.combinations(range(len(rank)), 2):\n",
    "        if k%2 == 0:\n",
    "            pair_fea.append(total_feature.getrow(rank[i]) - total_feature.getrow(rank[j]))\n",
    "        else:\n",
    "            pair_fea.append(total_feature.getrow(rank[j]) - total_feature.getrow(rank[i]))            \n",
    "        pair_diff.append((-1)**k)        \n",
    "        k += 1\n",
    "\n",
    "print '%s: total training sample: %d' %(logTime(), len(pair_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=.1)\n",
    "clf.fit(vstack(pair_fea), pair_diff)\n",
    "coef = clf.coef_.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's tau is: 0.7207\n"
     ]
    }
   ],
   "source": [
    "test_weight = [np.dot(coef, total_feature.getrow(plans.index(p)).toarray()[0]) for p in test_rank]\n",
    "letor_rank_ind = np.argsort(test_weight)[::-1]\n",
    "letor_rank = [test_rank[i] for i in letor_rank_ind]\n",
    "k_tau = stats.kendalltau(letor_rank,test_rank)\n",
    "print 'Kendall\\'s tau is: %.4f' %k_tau[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###Query to rank plans based on drug tier policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('18167UT0010003', 9, 26.666666666666668, 11.88888888888889)\n",
      "('18167UT0010002', 9, 21.666666666666668, 8.88888888888889)\n",
      "('18167UT0010001', 9, 21.666666666666668, 5.888888888888889)\n",
      "('42261UT0050003', 12, 0.0, 0.625)\n",
      "('68781UT0130005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0020005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0030005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0120005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0140005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0010005', 9, 2.2222222222222223, 0.2222222222222222)\n",
      "('68781UT0030016', 9, 2.2222222222222223, 0.21111111111111114)\n",
      "('68781UT0010016', 9, 2.2222222222222223, 0.21111111111111114)\n",
      "('68781UT0020016', 9, 2.2222222222222223, 0.21111111111111114)\n",
      "('68781UT0020011', 9, 3.3333333333333335, 0.18888888888888888)\n",
      "('68781UT0010011', 9, 3.3333333333333335, 0.18888888888888888)\n",
      "('68781UT0030011', 9, 3.3333333333333335, 0.18888888888888888)\n",
      "('68781UT0010001', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020002', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010004', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010002', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030015', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010008', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010003', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010007', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010009', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010006', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030014', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020007', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020001', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030004', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020003', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020015', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020004', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020006', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020008', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030006', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020009', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0020014', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030001', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030002', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010015', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030003', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030007', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030008', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0030009', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0010014', 9, 2.2222222222222223, 0.18888888888888888)\n",
      "('68781UT0130010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('68781UT0120010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('68781UT0140010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('68781UT0030010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('68781UT0020010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('68781UT0010010', 9, 3.3333333333333335, 0.17777777777777778)\n",
      "('42261UT0050002', 12, 8.333333333333334, 0.15833333333333333)\n",
      "('42261UT0050001', 12, 8.333333333333334, 0.15833333333333333)\n",
      "('56764UT0010003', 13, 62.5, 0.15384615384615385)\n",
      "('56764UT0010004', 13, 40.0, 0.15384615384615385)\n",
      "('42261UT0050005', 12, 8.333333333333334, 0.13333333333333333)\n",
      "('56764UT0010006', 13, 17.5, 0.10769230769230768)\n",
      "('56764UT0010005', 13, 17.5, 0.10769230769230768)\n",
      "('68781UT0010012', 9, 24.444444444444443, 0.027777777777777776)\n",
      "('68781UT0030012', 9, 24.444444444444443, 0.027777777777777776)\n",
      "('68781UT0020012', 9, 24.444444444444443, 0.027777777777777776)\n",
      "('42261UT0050004', 12, 0.0, 0.0)\n",
      "('68781UT0030017', 9, 0.0, 0.0)\n",
      "('68781UT0030019', 9, 0.0, 0.0)\n",
      "('68781UT0010017', 9, 0.0, 0.0)\n",
      "('68781UT0010018', 9, 0.0, 0.0)\n",
      "('68781UT0020017', 9, 0.0, 0.0)\n",
      "('68781UT0020019', 9, 0.0, 0.0)\n",
      "('68781UT0020018', 9, 0.0, 0.0)\n",
      "('68781UT0010019', 9, 0.0, 0.0)\n",
      "('68781UT0030018', 9, 0.0, 0.0)\n",
      "('56764UT0010001', 3, 0.0, 0.0)\n",
      "('56764UT0010002', 3, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "raw = []\n",
    "\n",
    "for p in plan_col.aggregate(\n",
    "    [\n",
    "        {'$match':{'plan_id':{'$in':plans}}},\n",
    "        {'$unwind':'$formulary'},\n",
    "        {'$unwind':'$formulary.cost_sharing'},\n",
    "        {'$group':{'_id':'$plan_id','n_drug':{'$sum':1}, \n",
    "                   'avg_copay':{'$avg':'$formulary.cost_sharing.copay_amount'},\n",
    "                   'avg_coinsure':{'$avg':'$formulary.cost_sharing.coinsurance_rate'}}},\n",
    "        {'$sort':{'n_drug':-1}},\n",
    "    ]\n",
    "):\n",
    "    raw.append((str(p['_id']), int(p['n_drug']), float(p['avg_copay']), float(p['avg_coinsure'])))\n",
    "\n",
    "# pymongo doesn't sort aggregation for multiple field, so do it manually\n",
    "vtype = [('plan', str), ('s1', int), ('s2', float), ('s3', float)]\n",
    "plan_rank_index = [i for i in np.argsort(np.array(raw,dtype=vtype), order=['s3', 's2', 's1'])][::-1]\n",
    "plan_rank =[raw[i][0] for i in plan_rank_index]\n",
    "for i in plan_rank_index:\n",
    "    print raw[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:46:52.365654: total training sample: 666\n"
     ]
    }
   ],
   "source": [
    "train_rank = plan_rank[0::2]\n",
    "test_rank =  plan_rank[1::2]\n",
    "rank_index = [plans.index(x) for x in train_rank]\n",
    "\n",
    "pair_fea, pair_diff = [], []\n",
    "\n",
    "for rank in [rank_index]:\n",
    "    k = 0\n",
    "    for i,j in itertools.combinations(range(len(rank)), 2):\n",
    "        if k%2 == 0:\n",
    "            pair_fea.append(total_feature.getrow(rank[i]) - total_feature.getrow(rank[j]))\n",
    "        else:\n",
    "            pair_fea.append(total_feature.getrow(rank[j]) - total_feature.getrow(rank[i]))            \n",
    "        pair_diff.append((-1)**k)        \n",
    "        k += 1\n",
    "\n",
    "print '%s: total training sample: %d' %(logTime(), len(pair_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=.1)\n",
    "clf.fit(vstack(pair_fea), pair_diff)\n",
    "coef = clf.coef_.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's tau is: 0.3694\n"
     ]
    }
   ],
   "source": [
    "test_weight = [np.dot(coef, total_feature.getrow(plans.index(p)).toarray()[0]) for p in test_rank]\n",
    "letor_rank_ind = np.argsort(test_weight)[::-1]\n",
    "letor_rank = [test_rank[i] for i in letor_rank_ind]\n",
    "k_tau = stats.kendalltau(letor_rank,test_rank)\n",
    "print 'Kendall\\'s tau is: %.4f' %k_tau[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Combine both rank for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-10 17:36:10.505711: total training sample: 1332\n"
     ]
    }
   ],
   "source": [
    "train_rank = [plan_rank[0::2], provider_rank[0::2]]\n",
    "test_rank = [plan_rank[1::2], provider_rank[1::2]]\n",
    "rank_index = [[plans.index(x) for x in t] for t in train_rank]\n",
    "\n",
    "pair_fea, pair_diff = [], []\n",
    "\n",
    "for rank in rank_index:\n",
    "    k = 0\n",
    "    for i,j in itertools.combinations(range(len(rank)), 2):\n",
    "        if k%2 == 0:\n",
    "            pair_fea.append(total_feature.getrow(rank[i]) - total_feature.getrow(rank[j]))\n",
    "        else:\n",
    "            pair_fea.append(total_feature.getrow(rank[j]) - total_feature.getrow(rank[i]))            \n",
    "        pair_diff.append((-1)**k)        \n",
    "        k += 1\n",
    "\n",
    "print '%s: total training sample: %d' %(logTime(), len(pair_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=.1)\n",
    "clf.fit(vstack(pair_fea), pair_diff)\n",
    "coef = clf.coef_.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's tau is: [0.075075075075075062, 0.23723723723723719]\n"
     ]
    }
   ],
   "source": [
    "test_weight = [[np.dot(coef, total_feature.getrow(plans.index(p)).toarray()[0]) for p in t] for t in test_rank]\n",
    "letor_rank_ind = [np.argsort(t)[::-1] for t in test_weight]\n",
    "letor_rank = [[tr[i] for i in t] for t, tr in zip(letor_rank_ind, test_rank)]\n",
    "k_tau = [stats.kendalltau(l,t)[0] for l,t in zip(letor_rank, test_rank)]\n",
    "print 'Kendall\\'s tau is: %s' %k_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "%reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
