{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pymongo import MongoClient\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "from sets import Set\n",
    "import numpy as np\n",
    "import json, sys, os, time, re, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using aws Mongo, total drug: 46206, total plan: 6035\n"
     ]
    }
   ],
   "source": [
    "local = False\n",
    "if local:\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    plan_col = client.aca.plan\n",
    "    drug_col = client.aca.drug\n",
    "else:\n",
    "    client = MongoClient('ec2-54-153-83-172.us-west-1.compute.amazonaws.com', 27017)\n",
    "    plan_col = client.plans.plans\n",
    "    drug_col = client.formularies.drugs\n",
    "    prov_col = client.providers.providers\n",
    "    faci_col = client.providers.facilities\n",
    "\n",
    "all_plan = drug_col.distinct('plans.plan_id')\n",
    "all_drug = drug_col.distinct('rxnorm_id')\n",
    "\n",
    "print 'Using %s Mongo, total drug: %d, total plan: %d' %('local' if local else 'aws', len(all_drug), len(all_plan))\n",
    "# client.formularies.scollection_names()\n",
    "# client.providers.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load encode definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'drug.plans.drug_tier': u'string',\n",
       " u'drug.plans.prior_authorization': u'boolean',\n",
       " u'drug.plans.quantity_limit': u'boolean',\n",
       " u'drug.plans.step_therapy': u'boolean',\n",
       " u'plan.formulary.cost_sharing.coinsurance_opt': u'string',\n",
       " u'plan.formulary.cost_sharing.coinsurance_rate': u'float',\n",
       " u'plan.formulary.cost_sharing.copay_amount': u'float',\n",
       " u'plan.formulary.cost_sharing.copay_opt': u'string',\n",
       " u'plan.formulary.cost_sharing.pharmacy_type': u'string',\n",
       " u'plan.formulary.drug_tier': u'string',\n",
       " u'plan.formulary.mail_order': u'boolean',\n",
       " u'plan.network.network_tier': u'string',\n",
       " u'plan.plan_id_type': u'string'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getEncodeFields(encode_def, rtn, path=''):\n",
    "    ''' extract the selected fields from the encode json definition '''\n",
    "    \n",
    "    if 'encode' in encode_def and encode_def['encode'] == 1:\n",
    "        rtn[path[1:]] = encode_def['type']\n",
    "    elif 'encode' not in encode_def:\n",
    "        for f in encode_def:\n",
    "            getEncodeFields(encode_def[f], rtn, path + ('' if f=='properties' else '.'+f))\n",
    "    return rtn\n",
    "\n",
    "def logTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "encode_list = getEncodeFields(json.load(open('encode2.json')), {})\n",
    "encode_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data uniformity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-04 20:51:05.524491: plan document: 12242\n",
      "2016-07-04 20:51:05.607379: drug document: 1540473\n",
      "2016-07-04 20:51:05.690348: unique plan_id: 6035\n",
      "2016-07-04 20:51:05.690473: unique rxnorm_id: 46206\n",
      "2016-07-04 20:51:06.574344: plans with multiple documents: 1259\n",
      "2016-07-04 20:51:47.001284: drugs with multiple documents: 12807\n",
      "2016-07-04 20:51:47.003948: states in the plan: AK, AL, AR, AZ, CO, DE, FL, GA, HI, IA, IL, IN, KS, KY, LA, MA, ME, MI, MN, MO, MS, MT, NC, ND, NE, NH, NJ, NM, NV, OH, OK, OR, PA, SC, SD, TN, TX, UT, VA, WA, WI, WV, WY\n"
     ]
    }
   ],
   "source": [
    "print '%s: plan document: %d' %(logTime(), plan_col.count())\n",
    "print '%s: drug document: %d' %(logTime(), drug_col.count())\n",
    "print '%s: unique plan_id: %d' %(logTime(), len(all_plan))\n",
    "print '%s: unique rxnorm_id: %d' %(logTime(), len(all_drug))\n",
    "\n",
    "multi_plan = [1 for p in plan_col.aggregate([{\"$group\": {\"_id\":\"$plan_id\", \"count\":{\"$sum\":1}}}]) if p['count']>1]\n",
    "print '%s: plans with multiple documents: %d' %(logTime(), sum(multi_plan))\n",
    "\n",
    "multi_drug = [1 for p in drug_col.aggregate([{\"$group\": {\"_id\":\"$rxnorm_id\", \"count\":{\"$sum\":1}}}]) if p['count']>1]\n",
    "print '%s: drugs with multiple documents: %d' %(logTime(), sum(multi_drug))\n",
    "\n",
    "state_id = np.unique([i[5:7] for i in all_plan])\n",
    "print '%s: states in the plan: %s' %(logTime(), ', '.join(state_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 270 plans for PA ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'drug.plans.drug_tier': [u'SPECIALTY-DRUGS',\n",
       "  u'NON-PREFERRED-BRAND',\n",
       "  u'GENERIC',\n",
       "  u'PREFERRED-BRAND',\n",
       "  u'ZERO-COST-SHARE-PREVENTIVE-DRUGS',\n",
       "  u'PREFERRED-GENERIC',\n",
       "  u'NON-PREFERRED-GENERIC',\n",
       "  u'SPECIALTY',\n",
       "  u'BRAND',\n",
       "  u'TIER-TWO',\n",
       "  u'TIER-THREE',\n",
       "  u'TIER-ONE',\n",
       "  u'TIER-FOUR',\n",
       "  u'PREFERRED-BRAND-SPECIALTY-DRUGS',\n",
       "  u'NON-PREFERRED-BRAND-SPECIATLY-DRUGS',\n",
       "  u'GENERIC-SPECIALTY-DRUGS',\n",
       "  u'NON-PREFERRED-GENERIC-NON-PREFERRED-BRAND',\n",
       "  u'NON-PREFERRED-BRAND-SPECIALTY-DRUGS',\n",
       "  u'PREFERRED-GENERIC-PREFERRED-BRAND'],\n",
       " u'plan.formulary.cost_sharing.coinsurance_opt': [u'AFTER-DEDUCTIBLE',\n",
       "  u'NO-CHARGE',\n",
       "  None,\n",
       "  u'NO-CHARGE-AFTER-DEDUCTIBLE'],\n",
       " u'plan.formulary.cost_sharing.copay_opt': [u'AFTER-DEDUCTIBLE',\n",
       "  u'NO-CHARGE',\n",
       "  None],\n",
       " u'plan.formulary.cost_sharing.pharmacy_type': [u'1-MONTH-IN-RETAIL',\n",
       "  u'1-MONTH-IN-MAIL',\n",
       "  u'1-MONTH-OUT-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL'],\n",
       " u'plan.formulary.drug_tier': [u'PREFERRED-GENERIC',\n",
       "  u'NON-PREFERRED-GENERIC',\n",
       "  u'PREFERRED-BRAND',\n",
       "  u'NON-PREFERRED-BRAND',\n",
       "  u'SPECIALTY-DRUGS',\n",
       "  u'ZERO-COST-SHARE-PREVENTIVE-DRUGS',\n",
       "  u'GENERIC',\n",
       "  u'SPECIALTY',\n",
       "  u'BRAND',\n",
       "  u'TIER-ONE',\n",
       "  u'TIER-THREE',\n",
       "  u'TIER-TWO',\n",
       "  u'TIER-FOUR',\n",
       "  u'NON-PREFERRED-BRAND-SPECIALTY-DRUGS',\n",
       "  u'NON-PREFERRED-GENERIC-NON-PREFERRED-BRAND',\n",
       "  u'PREFERRED-BRAND-SPECIALTY-DRUGS',\n",
       "  u'PREFERRED-GENERIC-PREFERRED-BRAND'],\n",
       " u'plan.network.network_tier': [u'NON-PREFERRED',\n",
       "  u'PREFERRED',\n",
       "  u'PARTICIPATING',\n",
       "  u'IN-NETWORK',\n",
       "  u'ALLOWABLE',\n",
       "  u'PHARMNETWORK',\n",
       "  u'TIER-ONE',\n",
       "  u'TIER-TWO'],\n",
       " u'plan.plan_id_type': [u'HIOS-PLAN-ID']}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 'PA' # set to None to include all (very slow process for all)\n",
    "ex_id = all_plan if not state else [i for i in all_plan if state in i]\n",
    "print 'processing %d plans for %s ...' %(len(ex_id), 'all' if not state else state)\n",
    "\n",
    "feature_space = {\n",
    "    k : (plan_col if k.startswith('plan') else drug_col).find(\n",
    "        { ('plan_id' if k.startswith('plan') else 'plans.plan_id') : {'$in':ex_id} }\n",
    "    ).distinct(k[k.index('.')+1:]) \n",
    "    for k,v in encode_list.items() if v=='string'\n",
    "}\n",
    "\n",
    "feature_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get common drugs between plans\n",
    "- operator reference [link](https://docs.mongodb.com/manual/reference/operator/query/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-04 20:51:55.152638: checking common drugs among 270 PA plans ...\n",
      "2016-07-04 20:51:59.380357: finishing 30 plans, 0 plan without drug, 2475 common drugs ...\n",
      "2016-07-04 20:52:03.553435: finishing 60 plans, 0 plan without drug, 2475 common drugs ...\n",
      "2016-07-04 20:52:07.981472: finishing 90 plans, 0 plan without drug, 2461 common drugs ...\n",
      "2016-07-04 20:52:12.699088: finishing 120 plans, 0 plan without drug, 2333 common drugs ...\n",
      "2016-07-04 20:52:17.000407: finishing 150 plans, 0 plan without drug, 47 common drugs ...\n",
      "2016-07-04 20:52:21.532955: finishing 180 plans, 0 plan without drug, 47 common drugs ...\n",
      "2016-07-04 20:52:26.216717: finishing 210 plans, 0 plan without drug, 47 common drugs ...\n",
      "2016-07-04 20:52:30.529520: finishing 240 plans, 0 plan without drug, 42 common drugs ...\n",
      "2016-07-04 20:52:34.734001: plan without drug: 0\n",
      "2016-07-04 20:52:34.734954: there are 28 common drug between 270 plans!\n"
     ]
    }
   ],
   "source": [
    "# get rxnorm_id group for each plan\n",
    "plan_drug = [drug_col.find({'plans.plan_id':pid}) for pid in ex_id] \n",
    "n_plan = len(ex_id)\n",
    "\n",
    "# find the first plan with non-zero drug association, \n",
    "# otherwise 'i' is out-of-bound of plan_drug and will stop 'naturally'\n",
    "cnt, i = [], -1\n",
    "while(len(cnt) == 0):\n",
    "    i += 1    \n",
    "    cnt = plan_drug[i].distinct('rxnorm_id')   \n",
    "\n",
    "common_drug, n_empty = Set(cnt), i\n",
    "\n",
    "print '%s: checking common drugs among %d %s plans ...' %(logTime(), n_plan - i, state)\n",
    "for pd in plan_drug[i+1:]:\n",
    "    i += 1\n",
    "    rx = pd.distinct('rxnorm_id')\n",
    "    if len(rx) > 0:\n",
    "        common_drug.intersection_update(rx)\n",
    "    else:\n",
    "        n_empty += 1\n",
    "    if i%30 == 0:\n",
    "        print '%s: finishing %d plans, %d plan without drug, %d common drugs ...' %(logTime(), i, n_empty, len(common_drug))\n",
    "\n",
    "print '%s: plan without drug: %d' %(logTime(), n_empty)\n",
    "\n",
    "# common_drug and drug_attr list will ensure the order of drug/attribute combination remains unchange\n",
    "common_drug = list(common_drug)\n",
    "n_drug = len(common_drug)\n",
    "drug_attr = [[k.split('.')[-1],v,k] for k,v in encode_list.items() if k.startswith ('drug')]\n",
    "drug_cat_index = [k[1]=='string' for k in drug_attr]*n_drug\n",
    "\n",
    "print '%s: there are %d common drug between %d plans!' %(logTime(), n_drug, n_plan-n_empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get pharmacy_type space (over all extracted plan IDs) for each drug_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'BRAND': [u'1-MONTH-IN-RETAIL',\n",
       "  u'1-MONTH-IN-MAIL',\n",
       "  u'1-MONTH-OUT-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL'],\n",
       " u'GENERIC': [u'1-MONTH-IN-RETAIL',\n",
       "  u'1-MONTH-OUT-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL',\n",
       "  u'1-MONTH-IN-MAIL'],\n",
       " u'NON-PREFERRED-BRAND': [u'1-MONTH-IN-RETAIL',\n",
       "  u'1-MONTH-IN-MAIL',\n",
       "  u'1-MONTH-OUT-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL'],\n",
       " u'NON-PREFERRED-BRAND-SPECIALTY-DRUGS': [u'1-MONTH-IN-RETAIL'],\n",
       " u'NON-PREFERRED-GENERIC': [],\n",
       " u'NON-PREFERRED-GENERIC-NON-PREFERRED-BRAND': [u'1-MONTH-IN-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL'],\n",
       " u'PREFERRED-BRAND': [u'1-MONTH-IN-RETAIL', u'3-MONTH-IN-MAIL'],\n",
       " u'PREFERRED-BRAND-SPECIALTY-DRUGS': [u'1-MONTH-IN-RETAIL'],\n",
       " u'PREFERRED-GENERIC': [u'1-MONTH-IN-RETAIL',\n",
       "  u'1-MONTH-OUT-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL',\n",
       "  u'1-MONTH-IN-MAIL'],\n",
       " u'PREFERRED-GENERIC-PREFERRED-BRAND': [u'1-MONTH-IN-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL'],\n",
       " u'SPECIALTY': [u'1-MONTH-IN-RETAIL'],\n",
       " u'SPECIALTY-DRUGS': [u'1-MONTH-IN-RETAIL'],\n",
       " u'TIER-FOUR': [],\n",
       " u'TIER-ONE': [],\n",
       " u'TIER-THREE': [],\n",
       " u'TIER-TWO': [],\n",
       " u'ZERO-COST-SHARE-PREVENTIVE-DRUGS': [u'1-MONTH-IN-RETAIL',\n",
       "  u'3-MONTH-IN-MAIL']}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: issue with distinct in the query\n",
    "# tier_pharm = {tier : plan_col.find(\n",
    "#         {'plan_id':{'$in':ex_id}, 'formulary.drug_tier':tier, 'formulary.0.cost_sharing.0':{'$exists':True}},\n",
    "#         {'_id':0, 'formulary':{'$elemMatch':{'drug_tier':tier}}}\n",
    "#     ).distinct('formulary.cost_sharing.pharmacy_type')\n",
    "#     for tier in feature_space['plan.formulary.drug_tier']\n",
    "# }\n",
    "\n",
    "tier_pharm = {}\n",
    "for tier in feature_space['plan.formulary.drug_tier']:\n",
    "    query = plan_col.find(\n",
    "        {\n",
    "            'plan_id':{'$in':ex_id}, \n",
    "            'formulary.drug_tier':tier,            \n",
    "            'formulary.0.cost_sharing.0':{'$exists':True},             \n",
    "        },\n",
    "        # NOTE: when fomulary is a dict instead of arrary, this projection won't return content\n",
    "        {'_id':0, 'formulary':{'$elemMatch':{'drug_tier':tier}}}\n",
    "    )\n",
    "    tier_pharm[tier] = list(Set(cs['pharmacy_type'] for p in query for f in p['formulary'] for cs in f['cost_sharing']))\n",
    "\n",
    "# simple query to double check results\n",
    "# for p in plan_col.find({'plan_id':{'$in':ex_id}}):\n",
    "#     if 'formulary' not in p:\n",
    "#         continue\n",
    "#     if type(p['formulary']) is dict:\n",
    "#         p['formulary'] = [p['formulary']]\n",
    "#     for f in p['formulary']:        \n",
    "#         if f['drug_tier'] not in tier_pharm:\n",
    "#             tier_pharm[f['drug_tier']]=[]        \n",
    "#         if 'cost_sharing' not in f:\n",
    "#             continue\n",
    "#         for cs in f['cost_sharing']:\n",
    "#             tier_pharm[f['drug_tier']].append(cs['pharmacy_type'])\n",
    "# tier_pharm = {k:list(set(v)) for k,v in tier_pharm.items()}\n",
    "\n",
    "tier_pharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get unique pharmacy_type for each drug_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put tier names into list so the order is fixed for feature extraction\n",
    "tiers = tier_pharm.keys()\n",
    "# we build pharmacy type into the order of feature vector, so no need to include\n",
    "cost_attr = [[k.split('.')[-1],v,k] for k,v in encode_list.items() if 'cost_sharing' in k and 'pharmacy_type' not in k]\n",
    "# flatten the vector to combine all tiers\n",
    "cat2d = [[False] + [k[1]=='string' for k in cost_attr]*len(tier_pharm[t]) for t in tiers]\n",
    "cost_cat_index = [y for x in cat2d for y in x]\n",
    "# # plan level attributes\n",
    "# plan_attr = [[k.split('.')[-1],v,k] for k,v in encode_list.items() if k.startswith('plan') and 'formulary' not in k]\n",
    "# plan_cat_index = [a[1]=='string' for a in plan_attr]\n",
    "\n",
    "# total feature catagrical index - must match with the order of feature canconnation in plan\n",
    "cat_index = cost_cat_index + drug_cat_index\n",
    "catagorical_var = [i for i,v in zip(range(len(cat_index)),cat_index) if v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extraction integer features for each plan\n",
    "- get plan feature --> cost_sharing/pharmacy type\n",
    "- get drug feature --> drug_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-04 20:53:02.456811: processing plan '53789PA0070011' (1/270) ...\n",
      "2016-07-04 20:53:03.978473: processing plan '33709PA0690001' (2/270) ...\n",
      "2016-07-04 20:53:05.832715: processing plan '33709PA0690002' (3/270) ...\n",
      "2016-07-04 20:53:07.678862: processing plan '33709PA0690003' (4/270) ...\n",
      "2016-07-04 20:53:09.523453: processing plan '16322PA0040006' (5/270) ...\n",
      "2016-07-04 20:53:11.041075: processing plan '16322PA0040007' (6/270) ...\n",
      "2016-07-04 20:53:12.562449: processing plan '16322PA0040008' (7/270) ...\n",
      "2016-07-04 20:53:14.072910: processing plan '16322PA0040010' (8/270) ...\n",
      "2016-07-04 20:53:15.619767: processing plan '16322PA0040012' (9/270) ...\n",
      "2016-07-04 20:53:17.123230: processing plan '16322PA0040024' (10/270) ...\n",
      "2016-07-04 20:53:18.628060: processing plan '16322PA0040025' (11/270) ...\n",
      "2016-07-04 20:53:20.156837: processing plan '16322PA0040026' (12/270) ...\n",
      "2016-07-04 20:53:21.686673: processing plan '16322PA0050029' (13/270) ...\n",
      "2016-07-04 20:53:23.197773: processing plan '16322PA0050030' (14/270) ...\n",
      "2016-07-04 20:53:24.709841: processing plan '16322PA0050031' (15/270) ...\n",
      "2016-07-04 20:53:26.284696: processing plan '16322PA0050033' (16/270) ...\n",
      "2016-07-04 20:53:27.888905: processing plan '16322PA0050035' (17/270) ...\n",
      "2016-07-04 20:53:29.423452: processing plan '16322PA0050100' (18/270) ...\n",
      "2016-07-04 20:53:30.931616: processing plan '16322PA0050101' (19/270) ...\n",
      "2016-07-04 20:53:32.438904: processing plan '16322PA0050102' (20/270) ...\n",
      "2016-07-04 20:53:33.942929: processing plan '16322PA0050103' (21/270) ...\n",
      "2016-07-04 20:53:35.453358: processing plan '16322PA0050104' (22/270) ...\n",
      "2016-07-04 20:53:36.979060: processing plan '16322PA0050105' (23/270) ...\n",
      "2016-07-04 20:53:38.487018: processing plan '16322PA0050106' (24/270) ...\n",
      "2016-07-04 20:53:40.013621: processing plan '16322PA0050107' (25/270) ...\n",
      "2016-07-04 20:53:41.551970: processing plan '16322PA0050108' (26/270) ...\n",
      "2016-07-04 20:53:43.088924: processing plan '16322PA0060041' (27/270) ...\n",
      "2016-07-04 20:53:44.595436: processing plan '16322PA0060042' (28/270) ...\n",
      "2016-07-04 20:53:46.118848: processing plan '16322PA0060043' (29/270) ...\n",
      "2016-07-04 20:53:47.635239: processing plan '16322PA0060044' (30/270) ...\n",
      "2016-07-04 20:53:49.149348: processing plan '16322PA0060045' (31/270) ...\n",
      "2016-07-04 20:53:50.657021: processing plan '16322PA0060046' (32/270) ...\n",
      "2016-07-04 20:53:52.225602: processing plan '16322PA0060047' (33/270) ...\n",
      "2016-07-04 20:53:53.825056: processing plan '16322PA0060048' (34/270) ...\n",
      "2016-07-04 20:53:55.374025: processing plan '16322PA0060049' (35/270) ...\n",
      "2016-07-04 20:53:56.880363: processing plan '16322PA0060050' (36/270) ...\n",
      "2016-07-04 20:53:58.412043: processing plan '16322PA0060051' (37/270) ...\n",
      "2016-07-04 20:53:59.930481: processing plan '16322PA0060052' (38/270) ...\n",
      "2016-07-04 20:54:01.453945: processing plan '16322PA0060053' (39/270) ...\n",
      "2016-07-04 20:54:02.996759: processing plan '16322PA0060054' (40/270) ...\n",
      "2016-07-04 20:54:04.494099: processing plan '16322PA0060055' (41/270) ...\n",
      "2016-07-04 20:54:05.997737: processing plan '16322PA0060056' (42/270) ...\n",
      "2016-07-04 20:54:07.530212: processing plan '16322PA0060057' (43/270) ...\n",
      "2016-07-04 20:54:09.037998: processing plan '16322PA0060058' (44/270) ...\n",
      "2016-07-04 20:54:10.566188: processing plan '16322PA0060059' (45/270) ...\n",
      "2016-07-04 20:54:12.111630: processing plan '16322PA0060060' (46/270) ...\n",
      "2016-07-04 20:54:13.623122: processing plan '16322PA0060061' (47/270) ...\n",
      "2016-07-04 20:54:15.132113: processing plan '16322PA0060062' (48/270) ...\n",
      "2016-07-04 20:54:16.663335: processing plan '16322PA0060063' (49/270) ...\n",
      "2016-07-04 20:54:18.235446: processing plan '16322PA0060064' (50/270) ...\n",
      "2016-07-04 20:54:19.770135: processing plan '16322PA0060065' (51/270) ...\n",
      "2016-07-04 20:54:21.280977: processing plan '16322PA0060066' (52/270) ...\n",
      "2016-07-04 20:54:22.792153: processing plan '16322PA0060067' (53/270) ...\n",
      "2016-07-04 20:54:24.329583: processing plan '16322PA0060068' (54/270) ...\n",
      "2016-07-04 20:54:25.865198: processing plan '16322PA0070011' (55/270) ...\n",
      "2016-07-04 20:54:27.387919: processing plan '16322PA0070012' (56/270) ...\n",
      "2016-07-04 20:54:28.897964: processing plan '16322PA0070013' (57/270) ...\n",
      "2016-07-04 20:54:30.408443: processing plan '16322PA0070014' (58/270) ...\n",
      "2016-07-04 20:54:31.913005: processing plan '16322PA0070015' (59/270) ...\n",
      "2016-07-04 20:54:33.429407: processing plan '16322PA0070016' (60/270) ...\n",
      "2016-07-04 20:54:34.929627: processing plan '16322PA0070017' (61/270) ...\n",
      "2016-07-04 20:54:36.435484: processing plan '16322PA0070018' (62/270) ...\n",
      "2016-07-04 20:54:37.976100: processing plan '16322PA0070019' (63/270) ...\n",
      "2016-07-04 20:54:39.486958: processing plan '16322PA0070020' (64/270) ...\n",
      "2016-07-04 20:54:40.995467: processing plan '16322PA0070021' (65/270) ...\n",
      "2016-07-04 20:54:42.504217: processing plan '16322PA0070022' (66/270) ...\n",
      "2016-07-04 20:54:44.053957: processing plan '16322PA0070023' (67/270) ...\n",
      "2016-07-04 20:54:45.580908: processing plan '16322PA0070024' (68/270) ...\n",
      "2016-07-04 20:54:47.087134: processing plan '62560PA0020053' (69/270) ...\n",
      "2016-07-04 20:54:48.592097: processing plan '62560PA0020054' (70/270) ...\n",
      "2016-07-04 20:54:50.546191: processing plan '62560PA0020055' (71/270) ...\n",
      "2016-07-04 20:54:52.058554: processing plan '62560PA0020059' (72/270) ...\n",
      "2016-07-04 20:54:53.955197: processing plan '62560PA0020060' (73/270) ...\n",
      "2016-07-04 20:54:55.468160: processing plan '62560PA0020061' (74/270) ...\n",
      "2016-07-04 20:54:56.975988: processing plan '62560PA0030003' (75/270) ...\n",
      "2016-07-04 20:54:58.492900: processing plan '33709PA0440009' (76/270) ...\n",
      "2016-07-04 20:55:00.666190: processing plan '33709PA0440013' (77/270) ...\n",
      "2016-07-04 20:55:02.444847: processing plan '33709PA0440014' (78/270) ...\n",
      "2016-07-04 20:55:04.198120: processing plan '33709PA0450004' (79/270) ...\n",
      "2016-07-04 20:55:06.038843: processing plan '33709PA0460007' (80/270) ...\n",
      "2016-07-04 20:55:08.675258: processing plan '33709PA0460008' (81/270) ...\n",
      "2016-07-04 20:55:10.443376: processing plan '33709PA0460012' (82/270) ...\n",
      "2016-07-04 20:55:12.220018: processing plan '33709PA0460013' (83/270) ...\n",
      "2016-07-04 20:55:13.983219: processing plan '33709PA0480003' (84/270) ...\n",
      "2016-07-04 20:55:15.769186: processing plan '33709PA0480004' (85/270) ...\n",
      "2016-07-04 20:55:17.554651: processing plan '33709PA0560007' (86/270) ...\n",
      "2016-07-04 20:55:19.335254: processing plan '33709PA0560009' (87/270) ...\n",
      "2016-07-04 20:55:21.132763: processing plan '33709PA0560011' (88/270) ...\n",
      "2016-07-04 20:55:22.924536: processing plan '33709PA0560013' (89/270) ...\n",
      "2016-07-04 20:55:24.696302: processing plan '33709PA0560015' (90/270) ...\n",
      "2016-07-04 20:55:26.453038: processing plan '33709PA0560017' (91/270) ...\n",
      "2016-07-04 20:55:28.250991: processing plan '33709PA0560019' (92/270) ...\n",
      "2016-07-04 20:55:30.021903: processing plan '33709PA0560021' (93/270) ...\n",
      "2016-07-04 20:55:31.772832: processing plan '33709PA0560023' (94/270) ...\n",
      "2016-07-04 20:55:33.545463: processing plan '33709PA0560027' (95/270) ...\n",
      "2016-07-04 20:55:35.303458: processing plan '33709PA0560029' (96/270) ...\n",
      "2016-07-04 20:55:37.063493: processing plan '33709PA0570004' (97/270) ...\n",
      "2016-07-04 20:55:39.284029: processing plan '33709PA0570006' (98/270) ...\n",
      "2016-07-04 20:55:41.094368: processing plan '33709PA0570007' (99/270) ...\n",
      "2016-07-04 20:55:42.871800: processing plan '33709PA0630002' (100/270) ...\n",
      "2016-07-04 20:55:44.620598: processing plan '33709PA0630003' (101/270) ...\n",
      "2016-07-04 20:55:46.465278: processing plan '33709PA0630004' (102/270) ...\n",
      "2016-07-04 20:55:48.576496: processing plan '33709PA0630005' (103/270) ...\n",
      "2016-07-04 20:55:50.334486: processing plan '33709PA0630006' (104/270) ...\n",
      "2016-07-04 20:55:52.093448: processing plan '33709PA0630007' (105/270) ...\n",
      "2016-07-04 20:55:54.256554: processing plan '33709PA0640001' (106/270) ...\n",
      "2016-07-04 20:55:56.032338: processing plan '33709PA0640002' (107/270) ...\n",
      "2016-07-04 20:55:58.489223: processing plan '33709PA0640003' (108/270) ...\n",
      "2016-07-04 20:56:00.245227: processing plan '33709PA0640004' (109/270) ...\n",
      "2016-07-04 20:56:02.031763: processing plan '33709PA0640005' (110/270) ...\n",
      "2016-07-04 20:56:03.804068: processing plan '33709PA0690004' (111/270) ...\n",
      "2016-07-04 20:56:05.559649: processing plan '33871PA0040002' (112/270) ...\n",
      "2016-07-04 20:56:07.476017: processing plan '33871PA0040003' (113/270) ...\n",
      "2016-07-04 20:56:09.826386: processing plan '33871PA0040004' (114/270) ...\n",
      "2016-07-04 20:56:12.202597: processing plan '33871PA0040005' (115/270) ...\n",
      "2016-07-04 20:56:14.124066: processing plan '33871PA0040006' (116/270) ...\n",
      "2016-07-04 20:56:16.054975: processing plan '33871PA0040007' (117/270) ...\n",
      "2016-07-04 20:56:18.009732: processing plan '33871PA0100008' (118/270) ...\n",
      "2016-07-04 20:56:19.985529: processing plan '33871PA0100009' (119/270) ...\n",
      "2016-07-04 20:56:22.181434: processing plan '33871PA0040001' (120/270) ...\n",
      "2016-07-04 20:56:24.072699: processing plan '33871PA0100001' (121/270) ...\n",
      "2016-07-04 20:56:25.920469: processing plan '33871PA0100002' (122/270) ...\n",
      "2016-07-04 20:56:27.767840: processing plan '33871PA0100003' (123/270) ...\n",
      "2016-07-04 20:56:30.049242: processing plan '33871PA0100004' (124/270) ...\n",
      "2016-07-04 20:56:32.312313: processing plan '33871PA0100005' (125/270) ...\n",
      "2016-07-04 20:56:34.217263: processing plan '33871PA0100006' (126/270) ...\n",
      "2016-07-04 20:56:36.085457: processing plan '33871PA0100007' (127/270) ...\n",
      "2016-07-04 20:56:38.276542: processing plan '33871PA0100010' (128/270) ...\n",
      "2016-07-04 20:56:40.510657: processing plan '33871PA0100011' (129/270) ...\n",
      "2016-07-04 20:56:42.742950: processing plan '33871PA0100012' (130/270) ...\n",
      "2016-07-04 20:56:44.618667: processing plan '33871PA0100013' (131/270) ..."
     ]
    }
   ],
   "source": [
    "# for each plan, get int features (plan level & combined fomulary level)\n",
    "plan_int_feature, i, skip = {}, 0, 0\n",
    "\n",
    "for pid in ex_id:\n",
    "    i += 1\n",
    "    if False: # i!=112:\n",
    "        continue\n",
    "    print '%s: processing plan \\'%s\\' (%d/%d) ...' %(logTime(), pid, i, len(ex_id))\n",
    "    # initialize feature vector\n",
    "    tier_feature = [None]*len(tiers)\n",
    "    \n",
    "    # for each plan document, assemble normalized tier info\n",
    "    for tier, pharm in tier_pharm.items():               \n",
    "        doc_cur = plan_col.find(\n",
    "            {'plan_id':pid, 'formulary.drug_tier':tier},\n",
    "            {'_id':0, 'formulary':{'$elemMatch':{'drug_tier':tier}}}        \n",
    "        )\n",
    "        \n",
    "        # no data for this tier, fill in the space with None\n",
    "        n_doc = doc_cur.count()\n",
    "        if n_doc == 0:            \n",
    "            tier_feature[tiers.index(tier)] = [None] * (1 + len(pharm) * len(cost_attr))\n",
    "            continue\n",
    "            \n",
    "        # parse tier info        \n",
    "        pharm_feature = [[None]*len(cost_attr)]*len(pharm)\n",
    "        for doc in doc_cur:              \n",
    "            ##### query issue doc is empty when formulary is not array in plan document\n",
    "            if not doc:\n",
    "                print '\\tWARNING, formulary is not array',pid,tier,n_doc\n",
    "                fml = plan_col.find_one({'plan_id':pid, 'formulary.drug_tier':tier})['formulary']\n",
    "            else:\n",
    "                fml = doc['formulary'][0]\n",
    "                \n",
    "            tier_feature[tiers.index(tier)] = [fml['mail_order']]                    \n",
    "            \n",
    "            # no pharmarcy type, only put mail_order (from one doc)\n",
    "            if len(pharm) == 0 or 'cost_sharing' not in fml:                \n",
    "                continue\n",
    "                        \n",
    "            # put pharmarcy types  \n",
    "            try:\n",
    "                for cs in fml['cost_sharing']:\n",
    "                    cost_feature = [cs[a[0]] if a[1]!='string' \n",
    "                                else feature_space[a[2]].index(cs[a[0]]) \n",
    "                                for a in cost_attr]\n",
    "                    pharm_feature[pharm.index(cs['pharmacy_type'])] = cost_feature\n",
    "            except Exception as ex:\n",
    "                print '\\tERROR parsing cost_sharing value', ex\n",
    "#                 print '\\tWARNING: cost_sharing data:', cs\n",
    "        \n",
    "        tier_feature[tiers.index(tier)] += [y for x in pharm_feature for y in x]\n",
    "        \n",
    "    # flaten the vector for the plan from hierarchy: tier-cost-pharmacy\n",
    "    formulary_feature = [y for x in tier_feature for y in x]\n",
    "    if len(formulary_feature) != len(cost_cat_index):\n",
    "        skip += 1\n",
    "        print 'Error: plan feature dimension mismatch for %s' %pid\n",
    "        continue\n",
    "        \n",
    "    # get the list of drug attributes for a plan\n",
    "    drug_cur = drug_col.find(\n",
    "        {'plans.plan_id':pid, 'rxnorm_id':{'$in':common_drug}},# 'plans.0':{'$exists':True}}, \n",
    "        {'_id':0, 'rxnorm_id':1, 'plans':{ '$elemMatch':{'plan_id':pid} }}\n",
    "    )\n",
    "\n",
    "    drug_dict = {d['rxnorm_id']:d['plans'][0] for d in drug_cur} #TODO: choose the plan matches the tier\n",
    "\n",
    "    # drop the plan if it doesn't match with common drug list\n",
    "    if len(drug_dict) != n_drug:\n",
    "        print 'plan %s drug list doesn\\'t have all common drug (n=%d), skip' %(pid, len(drug_dict))\n",
    "        skip += 1\n",
    "        continue\n",
    "\n",
    "    # flat the drug attributes for all common drugs        \n",
    "    try:\n",
    "        drug_feature = [drug_dict[rx][attr[0]] if attr[1]!='string' \n",
    "                             else feature_space[attr[2]].index(drug_dict[rx][attr[0]])\n",
    "                             for rx in common_drug for attr in drug_attr]\n",
    "    except Exception as ex:\n",
    "        skip += 1\n",
    "        print '\\tERROR (%s) parsing drug info, skip plan %s' %(ex, pid)\n",
    "        continue\n",
    "    \n",
    "    # combine for plan feature - must match with catagroical index concannation order\n",
    "    plan_int_feature[pid] = formulary_feature + drug_feature\n",
    "\n",
    "print '%s: completed processing plan, %d skipped due to parsing issue.' %(logTime(), skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugs: 2710\n",
      "--- 19.570182085 seconds ---\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "print 'drugs: %d' %len(drug_col.find({'plans.plan_id':'67577MI0390012'}).distinct('rxnorm_id'))\n",
    "print(\"--- %s seconds ---\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'drug_name': u'Brimonidine tartrate 2 MG/ML / Timolol 5 MG/ML Ophthalmic Solution [Combigan]',\n",
       " u'rxnorm_id': u'861637'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex filtering\n",
    "\n",
    "regx = re.compile(\".combigan.\", re.IGNORECASE)\n",
    "drug_col.find_one({'drug_name':regx}, {'_id':0, 'drug_name':1, 'rxnorm_id':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check if tier is defined in multiple doc\n",
    "\n",
    "[[None]*4]*3+[]\n",
    "\n",
    "for pid in ex_id:\n",
    "    for tier in tier_pharm:\n",
    "        cnt = plan_col.find(\n",
    "            {'plan_id':pid, 'formulary.drug_tier':tier},\n",
    "            {'_id':0, 'formulary':{'$elemMatch':{'drug_tier':tier}}}        \n",
    "        ).count()\n",
    "        if cnt>1:\n",
    "            print pid,tier,cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %reset "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
